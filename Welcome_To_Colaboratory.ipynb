{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratibha-Saxena/Practice/blob/master/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "\n",
        "def example(rank, world_size):\n",
        "    print(\"here\")\n",
        "    # create default process group\n",
        "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "    # create local model\n",
        "    model = nn.Linear(10, 10).to(rank)\n",
        "    # construct DDP model\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "    # define loss function and optimizer\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = ddp_model(torch.randn(20, 10).to(rank))\n",
        "    labels = torch.randn(20, 10).to(rank)\n",
        "    # backward pass\n",
        "    loss_fn(outputs, labels).backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "eKSE7a04Czew"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "world_size = 1\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
        "mp.spawn(example,\n",
        "    args=(world_size,),\n",
        "    nprocs=world_size,\n",
        "    join=True)"
      ],
      "metadata": {
        "id": "1ZAIPpp_C2zu",
        "outputId": "ad98d08e-133c-4a62-edf1-b30ea1b3046c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ProcessExitedException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d2c2c10fdcf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     join=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    238\u001b[0m                ' torch.multiprocessing.start_processes(...)' % start_method)\n\u001b[1;32m    239\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0merror_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 )\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def get_compiled_model():\n",
        "    # Make a simple 2-layer densely-connected neural network.\n",
        "    inputs = keras.Input(shape=(784,))\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    outputs = keras.layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    batch_size = 32\n",
        "    num_val_samples = 10000\n",
        "\n",
        "    # Return the MNIST dataset in the form of a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Preprocess the data (these are Numpy arrays)\n",
        "    x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
        "    x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
        "    y_train = y_train.astype(\"float32\")\n",
        "    y_test = y_test.astype(\"float32\")\n",
        "\n",
        "    # Reserve num_val_samples samples for validation\n",
        "    x_val = x_train[-num_val_samples:]\n",
        "    y_val = y_train[-num_val_samples:]\n",
        "    x_train = x_train[:-num_val_samples]\n",
        "    y_train = y_train[:-num_val_samples]\n",
        "    return (\n",
        "        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),\n",
        "        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),\n",
        "        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),\n",
        "    )\n",
        "\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model = get_compiled_model()\n",
        "\n",
        "# Train the model on all available devices.\n",
        "train_dataset, val_dataset, test_dataset = get_dataset()\n",
        "model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n",
        "\n",
        "# Test the model on all available devices.\n",
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "JQ5mzJGPDInC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "\n",
        "def setup(rank, world_size):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '12355'\n",
        "\n",
        "    # initialize the process group\n",
        "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "\n",
        "\n",
        "def cleanup():\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "\n",
        "class ToyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.net1 = nn.Linear(10, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.net2 = nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net2(self.relu(self.net1(x)))\n",
        "\n",
        "\n",
        "def demo_basic(rank, world_size):\n",
        "    print(f\"Running basic DDP example on rank {rank}.\")\n",
        "    setup(rank, world_size)\n",
        "\n",
        "    # create model and move it to GPU with id rank\n",
        "    model = ToyModel().to(rank)\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = ddp_model(torch.randn(20, 10))\n",
        "    labels = torch.randn(20, 5).to(rank)\n",
        "    loss_fn(outputs, labels).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(optimizer.state)\n",
        "    cleanup()\n",
        "\n",
        "\n",
        "def run_demo(demo_fn, world_size):\n",
        "\n",
        "    mp.spawn(demo_fn,\n",
        "             args=(world_size,),\n",
        "             nprocs=world_size,\n",
        "             join=True)"
      ],
      "metadata": {
        "id": "8i6AUYzKQejR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_basic(0, 1)"
      ],
      "metadata": {
        "id": "uCBeytE5ZhDF",
        "outputId": "8c67d2d3-9c6f-415f-b249-a9f396073c71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running basic DDP example on rank 0.\n",
            "defaultdict(<class 'dict'>, {Parameter containing:\n",
            "tensor([[ 0.2088, -0.1694, -0.1021,  0.0227, -0.2131,  0.0336,  0.1689,  0.1175,\n",
            "         -0.0136,  0.1406],\n",
            "        [ 0.2453, -0.2789,  0.2364,  0.1790, -0.1127, -0.2589, -0.0633, -0.1115,\n",
            "          0.0259, -0.0732],\n",
            "        [-0.1251,  0.1331, -0.2798, -0.2801,  0.2942, -0.2900, -0.2900,  0.0877,\n",
            "          0.3006, -0.1386],\n",
            "        [-0.0024, -0.0063, -0.3090, -0.2041,  0.2870,  0.2575,  0.2388, -0.0844,\n",
            "         -0.1086, -0.2280],\n",
            "        [ 0.0534,  0.2938,  0.2187, -0.0969, -0.0848,  0.1973, -0.1071,  0.2268,\n",
            "         -0.2613,  0.2259],\n",
            "        [-0.2931, -0.1511,  0.3010,  0.2296, -0.1266, -0.2567, -0.2651, -0.3055,\n",
            "          0.0853,  0.0571],\n",
            "        [-0.2774, -0.1412,  0.1267,  0.1191,  0.0874,  0.1520, -0.2202, -0.1019,\n",
            "         -0.1081,  0.2409],\n",
            "        [ 0.1463, -0.3134,  0.1111, -0.2824, -0.3007, -0.0595,  0.1480, -0.1434,\n",
            "         -0.0043,  0.0309],\n",
            "        [ 0.2998, -0.3127, -0.2823,  0.1486, -0.0671, -0.1245, -0.1895, -0.1884,\n",
            "         -0.2097, -0.2699],\n",
            "        [ 0.0195,  0.1183,  0.1670, -0.0163, -0.0178, -0.3009, -0.2832,  0.0009,\n",
            "         -0.1761,  0.0324]], device='cuda:0', requires_grad=True): {'momentum_buffer': None}, Parameter containing:\n",
            "tensor([ 0.1712, -0.0438,  0.1473,  0.1351,  0.0002, -0.0942, -0.1021,  0.1694,\n",
            "         0.0607, -0.2040], device='cuda:0', requires_grad=True): {'momentum_buffer': None}, Parameter containing:\n",
            "tensor([[ 0.0328,  0.2536, -0.1222, -0.1695, -0.2342, -0.2523,  0.1742,  0.0876,\n",
            "         -0.0236, -0.1375],\n",
            "        [-0.1234,  0.2549, -0.1009,  0.2449, -0.2625,  0.1446, -0.0016, -0.2497,\n",
            "          0.2112, -0.0741],\n",
            "        [-0.0417, -0.0850, -0.1677, -0.1109, -0.1421, -0.1188,  0.3022, -0.2566,\n",
            "         -0.0717, -0.2934],\n",
            "        [-0.2035, -0.0048, -0.2442, -0.1673,  0.0056, -0.2189,  0.1027, -0.0463,\n",
            "          0.1651, -0.1217],\n",
            "        [-0.0354,  0.0233,  0.0037, -0.2012, -0.0378, -0.3137, -0.2029,  0.1962,\n",
            "          0.3063,  0.2451]], device='cuda:0', requires_grad=True): {'momentum_buffer': None}, Parameter containing:\n",
            "tensor([-0.1581, -0.1551, -0.0364, -0.1106, -0.2247], device='cuda:0',\n",
            "       requires_grad=True): {'momentum_buffer': None}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "ofmU5JYfa9wB",
        "outputId": "0baab253-4526-4830-b1de-2c9955dd4cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Nb9QzbL_eW05"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}