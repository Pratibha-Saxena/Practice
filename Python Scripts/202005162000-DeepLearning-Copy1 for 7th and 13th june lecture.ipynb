{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv(\"C:/Users/Admin/Documents/Datasets/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "iris.Species = iris.Species.astype(\"category\")\n",
    "iris[\"Species1\"] = np.repeat([0, 1, 2], 50) # for first 50 observations = 0; for next 50 = 1; for last 50 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>Species1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species  \\\n",
       "0           1           5.1          3.5           1.4          0.2  setosa   \n",
       "1           2           4.9          3.0           1.4          0.2  setosa   \n",
       "2           3           4.7          3.2           1.3          0.2  setosa   \n",
       "3           4           4.6          3.1           1.5          0.2  setosa   \n",
       "4           5           5.0          3.6           1.4          0.2  setosa   \n",
       "\n",
       "   Species1  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length\n",
      "0           1           5.1          3.5           1.4\n",
      "1           2           4.9          3.0           1.4\n",
      "2           3           4.7          3.2           1.3\n",
      "3           4           4.6          3.1           1.5\n",
      "4           5           5.0          3.6           1.4\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Species1, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "X = iris.iloc[:, :4]\n",
    "y = iris.iloc[:, -1]\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Neural Network libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "# activation: 'logistic', 'tanh', 'relu', 'identity'(f(x)=x  sometimes we need it, but, mostly not)\n",
    "nnclf = MLPClassifier(solver=\"sgd\", activation=\"logistic\",\n",
    "                     hidden_layer_sizes=(5),\n",
    "                     learning_rate_init=0.05,\n",
    "                     max_iter=2000,\n",
    "                     random_state=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data Set\n",
      "Accuracy of NN classifier on train set: 0.429\n",
      "Accuracy of NN classifier on test set: 0.289\n"
     ]
    }
   ],
   "source": [
    "print(\"Iris Data Set\")\n",
    "print(\"Accuracy of NN classifier on train set: {:.3f}\".format(nnclf.score(X_train, y_train)))\n",
    "print(\"Accuracy of NN classifier on test set: {:.3f}\".format(nnclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31493471 0.31382249 0.37124279]\n",
      " [0.31551861 0.31354139 0.37094   ]\n",
      " [0.31588612 0.31339164 0.37072224]\n",
      " [0.31449919 0.31403438 0.37146644]\n",
      " [0.41713686 0.24224624 0.3406169 ]\n",
      " [0.31462119 0.31397503 0.37140378]\n",
      " [0.31676692 0.31294841 0.37028467]\n",
      " [0.31477753 0.31389903 0.37132343]\n",
      " [0.31482243 0.31387748 0.37130009]\n",
      " [0.31520645 0.31369093 0.37110262]\n",
      " [0.31477987 0.31389782 0.37132231]\n",
      " [0.31493319 0.31383296 0.37123385]\n",
      " [0.31503382 0.31377488 0.3711913 ]\n",
      " [0.31498472 0.31380593 0.37120935]\n",
      " [0.31503119 0.31377789 0.37119092]\n",
      " [0.31672725 0.31297674 0.37029601]\n",
      " [0.31506596 0.31375892 0.37117512]\n",
      " [0.31533684 0.31362694 0.37103622]\n",
      " [0.31732654 0.3126705  0.37000296]\n",
      " [0.31845216 0.3117948  0.36975305]\n",
      " [0.31501431 0.31378377 0.37120192]\n",
      " [0.31520452 0.31369273 0.37110275]\n",
      " [0.31671552 0.31315994 0.37012454]\n",
      " [0.36616094 0.27779486 0.3560442 ]\n",
      " [0.31486034 0.31385867 0.37128099]\n",
      " [0.31740881 0.3127978  0.36979339]\n",
      " [0.31610351 0.31326423 0.37063227]\n",
      " [0.31499818 0.31379163 0.37121019]\n",
      " [0.31617395 0.31321978 0.37060627]\n",
      " [0.31672923 0.3130866  0.37018417]\n",
      " [0.31464124 0.31396526 0.3713935 ]\n",
      " [0.31522004 0.31368382 0.37109614]\n",
      " [0.31653715 0.31315023 0.37031262]\n",
      " [0.31481995 0.31387832 0.37130173]\n",
      " [0.31468622 0.31394337 0.3713704 ]\n",
      " [0.31573229 0.31343845 0.37082926]\n",
      " [0.31658684 0.3131123  0.37030086]\n",
      " [0.31498126 0.31380003 0.37121871]]\n",
      "[2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print(nnclf.predict_proba(X_test))\n",
    "print(nnclf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes for y:  [0 1 2]\n",
      "Activation function at output layer:  softmax\n",
      "Number of Layers:  3\n",
      "Number of Outputs:  3\n",
      "Number of iterations for convergence:  37\n",
      "\n",
      "Weights matrix:\n",
      " [array([[-0.52998925,  0.36111599,  0.18796543,  0.00311888, -0.13948093],\n",
      "       [ 0.44673126,  0.07644852,  0.42740621,  0.35455554, -0.15755169],\n",
      "       [ 0.52004205,  0.11969676,  0.1036916 ,  0.33844122, -0.43805413],\n",
      "       [-0.36014659, -0.41289383,  0.33042912,  0.25379574,  0.33733733]]), array([[ 0.76893892, -0.4769718 , -0.06402685],\n",
      "       [-0.0612938 , -0.05300824, -0.18462821],\n",
      "       [ 0.35106413, -0.07039123,  0.01814119],\n",
      "       [-0.40492702,  0.08538132,  0.06806998],\n",
      "       [ 0.20906486,  0.41012578,  0.1233021 ]])]\n",
      "\n",
      "Biases:\n",
      " [array([ 0.51745775,  0.3094561 , -0.02450144,  0.24647198, -0.36974329]), array([-0.02666635, -0.10373138,  0.12456878])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes for y: \", nnclf.classes_)\n",
    "print(\"Activation function at output layer: \", nnclf.out_activation_)\n",
    "print(\"Number of Layers: \", nnclf.n_layers_)\n",
    "print(\"Number of Outputs: \", nnclf.n_outputs_)\n",
    "print(\"Number of iterations for convergence: \", nnclf.n_iter_)\n",
    "print(\"\\nWeights matrix:\\n\", nnclf.coefs_)\n",
    "print(\"\\nBiases:\\n\", nnclf.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is built in Python and on top of TensorFlow 2.0\n",
    "# Keras is a neural network library while \n",
    "# TensorFlow is the open source library for a number of tasks in machine learning.\n",
    "# Both frameworks provide high-level APIs for building and training models with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating MLP in Keras\n",
    "# Sequential function groups a linear stack of Layers into a keras model\n",
    "# Sequential model provides training and inference features onthis model\n",
    "from keras import Sequential\n",
    "# A dense layer is just a regular layer of neurons in a neural network.\n",
    "# Each neuron receives input from all the neurons in the previous layer,\n",
    "# thus, densely connected.\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In first Dense layer, the dimension of input layer can be given\n",
    "model.add(Dense(6, input_dim=4, activation='sigmoid', name='HL1'))\n",
    "model.add(Dense(3, activation='relu', name='HL2'))\n",
    "model.add(Dense(3, activation='softmax', name='OL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[-0.10976148, -0.724444  , -0.65626395,  0.03619325, -0.65522605,\n",
      "        -0.1286413 ],\n",
      "       [ 0.17736149,  0.43961787,  0.24760103,  0.6833154 , -0.5694884 ,\n",
      "        -0.05032927],\n",
      "       [ 0.7553977 ,  0.49032164, -0.15084296, -0.49373895, -0.06490886,\n",
      "        -0.58194923],\n",
      "       [-0.04479241, -0.69237113,  0.51764345,  0.35794258, -0.16833794,\n",
      "        -0.1721471 ]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32)], [array([[ 0.74488175, -0.54191613, -0.5168633 ],\n",
      "       [ 0.5770873 , -0.7906784 ,  0.7854657 ],\n",
      "       [-0.07608813,  0.16662508,  0.24417436],\n",
      "       [-0.26737082, -0.01518101, -0.74629897],\n",
      "       [-0.47043985, -0.811698  ,  0.08906704],\n",
      "       [-0.28696412,  0.44837713, -0.6783608 ]], dtype=float32), array([0., 0., 0.], dtype=float32)], [array([[ 0.9990339 , -0.7179899 , -0.3273058 ],\n",
      "       [-0.08639574,  0.4291401 , -0.8756099 ],\n",
      "       [ 0.6613624 ,  0.17456937, -0.8141086 ]], dtype=float32), array([0., 0., 0.], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "# initialized weights\n",
    "print([layer.get_weights() for layer in model.layers])\n",
    "# print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape:  (None, 4)\n",
      "Output layer shape:  (None, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input layer shape: \", model.input_shape)\n",
    "print(\"Output layer shape: \", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Compile defines the loss function, the optimizer and the metrics\n",
    "# You need a compiled model to train because training uses the loss function and optimizer\n",
    "# model.compile(loss='mse', optimizer='sgd',\n",
    "#              metrics=['accuracy', AUC, Precision, Recall])\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-JUN-7TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
      "Unnamed: 0                                                           \n",
      "Mazda RX4          160.0  110  3.90  2.620  16.46   0   1     4     4\n",
      "Mazda RX4 Wag      160.0  110  3.90  2.875  17.02   0   1     4     4\n",
      "Datsun 710         108.0   93  3.85  2.320  18.61   1   1     4     1\n",
      "Hornet 4 Drive     258.0  110  3.08  3.215  19.44   1   0     3     1\n",
      "Hornet Sportabout  360.0  175  3.15  3.440  17.02   0   0     3     2\n",
      "Unnamed: 0\n",
      "Mazda RX4            21.0\n",
      "Mazda RX4 Wag        21.0\n",
      "Datsun 710           22.8\n",
      "Hornet 4 Drive       21.4\n",
      "Hornet Sportabout    18.7\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cars = pd.read_csv(\"C:/Users/Admin/Documents/Datasets/mtcars.csv\")\n",
    "cars.set_index('Unnamed: 0', inplace = True)\n",
    "# cars['cyl'] = cars['cyl'].astype('category')\n",
    "# cars['am'] = cars['am'].astype('category')\n",
    "\n",
    "y = cars['mpg']\n",
    "X = cars.iloc[:,2:11]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.82316132 -0.62584351  0.20011909 -0.70870565  1.07038511  1.\n",
      "  -0.84515425 -0.9701425  -1.02105494]\n",
      " [ 0.53669245  0.58452568 -1.00537917  0.82095857 -0.00782282 -1.\n",
      "  -0.84515425 -0.9701425   0.14586499]]\n"
     ]
    }
   ],
   "source": [
    "# Effect of Normalizing input value\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit(X_train)\n",
    "X_scaled_train = X_scaled.transform(X_train)\n",
    "X_scaled_test = X_scaled.transform(X_test)\n",
    "# scaled values\n",
    "print(X_scaled_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ab9b76a2e37c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#                     alpha=\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     random_state=0).fit(X_scaled_train, y_train)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# sgd,relu,[70,70],learning_rate_init = 0.1 diverges\n",
    "nnreg = MLPRegressor(solver = 'sgd', activation = 'relu',\n",
    "                    hidden_layer_sizes = [70,70],\n",
    "                    learning_rate = 'constant',\n",
    "                    learning_rate_init = 0.00001,\n",
    "                    max_iter = 6000,\n",
    "#                     alpha=\n",
    "                    random_state=0).fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars Data Set\n",
      "R2 on training set: 0.928\n",
      "R2 on test set: 0.754\n"
     ]
    }
   ],
   "source": [
    "print('Cars Data Set')\n",
    "print('R2 on training set: {:.3f}'\n",
    "    .format(nnreg.score(X_scaled_train, y_train)))\n",
    "print('R2 on test set: {:.3f}'\n",
    "    .format(nnreg.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Total number of models in Grid = 3* 3 * 5 * 3 = 135\n",
    "solv = ['lbfgs','adam','sgd']\n",
    "act = ['logistic','tanh','relu']\n",
    "lr_init = [0.1,0.05,0.01,0.005]#,0.001] \n",
    "hidden_layer_sz = [(7),(7,7),(7,7,7)]\n",
    "\n",
    "param_grid = {'solver': solv,\n",
    "              'activation': act,\n",
    "              'learning_rate_init': lr_init,\n",
    "              'hidden_layer_sizes': hidden_layer_sz }\n",
    "\n",
    "grid_search = GridSearchCV(MLPRegressor(learning_rate = 'constant',\n",
    "                                                    max_iter = 8000,\n",
    "                                                    random_state=30),\n",
    "                           param_grid, cv=3, return_train_score=True,\n",
    "                           scoring = ['neg_mean_squared_error','r2'],\n",
    "                           refit = 'r2')\n",
    "#                          scoring = ['precision','recall','f1','auc'],\n",
    "#                          refit = 'f1')\n",
    "\n",
    "grid_models = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       " 'r2': make_scorer(r2_score)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring parameters\n",
    "grid_models.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'hidden_layer_sizes': (7, 7, 7),\n",
       " 'learning_rate_init': 0.1,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "grid_models.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(7, 7, 7), learning_rate='constant',\n",
       "             learning_rate_init=0.1, max_fun=15000, max_iter=8000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=30, shuffle=True, solver='adam', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators\n",
    "grid_models.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779579463198389"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean test r2 (mean of all folds)\n",
    "grid_models.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6271057248958436"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting on training data\n",
    "grid_models.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4552296477553893"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting on test data\n",
    "grid_models.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=7, learning_rate='constant',\n",
       "             learning_rate_init=0.1, max_fun=15000, max_iter=8000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=0, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators\n",
    "grid_models.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872762187459511"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean test r2 (mean of all folds)\n",
    "grid_models.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406414936836227"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting on training data\n",
    "grid_models.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2716990824404726"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting on test data\n",
    "grid_models.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 31)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results for all the models, imported into dataframe\n",
    "cv_results = pd.DataFrame(grid_models.cv_results_)\n",
    "cv_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_train_r2</th>\n",
       "      <th>split1_train_r2</th>\n",
       "      <th>split2_train_r2</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094382</td>\n",
       "      <td>0.119539</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>logistic</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-32.059644</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759096e-02</td>\n",
       "      <td>-0.077878</td>\n",
       "      <td>-0.036539</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>80</td>\n",
       "      <td>-1.300429e-07</td>\n",
       "      <td>-1.950328e-08</td>\n",
       "      <td>-7.915540e-09</td>\n",
       "      <td>-5.248725e-08</td>\n",
       "      <td>5.504381e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026209</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>logistic</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-31.660795</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.940798e-07</td>\n",
       "      <td>-0.183036</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>97</td>\n",
       "      <td>-2.023084e-02</td>\n",
       "      <td>-2.524962e-02</td>\n",
       "      <td>-1.801163e-02</td>\n",
       "      <td>-2.116403e-02</td>\n",
       "      <td>3.027680e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.094382      0.119539         0.001344        0.000620   \n",
       "1       0.026209      0.003698         0.002239        0.000905   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0         logistic                        7                      0.1   \n",
       "1         logistic                        7                      0.1   \n",
       "\n",
       "  param_solver                                             params  \\\n",
       "0        lbfgs  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "1         adam  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "\n",
       "   split0_test_neg_mean_squared_error  ...  split1_test_r2  split2_test_r2  \\\n",
       "0                          -32.059644  ...   -1.759096e-02       -0.077878   \n",
       "1                          -31.660795  ...   -6.940798e-07       -0.183036   \n",
       "\n",
       "   mean_test_r2  std_test_r2  rank_test_r2  split0_train_r2  split1_train_r2  \\\n",
       "0     -0.036539     0.029264            80    -1.300429e-07    -1.950328e-08   \n",
       "1     -0.061523     0.085925            97    -2.023084e-02    -2.524962e-02   \n",
       "\n",
       "   split2_train_r2  mean_train_r2  std_train_r2  \n",
       "0    -7.915540e-09  -5.248725e-08  5.504381e-08  \n",
       "1    -1.801163e-02  -2.116403e-02  3.027680e-03  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_activation', 'param_hidden_layer_sizes',\n",
       "       'param_learning_rate_init', 'param_solver', 'params',\n",
       "       'split0_test_neg_mean_squared_error',\n",
       "       'split1_test_neg_mean_squared_error',\n",
       "       'split2_test_neg_mean_squared_error',\n",
       "       'mean_test_neg_mean_squared_error', 'std_test_neg_mean_squared_error',\n",
       "       'rank_test_neg_mean_squared_error',\n",
       "       'split0_train_neg_mean_squared_error',\n",
       "       'split1_train_neg_mean_squared_error',\n",
       "       'split2_train_neg_mean_squared_error',\n",
       "       'mean_train_neg_mean_squared_error', 'std_train_neg_mean_squared_error',\n",
       "       'split0_test_r2', 'split1_test_r2', 'split2_test_r2', 'mean_test_r2',\n",
       "       'std_test_r2', 'rank_test_r2', 'split0_train_r2', 'split1_train_r2',\n",
       "       'split2_train_r2', 'mean_train_r2', 'std_train_r2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_models.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                                                    0.16659\n",
       "std_fit_time                                                                   0.0763769\n",
       "mean_score_time                                                               0.00323025\n",
       "std_score_time                                                                0.00317926\n",
       "param_activation                                                                    relu\n",
       "param_hidden_layer_sizes                                                               7\n",
       "param_learning_rate_init                                                             0.1\n",
       "param_solver                                                                       lbfgs\n",
       "params                                 {'activation': 'relu', 'hidden_layer_sizes': 7...\n",
       "split0_test_neg_mean_squared_error                                              -9.98572\n",
       "split1_test_neg_mean_squared_error                                              -7.60114\n",
       "split2_test_neg_mean_squared_error                                              -4.85687\n",
       "mean_test_neg_mean_squared_error                                                -7.48125\n",
       "std_test_neg_mean_squared_error                                                  2.09556\n",
       "rank_test_neg_mean_squared_error                                                       1\n",
       "split0_train_neg_mean_squared_error                                            -0.295724\n",
       "split1_train_neg_mean_squared_error                                              -1.8123\n",
       "split2_train_neg_mean_squared_error                                             -2.31303\n",
       "mean_train_neg_mean_squared_error                                               -1.47368\n",
       "std_train_neg_mean_squared_error                                                0.857662\n",
       "split0_test_r2                                                                  0.684119\n",
       "split1_test_r2                                                                  0.832633\n",
       "split2_test_r2                                                                  0.845076\n",
       "mean_test_r2                                                                    0.787276\n",
       "std_test_r2                                                                    0.0731195\n",
       "rank_test_r2                                                                           1\n",
       "split0_train_r2                                                                 0.992428\n",
       "split1_train_r2                                                                 0.943426\n",
       "split2_train_r2                                                                 0.939952\n",
       "mean_train_r2                                                                   0.958602\n",
       "std_train_r2                                                                   0.0239603\n",
       "Name: 90, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.loc[grid_models.best_index_,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of best model in data frame 90\n",
      "\n",
      "Best result of scoring parameters\n",
      "\n",
      "mean_train_neg_mean_squared_error   -1.47368\n",
      "mean_test_neg_mean_squared_error    -7.48125\n",
      "Name: 90, dtype: object \n",
      "\n",
      "mean_train_r2    0.958602\n",
      "mean_test_r2     0.787276\n",
      "Name: 90, dtype: object\n",
      "\n",
      "Note: Test result is on cross validation test rows\n"
     ]
    }
   ],
   "source": [
    "# Best result of scoring parameters\n",
    "print('index of best model in data frame', grid_models.best_index_)\n",
    "print('\\nBest result of scoring parameters\\n')\n",
    "print(cv_results.loc[grid_models.best_index_, \n",
    "                     ['mean_train_neg_mean_squared_error','mean_test_neg_mean_squared_error']],'\\n')\n",
    "print(cv_results.loc[grid_models.best_index_, \n",
    "                     ['mean_train_r2','mean_test_r2']])\n",
    "print('\\nNote: Test result is on cross validation test rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.34946705, 20.84060623, 26.96461804, 20.73011831, 18.47717302,\n",
       "       19.03385681, 14.38421352, 22.34521078, 23.94715686, 18.53838783,\n",
       "       18.87333782, 13.4535887 , 14.66054645, 14.72277177, 12.72599627,\n",
       "       11.80027882, 11.63238393, 29.77176693, 32.12241798, 31.78337639,\n",
       "       21.81134188, 16.74005556, 17.74725734, 14.12927304, 17.95338961,\n",
       "       30.17800082, 28.48378045, 29.89764245, 24.02655125, 19.1610249 ,\n",
       "       14.9857022 , 24.32073741])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_models.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_init_fn(n,low,high):\n",
    "    print(np.log10(low))\n",
    "    print(np.log10(high))\n",
    "    print(np.log10(high) - np.log10(low))\n",
    "    print(*np.random.sample(n))\n",
    "    print((np.log10(high) - np.log10(low))*np.random.sample(n))\n",
    "    print(np.log10(low)+(np.log10(high) - np.log10(low))*np.random.sample(n))\n",
    "    \n",
    "    return(10**(np.log10(low)+(np.log10(high) - np.log10(low))*np.random.sample(n)))\n",
    "\n",
    "def hidden_layer_fn(n_instance,n_layers,low,high,):\n",
    "    hid_layer_list = []\n",
    "    for i in range(n_instance):\n",
    "        hid_layer = []\n",
    "        for j in range(n_layers):\n",
    "            hid_layer.append(np.random.randint(low, high))\n",
    "        hid_layer_list.append(hid_layer)\n",
    "    return hid_layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0\n",
      "-1.0\n",
      "3.0\n",
      "0.8242275467544284 0.8948692698106464 0.7806560832302964 0.7202966647421338 0.6973579325314073 0.46283023317604854 0.13504097473397936 0.031029160895352348 0.1578341287842756 0.4764165680892759 0.05477676040726476 0.048908416149630596 0.03261199227399847 0.489169413854727 0.23434372107199708 0.385353794379822 0.5602753210292067 0.08005481341687115 0.9473046818342771 0.7395323489584626 0.34217111191777294 0.26762143433466046 0.8297042112974878 0.8692325701171996 0.2701956060630417\n",
      "[2.04610972 1.93053458 2.26550282 2.03497509 2.27094348 1.07079412\n",
      " 1.02633739 2.78242682 2.14941555 1.74289827 1.26491369 1.82431921\n",
      " 2.26179739 1.51822322 1.9746627  0.27036151 0.42330746 1.37744199\n",
      " 1.99989156 2.65406944 0.78394214 2.43220451 2.98098078 1.66281143\n",
      " 2.21523515]\n",
      "[-2.54473637 -1.49088734 -3.83271837 -2.71135391 -2.68533998 -2.8757275\n",
      " -3.06145852 -2.23530669 -2.29004101 -3.67176334 -2.38303507 -3.48778709\n",
      " -1.96787776 -2.22558661 -1.87822608 -2.75666793 -2.1212467  -3.00040583\n",
      " -2.458932   -3.704005   -3.23968022 -3.59384403 -1.99232791 -2.6508913\n",
      " -3.89093614]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# n_iter: The number of parameter settings that are tried\n",
    "\n",
    "solv = ['lbfgs','adam','sgd']\n",
    "act = ['logistic','tanh','relu']\n",
    "lr_init = lr_init_fn(25,0.0001,0.1)\n",
    "hidden_layer_sz = hidden_layer_fn(5,1,3,10)+hidden_layer_fn(4,2,3,10)+hidden_layer_fn(3,3,3,10)\n",
    "\n",
    "\n",
    "param_grid = {'solver': solv,\n",
    "              'activation': act,\n",
    "              'learning_rate_init': lr_init,\n",
    "              'hidden_layer_sizes': hidden_layer_sz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00043842, 0.0518229 , 0.00022166, 0.00670933, 0.01974964,\n",
       "       0.00081215, 0.04245316, 0.00052137, 0.0097197 , 0.00012665,\n",
       "       0.00900137, 0.0002778 , 0.00011307, 0.00014487, 0.00017283,\n",
       "       0.01224821, 0.0386499 , 0.01309838, 0.00104719, 0.0029726 ,\n",
       "       0.09206452, 0.00051526, 0.00013265, 0.00021981, 0.01362494])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8],\n",
       " [3],\n",
       " [6],\n",
       " [8],\n",
       " [4],\n",
       " [5, 4],\n",
       " [5, 7],\n",
       " [4, 9],\n",
       " [8, 7],\n",
       " [9, 7, 3],\n",
       " [4, 9, 5],\n",
       " [3, 6, 8]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(MLPRegressor(learning_rate = 'constant',\n",
    "                                                max_iter = 8000,\n",
    "                                                random_state=0),\n",
    "                           param_grid, cv=3, return_train_score=True,\n",
    "                           scoring = ['neg_mean_squared_error','r2'],\n",
    "                           n_iter = 30,\n",
    "                           refit = 'r2')\n",
    "\n",
    "random_models = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 31)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results for all the models, imported into dataframe\n",
    "cv_results = pd.DataFrame(random_models.cv_results_)\n",
    "cv_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_train_r2</th>\n",
       "      <th>split1_train_r2</th>\n",
       "      <th>split2_train_r2</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>4.702464e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000812151</td>\n",
       "      <td>[4]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.205968e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.758941e-02</td>\n",
       "      <td>-7.787305e-02</td>\n",
       "      <td>-3.653767e-02</td>\n",
       "      <td>2.926223e-02</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.699136e-10</td>\n",
       "      <td>-2.508683e-08</td>\n",
       "      <td>-3.106693e-11</td>\n",
       "      <td>-8.429269e-09</td>\n",
       "      <td>1.177881e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>4.693590e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000438419</td>\n",
       "      <td>[8]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0004...</td>\n",
       "      <td>-3.384653e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.958010e+01</td>\n",
       "      <td>-8.521310e+01</td>\n",
       "      <td>-8.695355e+01</td>\n",
       "      <td>1.494665e+01</td>\n",
       "      <td>29</td>\n",
       "      <td>-8.388615e+01</td>\n",
       "      <td>-9.553412e+01</td>\n",
       "      <td>-7.360857e+01</td>\n",
       "      <td>-8.434295e+01</td>\n",
       "      <td>8.956896e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.048415</td>\n",
       "      <td>1.913177</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>9.402684e-04</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000144872</td>\n",
       "      <td>[5, 4]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-1.889685e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.102564e-01</td>\n",
       "      <td>7.243084e-01</td>\n",
       "      <td>6.455989e-01</td>\n",
       "      <td>1.756273e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>8.754179e-01</td>\n",
       "      <td>7.968013e-01</td>\n",
       "      <td>7.669961e-01</td>\n",
       "      <td>8.130718e-01</td>\n",
       "      <td>4.573380e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017181</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>7.690395e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00900137</td>\n",
       "      <td>[9, 7, 3]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0090...</td>\n",
       "      <td>-4.035416e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621953e-01</td>\n",
       "      <td>-8.923214e-01</td>\n",
       "      <td>-4.436828e-01</td>\n",
       "      <td>3.206511e-01</td>\n",
       "      <td>25</td>\n",
       "      <td>-3.365537e-01</td>\n",
       "      <td>-4.063295e-01</td>\n",
       "      <td>-3.605242e-01</td>\n",
       "      <td>-3.678025e-01</td>\n",
       "      <td>2.894704e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.192254</td>\n",
       "      <td>0.029827</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>3.549814e-03</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000221655</td>\n",
       "      <td>[4]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>-3.218898e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.132567e-02</td>\n",
       "      <td>-6.914451e-02</td>\n",
       "      <td>-3.623705e-02</td>\n",
       "      <td>2.330314e-02</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.132454e-04</td>\n",
       "      <td>-2.572966e-04</td>\n",
       "      <td>-2.148882e-04</td>\n",
       "      <td>-2.284767e-04</td>\n",
       "      <td>2.038980e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>4.601874e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00900137</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.205957e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759256e-02</td>\n",
       "      <td>-7.787559e-02</td>\n",
       "      <td>-3.653849e-02</td>\n",
       "      <td>2.926356e-02</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.050156e-07</td>\n",
       "      <td>-9.650690e-08</td>\n",
       "      <td>-9.036938e-08</td>\n",
       "      <td>-9.729729e-08</td>\n",
       "      <td>6.005351e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.116542</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>8.142961e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000221655</td>\n",
       "      <td>[6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>-3.214129e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.995915e-02</td>\n",
       "      <td>-7.215323e-02</td>\n",
       "      <td>-3.628152e-02</td>\n",
       "      <td>2.539931e-02</td>\n",
       "      <td>12</td>\n",
       "      <td>-8.796650e-05</td>\n",
       "      <td>-1.065063e-04</td>\n",
       "      <td>-8.888816e-05</td>\n",
       "      <td>-9.445364e-05</td>\n",
       "      <td>8.530796e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.676124</td>\n",
       "      <td>0.522935</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>9.394814e-04</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000515265</td>\n",
       "      <td>[6]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-1.310749e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.807236e-01</td>\n",
       "      <td>6.439377e-01</td>\n",
       "      <td>6.700097e-01</td>\n",
       "      <td>8.185669e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>8.521717e-01</td>\n",
       "      <td>8.675629e-01</td>\n",
       "      <td>8.295143e-01</td>\n",
       "      <td>8.497496e-01</td>\n",
       "      <td>1.562741e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.392203</td>\n",
       "      <td>0.303768</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.362676e-06</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000172834</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-2.748034e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.805191e+00</td>\n",
       "      <td>-6.344480e+00</td>\n",
       "      <td>-6.280861e+00</td>\n",
       "      <td>1.179766e+00</td>\n",
       "      <td>27</td>\n",
       "      <td>-5.704516e+00</td>\n",
       "      <td>-6.013104e+00</td>\n",
       "      <td>-6.370682e+00</td>\n",
       "      <td>-6.029434e+00</td>\n",
       "      <td>2.722062e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>4.762555e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00013265</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.205959e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.758894e-02</td>\n",
       "      <td>-7.787395e-02</td>\n",
       "      <td>-3.653695e-02</td>\n",
       "      <td>2.926341e-02</td>\n",
       "      <td>15</td>\n",
       "      <td>-8.143042e-12</td>\n",
       "      <td>-9.851897e-12</td>\n",
       "      <td>-8.896661e-12</td>\n",
       "      <td>-8.963867e-12</td>\n",
       "      <td>6.992539e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.153572</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>6.270889e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00052137</td>\n",
       "      <td>[4, 9, 5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0005...</td>\n",
       "      <td>-3.207330e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.799153e-02</td>\n",
       "      <td>-7.696559e-02</td>\n",
       "      <td>-3.651284e-02</td>\n",
       "      <td>2.863827e-02</td>\n",
       "      <td>14</td>\n",
       "      <td>-2.654185e-06</td>\n",
       "      <td>-3.240850e-06</td>\n",
       "      <td>-2.174012e-06</td>\n",
       "      <td>-2.689682e-06</td>\n",
       "      <td>4.362574e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010964</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>4.708648e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00670933</td>\n",
       "      <td>[6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0067...</td>\n",
       "      <td>-3.418225e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.229238e-02</td>\n",
       "      <td>-4.933315e-01</td>\n",
       "      <td>-2.056394e-01</td>\n",
       "      <td>2.040512e-01</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.321593e-01</td>\n",
       "      <td>-1.622281e-01</td>\n",
       "      <td>-1.458400e-01</td>\n",
       "      <td>-1.467424e-01</td>\n",
       "      <td>1.229211e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.772509</td>\n",
       "      <td>0.947370</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>4.126471e-06</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000126645</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-3.205532e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.012203e+00</td>\n",
       "      <td>-7.673980e+00</td>\n",
       "      <td>-7.608770e+00</td>\n",
       "      <td>1.277802e+00</td>\n",
       "      <td>28</td>\n",
       "      <td>-6.827915e+00</td>\n",
       "      <td>-7.626603e+00</td>\n",
       "      <td>-7.566723e+00</td>\n",
       "      <td>-7.340414e+00</td>\n",
       "      <td>3.632149e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.350070</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>4.648953e-04</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00900137</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.009...</td>\n",
       "      <td>-3.219435e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.155573e-02</td>\n",
       "      <td>-6.845069e-02</td>\n",
       "      <td>-3.613909e-02</td>\n",
       "      <td>2.288380e-02</td>\n",
       "      <td>8</td>\n",
       "      <td>-2.269745e-04</td>\n",
       "      <td>-2.857935e-04</td>\n",
       "      <td>-2.473267e-04</td>\n",
       "      <td>-2.533649e-04</td>\n",
       "      <td>2.438939e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.446067</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>2.820860e-03</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000113065</td>\n",
       "      <td>[4, 9]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.087485e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.049642e+00</td>\n",
       "      <td>3.470097e-01</td>\n",
       "      <td>-8.931012e-01</td>\n",
       "      <td>1.530620e+00</td>\n",
       "      <td>26</td>\n",
       "      <td>8.524417e-01</td>\n",
       "      <td>9.526632e-01</td>\n",
       "      <td>9.490948e-01</td>\n",
       "      <td>9.180666e-01</td>\n",
       "      <td>4.642664e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.240349</td>\n",
       "      <td>0.323756</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>4.713723e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0130984</td>\n",
       "      <td>[8]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.01...</td>\n",
       "      <td>-3.381487e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.205049e-01</td>\n",
       "      <td>-5.532029e-01</td>\n",
       "      <td>-1.341236e-01</td>\n",
       "      <td>3.191357e-01</td>\n",
       "      <td>23</td>\n",
       "      <td>9.933669e-01</td>\n",
       "      <td>3.392703e-01</td>\n",
       "      <td>6.425775e-02</td>\n",
       "      <td>4.656316e-01</td>\n",
       "      <td>3.896891e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>9.397623e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000172834</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.205957e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759256e-02</td>\n",
       "      <td>-7.787559e-02</td>\n",
       "      <td>-3.653849e-02</td>\n",
       "      <td>2.926356e-02</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.050156e-07</td>\n",
       "      <td>-9.650690e-08</td>\n",
       "      <td>-9.036938e-08</td>\n",
       "      <td>-9.729729e-08</td>\n",
       "      <td>6.005351e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.251665</td>\n",
       "      <td>0.105856</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>4.700781e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0424532</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.04...</td>\n",
       "      <td>-2.501551e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.601620e-01</td>\n",
       "      <td>1.579322e-01</td>\n",
       "      <td>3.755911e-01</td>\n",
       "      <td>2.727208e-01</td>\n",
       "      <td>6</td>\n",
       "      <td>9.894676e-01</td>\n",
       "      <td>9.643864e-01</td>\n",
       "      <td>9.868323e-01</td>\n",
       "      <td>9.802288e-01</td>\n",
       "      <td>1.125378e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.698531e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000113065</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.205957e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759256e-02</td>\n",
       "      <td>-7.787559e-02</td>\n",
       "      <td>-3.653849e-02</td>\n",
       "      <td>2.926356e-02</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.050156e-07</td>\n",
       "      <td>-9.650690e-08</td>\n",
       "      <td>-9.036938e-08</td>\n",
       "      <td>-9.729729e-08</td>\n",
       "      <td>6.005351e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.596933</td>\n",
       "      <td>0.454646</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>1.264443e-05</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000172834</td>\n",
       "      <td>[8]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-3.702362e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.269587e-01</td>\n",
       "      <td>2.394752e-01</td>\n",
       "      <td>2.650859e-01</td>\n",
       "      <td>3.671089e-01</td>\n",
       "      <td>7</td>\n",
       "      <td>7.105126e-01</td>\n",
       "      <td>4.435408e-01</td>\n",
       "      <td>6.535900e-01</td>\n",
       "      <td>6.025478e-01</td>\n",
       "      <td>1.148114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.695725e-04</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000812151</td>\n",
       "      <td>[8]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.205957e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759256e-02</td>\n",
       "      <td>-7.787559e-02</td>\n",
       "      <td>-3.653849e-02</td>\n",
       "      <td>2.926356e-02</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.050156e-07</td>\n",
       "      <td>-9.650690e-08</td>\n",
       "      <td>-9.036938e-08</td>\n",
       "      <td>-9.729729e-08</td>\n",
       "      <td>6.005351e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.464618</td>\n",
       "      <td>1.370293</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>8.104673e-07</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00052137</td>\n",
       "      <td>[4, 9, 5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-3.580259e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.137429e-01</td>\n",
       "      <td>4.781150e-01</td>\n",
       "      <td>3.864356e-01</td>\n",
       "      <td>3.917243e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>9.875705e-01</td>\n",
       "      <td>9.450397e-01</td>\n",
       "      <td>9.999287e-01</td>\n",
       "      <td>9.775130e-01</td>\n",
       "      <td>2.350976e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.843465</td>\n",
       "      <td>0.898607</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>5.545802e-03</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00013265</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-1.874784e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.075988e-01</td>\n",
       "      <td>6.281501e-01</td>\n",
       "      <td>6.142315e-01</td>\n",
       "      <td>1.638618e-01</td>\n",
       "      <td>4</td>\n",
       "      <td>8.700657e-01</td>\n",
       "      <td>7.701361e-01</td>\n",
       "      <td>7.902548e-01</td>\n",
       "      <td>8.101522e-01</td>\n",
       "      <td>4.315408e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.222103</td>\n",
       "      <td>0.605734</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>8.387305e-06</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0136249</td>\n",
       "      <td>[6]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.013...</td>\n",
       "      <td>-3.225785e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.326859e-02</td>\n",
       "      <td>-6.484781e-02</td>\n",
       "      <td>-3.617857e-02</td>\n",
       "      <td>2.030556e-02</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.644726e-04</td>\n",
       "      <td>-5.625530e-04</td>\n",
       "      <td>-4.849422e-04</td>\n",
       "      <td>-5.039893e-04</td>\n",
       "      <td>4.224557e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.609463</td>\n",
       "      <td>0.025418</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.697970e-04</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0029726</td>\n",
       "      <td>[4]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.002...</td>\n",
       "      <td>-3.235734e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.607664e-02</td>\n",
       "      <td>-5.963431e-02</td>\n",
       "      <td>-3.642584e-02</td>\n",
       "      <td>1.644283e-02</td>\n",
       "      <td>13</td>\n",
       "      <td>-9.677787e-04</td>\n",
       "      <td>-1.181013e-03</td>\n",
       "      <td>-9.893780e-04</td>\n",
       "      <td>-1.046057e-03</td>\n",
       "      <td>9.583518e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.450720</td>\n",
       "      <td>0.140142</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>1.695950e-03</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000219807</td>\n",
       "      <td>[9, 7, 3]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>-3.218986e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.135014e-02</td>\n",
       "      <td>-6.904925e-02</td>\n",
       "      <td>-3.622269e-02</td>\n",
       "      <td>2.324595e-02</td>\n",
       "      <td>10</td>\n",
       "      <td>-2.153159e-04</td>\n",
       "      <td>-2.604060e-04</td>\n",
       "      <td>-2.186549e-04</td>\n",
       "      <td>-2.314589e-04</td>\n",
       "      <td>2.051401e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.031112</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>4.704714e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0386499</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0386...</td>\n",
       "      <td>-3.205505e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.745561e-02</td>\n",
       "      <td>-7.822818e-02</td>\n",
       "      <td>-3.656264e-02</td>\n",
       "      <td>2.949566e-02</td>\n",
       "      <td>21</td>\n",
       "      <td>-2.943127e-07</td>\n",
       "      <td>-3.558005e-07</td>\n",
       "      <td>-3.236948e-07</td>\n",
       "      <td>-3.246027e-07</td>\n",
       "      <td>2.511049e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.036244</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>5.850231e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0130984</td>\n",
       "      <td>[4, 9, 5]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0130...</td>\n",
       "      <td>-3.180221e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.788956e-03</td>\n",
       "      <td>-1.073677e-01</td>\n",
       "      <td>-4.105428e-02</td>\n",
       "      <td>4.691610e-02</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.390242e-03</td>\n",
       "      <td>-1.608337e-03</td>\n",
       "      <td>-1.922935e-03</td>\n",
       "      <td>-1.640505e-03</td>\n",
       "      <td>2.186573e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.888118</td>\n",
       "      <td>1.134072</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>4.697972e-04</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00013265</td>\n",
       "      <td>[5, 4]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-1.915328e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.987765e-01</td>\n",
       "      <td>7.086711e-01</td>\n",
       "      <td>6.338560e-01</td>\n",
       "      <td>1.734640e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>8.676758e-01</td>\n",
       "      <td>7.747964e-01</td>\n",
       "      <td>7.540785e-01</td>\n",
       "      <td>7.988502e-01</td>\n",
       "      <td>4.939653e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>6.768804e-04</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0130984</td>\n",
       "      <td>[8]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0130...</td>\n",
       "      <td>-3.408792e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.748218e+09</td>\n",
       "      <td>-8.205404e+09</td>\n",
       "      <td>-8.578909e+09</td>\n",
       "      <td>1.668274e+09</td>\n",
       "      <td>30</td>\n",
       "      <td>-8.728522e+09</td>\n",
       "      <td>-9.567132e+09</td>\n",
       "      <td>-6.678142e+09</td>\n",
       "      <td>-8.324599e+09</td>\n",
       "      <td>1.213516e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_solver  \\\n",
       "0        0.013145      0.010160         0.001331    4.702464e-04        lbfgs   \n",
       "1        0.012300      0.006163         0.001661    4.693590e-04          sgd   \n",
       "2        7.048415      1.913177         0.001664    9.402684e-04         adam   \n",
       "3        0.017181      0.006679         0.001540    7.690395e-04          sgd   \n",
       "4        0.192254      0.029827         0.004987    3.549814e-03          sgd   \n",
       "5        0.005659      0.001234         0.001323    4.601874e-04        lbfgs   \n",
       "6        0.116542      0.016160         0.001994    8.142961e-04          sgd   \n",
       "7        4.676124      0.522935         0.003656    9.394814e-04         adam   \n",
       "8        3.392203      0.303768         0.001995    1.362676e-06         adam   \n",
       "9        0.007983      0.002154         0.001671    4.762555e-04        lbfgs   \n",
       "10       0.153572      0.012231         0.002437    6.270889e-04          sgd   \n",
       "11       0.010964      0.002825         0.002326    4.708648e-04          sgd   \n",
       "12       3.772509      0.947370         0.001995    4.126471e-06         adam   \n",
       "13       0.350070      0.029216         0.002335    4.648953e-04         adam   \n",
       "14       0.446067      0.366413         0.003990    2.820860e-03        lbfgs   \n",
       "15       0.240349      0.323756         0.001663    4.713723e-04        lbfgs   \n",
       "16       0.006649      0.001243         0.002660    9.397623e-04        lbfgs   \n",
       "17       0.251665      0.105856         0.001663    4.700781e-04        lbfgs   \n",
       "18       0.005041      0.000749         0.001330    4.698531e-04        lbfgs   \n",
       "19       3.596933      0.454646         0.000988    1.264443e-05         adam   \n",
       "20       0.004986      0.000815         0.001330    4.695725e-04        lbfgs   \n",
       "21       1.464618      1.370293         0.001996    8.104673e-07        lbfgs   \n",
       "22       4.843465      0.898607         0.007316    5.545802e-03         adam   \n",
       "23       1.222103      0.605734         0.002001    8.387305e-06         adam   \n",
       "24       1.609463      0.025418         0.001330    4.697970e-04         adam   \n",
       "25       0.450720      0.140142         0.002661    1.695950e-03          sgd   \n",
       "26       0.031112      0.003201         0.002327    4.704714e-04          sgd   \n",
       "27       0.036244      0.008469         0.003788    5.850231e-04          sgd   \n",
       "28       5.888118      1.134072         0.002327    4.697972e-04         adam   \n",
       "29       0.009972      0.001629         0.001879    6.768804e-04          sgd   \n",
       "\n",
       "   param_learning_rate_init param_hidden_layer_sizes param_activation  \\\n",
       "0               0.000812151                      [4]         logistic   \n",
       "1               0.000438419                      [8]             relu   \n",
       "2               0.000144872                   [5, 4]             relu   \n",
       "3                0.00900137                [9, 7, 3]             tanh   \n",
       "4               0.000221655                      [4]         logistic   \n",
       "5                0.00900137                      [8]         logistic   \n",
       "6               0.000221655                      [6]             tanh   \n",
       "7               0.000515265                      [6]             relu   \n",
       "8               0.000172834                      [8]         logistic   \n",
       "9                0.00013265                   [5, 7]             tanh   \n",
       "10               0.00052137                [4, 9, 5]             tanh   \n",
       "11               0.00670933                      [6]             tanh   \n",
       "12              0.000126645                      [8]         logistic   \n",
       "13               0.00900137                      [8]         logistic   \n",
       "14              0.000113065                   [4, 9]             relu   \n",
       "15                0.0130984                      [8]             tanh   \n",
       "16              0.000172834                      [8]         logistic   \n",
       "17                0.0424532                   [5, 7]             relu   \n",
       "18              0.000113065                      [8]         logistic   \n",
       "19              0.000172834                      [8]             relu   \n",
       "20              0.000812151                      [8]         logistic   \n",
       "21               0.00052137                [4, 9, 5]             relu   \n",
       "22               0.00013265                   [5, 7]             relu   \n",
       "23                0.0136249                      [6]         logistic   \n",
       "24                0.0029726                      [4]         logistic   \n",
       "25              0.000219807                [9, 7, 3]         logistic   \n",
       "26                0.0386499                   [5, 7]             tanh   \n",
       "27                0.0130984                [4, 9, 5]         logistic   \n",
       "28               0.00013265                   [5, 4]             relu   \n",
       "29                0.0130984                      [8]             relu   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "1   {'solver': 'sgd', 'learning_rate_init': 0.0004...   \n",
       "2   {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "3   {'solver': 'sgd', 'learning_rate_init': 0.0090...   \n",
       "4   {'solver': 'sgd', 'learning_rate_init': 0.0002...   \n",
       "5   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "6   {'solver': 'sgd', 'learning_rate_init': 0.0002...   \n",
       "7   {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "8   {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "9   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "10  {'solver': 'sgd', 'learning_rate_init': 0.0005...   \n",
       "11  {'solver': 'sgd', 'learning_rate_init': 0.0067...   \n",
       "12  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "13  {'solver': 'adam', 'learning_rate_init': 0.009...   \n",
       "14  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "15  {'solver': 'lbfgs', 'learning_rate_init': 0.01...   \n",
       "16  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "17  {'solver': 'lbfgs', 'learning_rate_init': 0.04...   \n",
       "18  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "19  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "20  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "21  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "22  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "23  {'solver': 'adam', 'learning_rate_init': 0.013...   \n",
       "24  {'solver': 'adam', 'learning_rate_init': 0.002...   \n",
       "25  {'solver': 'sgd', 'learning_rate_init': 0.0002...   \n",
       "26  {'solver': 'sgd', 'learning_rate_init': 0.0386...   \n",
       "27  {'solver': 'sgd', 'learning_rate_init': 0.0130...   \n",
       "28  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "29  {'solver': 'sgd', 'learning_rate_init': 0.0130...   \n",
       "\n",
       "    split0_test_neg_mean_squared_error  ...  split1_test_r2  split2_test_r2  \\\n",
       "0                        -3.205968e+01  ...   -1.758941e-02   -7.787305e-02   \n",
       "1                        -3.384653e+03  ...   -6.958010e+01   -8.521310e+01   \n",
       "2                        -1.889685e+01  ...    8.102564e-01    7.243084e-01   \n",
       "3                        -4.035416e+01  ...   -1.621953e-01   -8.923214e-01   \n",
       "4                        -3.218898e+01  ...   -2.132567e-02   -6.914451e-02   \n",
       "5                        -3.205957e+01  ...   -1.759256e-02   -7.787559e-02   \n",
       "6                        -3.214129e+01  ...   -1.995915e-02   -7.215323e-02   \n",
       "7                        -1.310749e+01  ...    7.807236e-01    6.439377e-01   \n",
       "8                        -2.748034e+02  ...   -4.805191e+00   -6.344480e+00   \n",
       "9                        -3.205959e+01  ...   -1.758894e-02   -7.787395e-02   \n",
       "10                       -3.207330e+01  ...   -1.799153e-02   -7.696559e-02   \n",
       "11                       -3.418225e+01  ...   -4.229238e-02   -4.933315e-01   \n",
       "12                       -3.205532e+02  ...   -6.012203e+00   -7.673980e+00   \n",
       "13                       -3.219435e+01  ...   -2.155573e-02   -6.845069e-02   \n",
       "14                       -3.087485e+01  ...   -3.049642e+00    3.470097e-01   \n",
       "15                       -3.381487e+01  ...    2.205049e-01   -5.532029e-01   \n",
       "16                       -3.205957e+01  ...   -1.759256e-02   -7.787559e-02   \n",
       "17                       -2.501551e+01  ...    7.601620e-01    1.579322e-01   \n",
       "18                       -3.205957e+01  ...   -1.759256e-02   -7.787559e-02   \n",
       "19                       -3.702362e+01  ...    7.269587e-01    2.394752e-01   \n",
       "20                       -3.205957e+01  ...   -1.759256e-02   -7.787559e-02   \n",
       "21                       -3.580259e+01  ...    8.137429e-01    4.781150e-01   \n",
       "22                       -1.874784e+01  ...    8.075988e-01    6.281501e-01   \n",
       "23                       -3.225785e+01  ...   -2.326859e-02   -6.484781e-02   \n",
       "24                       -3.235734e+01  ...   -2.607664e-02   -5.963431e-02   \n",
       "25                       -3.218986e+01  ...   -2.135014e-02   -6.904925e-02   \n",
       "26                       -3.205505e+01  ...   -1.745561e-02   -7.822818e-02   \n",
       "27                       -3.180221e+01  ...   -9.788956e-03   -1.073677e-01   \n",
       "28                       -1.915328e+01  ...    7.987765e-01    7.086711e-01   \n",
       "29                       -3.408792e+11  ...   -6.748218e+09   -8.205404e+09   \n",
       "\n",
       "    mean_test_r2   std_test_r2  rank_test_r2  split0_train_r2  \\\n",
       "0  -3.653767e-02  2.926223e-02            16    -1.699136e-10   \n",
       "1  -8.695355e+01  1.494665e+01            29    -8.388615e+01   \n",
       "2   6.455989e-01  1.756273e-01             2     8.754179e-01   \n",
       "3  -4.436828e-01  3.206511e-01            25    -3.365537e-01   \n",
       "4  -3.623705e-02  2.330314e-02            11    -2.132454e-04   \n",
       "5  -3.653849e-02  2.926356e-02            17    -1.050156e-07   \n",
       "6  -3.628152e-02  2.539931e-02            12    -8.796650e-05   \n",
       "7   6.700097e-01  8.185669e-02             1     8.521717e-01   \n",
       "8  -6.280861e+00  1.179766e+00            27    -5.704516e+00   \n",
       "9  -3.653695e-02  2.926341e-02            15    -8.143042e-12   \n",
       "10 -3.651284e-02  2.863827e-02            14    -2.654185e-06   \n",
       "11 -2.056394e-01  2.040512e-01            24    -1.321593e-01   \n",
       "12 -7.608770e+00  1.277802e+00            28    -6.827915e+00   \n",
       "13 -3.613909e-02  2.288380e-02             8    -2.269745e-04   \n",
       "14 -8.931012e-01  1.530620e+00            26     8.524417e-01   \n",
       "15 -1.341236e-01  3.191357e-01            23     9.933669e-01   \n",
       "16 -3.653849e-02  2.926356e-02            17    -1.050156e-07   \n",
       "17  3.755911e-01  2.727208e-01             6     9.894676e-01   \n",
       "18 -3.653849e-02  2.926356e-02            17    -1.050156e-07   \n",
       "19  2.650859e-01  3.671089e-01             7     7.105126e-01   \n",
       "20 -3.653849e-02  2.926356e-02            17    -1.050156e-07   \n",
       "21  3.864356e-01  3.917243e-01             5     9.875705e-01   \n",
       "22  6.142315e-01  1.638618e-01             4     8.700657e-01   \n",
       "23 -3.617857e-02  2.030556e-02             9    -4.644726e-04   \n",
       "24 -3.642584e-02  1.644283e-02            13    -9.677787e-04   \n",
       "25 -3.622269e-02  2.324595e-02            10    -2.153159e-04   \n",
       "26 -3.656264e-02  2.949566e-02            21    -2.943127e-07   \n",
       "27 -4.105428e-02  4.691610e-02            22    -1.390242e-03   \n",
       "28  6.338560e-01  1.734640e-01             3     8.676758e-01   \n",
       "29 -8.578909e+09  1.668274e+09            30    -8.728522e+09   \n",
       "\n",
       "    split1_train_r2  split2_train_r2  mean_train_r2  std_train_r2  \n",
       "0     -2.508683e-08    -3.106693e-11  -8.429269e-09  1.177881e-08  \n",
       "1     -9.553412e+01    -7.360857e+01  -8.434295e+01  8.956896e+00  \n",
       "2      7.968013e-01     7.669961e-01   8.130718e-01  4.573380e-02  \n",
       "3     -4.063295e-01    -3.605242e-01  -3.678025e-01  2.894704e-02  \n",
       "4     -2.572966e-04    -2.148882e-04  -2.284767e-04  2.038980e-05  \n",
       "5     -9.650690e-08    -9.036938e-08  -9.729729e-08  6.005351e-09  \n",
       "6     -1.065063e-04    -8.888816e-05  -9.445364e-05  8.530796e-06  \n",
       "7      8.675629e-01     8.295143e-01   8.497496e-01  1.562741e-02  \n",
       "8     -6.013104e+00    -6.370682e+00  -6.029434e+00  2.722062e-01  \n",
       "9     -9.851897e-12    -8.896661e-12  -8.963867e-12  6.992539e-13  \n",
       "10    -3.240850e-06    -2.174012e-06  -2.689682e-06  4.362574e-07  \n",
       "11    -1.622281e-01    -1.458400e-01  -1.467424e-01  1.229211e-02  \n",
       "12    -7.626603e+00    -7.566723e+00  -7.340414e+00  3.632149e-01  \n",
       "13    -2.857935e-04    -2.473267e-04  -2.533649e-04  2.438939e-05  \n",
       "14     9.526632e-01     9.490948e-01   9.180666e-01  4.642664e-02  \n",
       "15     3.392703e-01     6.425775e-02   4.656316e-01  3.896891e-01  \n",
       "16    -9.650690e-08    -9.036938e-08  -9.729729e-08  6.005351e-09  \n",
       "17     9.643864e-01     9.868323e-01   9.802288e-01  1.125378e-02  \n",
       "18    -9.650690e-08    -9.036938e-08  -9.729729e-08  6.005351e-09  \n",
       "19     4.435408e-01     6.535900e-01   6.025478e-01  1.148114e-01  \n",
       "20    -9.650690e-08    -9.036938e-08  -9.729729e-08  6.005351e-09  \n",
       "21     9.450397e-01     9.999287e-01   9.775130e-01  2.350976e-02  \n",
       "22     7.701361e-01     7.902548e-01   8.101522e-01  4.315408e-02  \n",
       "23    -5.625530e-04    -4.849422e-04  -5.039893e-04  4.224557e-05  \n",
       "24    -1.181013e-03    -9.893780e-04  -1.046057e-03  9.583518e-05  \n",
       "25    -2.604060e-04    -2.186549e-04  -2.314589e-04  2.051401e-05  \n",
       "26    -3.558005e-07    -3.236948e-07  -3.246027e-07  2.511049e-08  \n",
       "27    -1.608337e-03    -1.922935e-03  -1.640505e-03  2.186573e-04  \n",
       "28     7.747964e-01     7.540785e-01   7.988502e-01  4.939653e-02  \n",
       "29    -9.567132e+09    -6.678142e+09  -8.324599e+09  1.213516e+09  \n",
       "\n",
       "[30 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       " 'r2': make_scorer(r2_score)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of best model in data frame 7\n",
      "\n",
      "Best result of scoring parameters\n",
      "\n",
      "mean_train_neg_mean_squared_error   -5.52761\n",
      "mean_test_neg_mean_squared_error    -11.4096\n",
      "Name: 7, dtype: object \n",
      "\n",
      "mean_train_r2    0.84975\n",
      "mean_test_r2     0.67001\n",
      "Name: 7, dtype: object\n",
      "\n",
      "Note: Test result is on cross validation test rows\n"
     ]
    }
   ],
   "source": [
    "# Best result of scoring parameters\n",
    "print('index of best model in data frame', random_models.best_index_)\n",
    "print('\\nBest result of scoring parameters\\n')\n",
    "print(cv_results.loc[random_models.best_index_, \n",
    "                     ['mean_train_neg_mean_squared_error','mean_test_neg_mean_squared_error']],'\\n')\n",
    "print(cv_results.loc[random_models.best_index_, \n",
    "                     ['mean_train_r2','mean_test_r2']])\n",
    "print('\\nNote: Test result is on cross validation test rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'adam',\n",
       " 'learning_rate_init': 0.0005152646350460735,\n",
       " 'hidden_layer_sizes': [6],\n",
       " 'activation': 'relu'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=[6], learning_rate='constant',\n",
       "             learning_rate_init=0.0005152646350460735, max_fun=15000,\n",
       "             max_iter=8000, momentum=0.9, n_iter_no_change=10,\n",
       "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700097360717635"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461420879445843"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5907545667387005"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.95274656, 22.1977531 , 27.36383007, 21.23750922, 16.11640121,\n",
       "       21.40243843, 12.67779905, 24.35991245, 25.67408544, 20.91351916,\n",
       "       21.27695953, 15.2081594 , 15.45491215, 15.67873427, 13.99235523,\n",
       "       13.68451927, 13.36316612, 28.65446742, 28.67978029, 29.19053117,\n",
       "       22.56958834, 16.10869864, 16.7427574 , 12.78093561, 15.95421362,\n",
       "       28.40734335, 26.44685964, 27.49296062, 19.93886972, 20.43415503,\n",
       "       15.11571958, 26.44968739])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_models.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-JUN-13TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           1           5.1          3.5           1.4          0.2  setosa\n",
       "1           2           4.9          3.0           1.4          0.2  setosa\n",
       "2           3           4.7          3.2           1.3          0.2  setosa\n",
       "3           4           4.6          3.1           1.5          0.2  setosa\n",
       "4           5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv(\"C:/Users/Admin/Documents/Datasets/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "iris.Species = iris.Species.astype(\"category\")\n",
    "iris[\"Species1\"] = np.repeat([0, 1, 2], 50) # for first 50 observations = 0; for next 50 = 1; for last 50 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>Species1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species  \\\n",
       "0           1           5.1          3.5           1.4          0.2  setosa   \n",
       "1           2           4.9          3.0           1.4          0.2  setosa   \n",
       "2           3           4.7          3.2           1.3          0.2  setosa   \n",
       "3           4           4.6          3.1           1.5          0.2  setosa   \n",
       "4           5           5.0          3.6           1.4          0.2  setosa   \n",
       "\n",
       "   Species1  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is built in Python and on top of TensorFlow 2.0\n",
    "# Keras is a neural network library while \n",
    "# TensorFlow is the open source library for a number of tasks in machine learning.\n",
    "# Both frameworks provide high-level APIs for building and training models with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length\n",
      "0           1           5.1          3.5           1.4\n",
      "1           2           4.9          3.0           1.4\n",
      "2           3           4.7          3.2           1.3\n",
      "3           4           4.6          3.1           1.5\n",
      "4           5           5.0          3.6           1.4\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Species1, dtype: int32\n",
      "2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: Species1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = iris.iloc[:, :4]\n",
    "y = iris.iloc[:, -1]\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  0  0\n",
       "1  1  0  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n",
      "(112, 3)\n",
      "(38, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2\n",
       "114  0  0  1\n",
       "62   0  1  0\n",
       "33   1  0  0\n",
       "107  0  0  1\n",
       "7    1  0  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating MLP in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Creating MLP in Keras\n",
    "# Sequential function groups a linear stack of layers into a keras model\n",
    "# Sequential model provides trainging and inference faetures on this model\n",
    "from keras.models import Sequential\n",
    "# A dense layer is just a regular layer of neurons in a neural network.\n",
    "# Each neuron recieves input from all the neurons in previous layer, thus densely connected.\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In first Dense layer, the dimension of input layer can be given\n",
    "# tensorflow:Large dropout rate: 0.8 (>0.5). \n",
    "# In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. \n",
    "# Please ensure that this is intended.\n",
    "model.add(Dense(6, input_dim=4, activation=\"sigmoid\", name=\"HL1\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='relu', name=\"HL2\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax', name=\"OL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'HL1/kernel:0' shape=(4, 6) dtype=float32, numpy=\n",
      "array([[-0.5099182 , -0.2782163 , -0.65879977,  0.7546493 ,  0.13363522,\n",
      "         0.44102728],\n",
      "       [-0.25273234,  0.14513183,  0.65977967,  0.03207397, -0.5549391 ,\n",
      "         0.24491847],\n",
      "       [ 0.10666811, -0.41944233,  0.08610916, -0.7293204 ,  0.36204982,\n",
      "        -0.19563907],\n",
      "       [-0.2670682 , -0.3420073 , -0.65178823,  0.08388233, -0.07693177,\n",
      "         0.48077726]], dtype=float32)>, <tf.Variable 'HL1/bias:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'HL2/kernel:0' shape=(6, 6) dtype=float32, numpy=\n",
      "array([[ 0.706804  , -0.35974544, -0.5136436 ,  0.1287576 , -0.44010514,\n",
      "        -0.0410679 ],\n",
      "       [-0.04632443, -0.41179004, -0.6690682 ,  0.46490806,  0.10290724,\n",
      "         0.06633288],\n",
      "       [ 0.25210595, -0.54829156, -0.16876441, -0.14744216, -0.22779915,\n",
      "        -0.202052  ],\n",
      "       [-0.17427689, -0.24586567,  0.16396457,  0.06138134, -0.18202835,\n",
      "         0.07029688],\n",
      "       [ 0.00379658, -0.10989285, -0.3739882 , -0.22034305,  0.3850239 ,\n",
      "        -0.0157181 ],\n",
      "       [-0.44093695,  0.5356367 ,  0.12334478,  0.654975  , -0.32051548,\n",
      "         0.01303786]], dtype=float32)>, <tf.Variable 'HL2/bias:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'OL/kernel:0' shape=(6, 3) dtype=float32, numpy=\n",
      "array([[-0.7107242 ,  0.0552246 , -0.17706549],\n",
      "       [ 0.19025385,  0.6914849 , -0.3558141 ],\n",
      "       [ 0.6038555 ,  0.7090465 ,  0.5367    ],\n",
      "       [ 0.61288714,  0.24995053, -0.52709794],\n",
      "       [-0.764254  , -0.4655354 , -0.55951524],\n",
      "       [ 0.20460904, -0.40382332,  0.23734832]], dtype=float32)>, <tf.Variable 'OL/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# initialized weights\n",
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape: (None, 4)\n",
      "Output layer shape: (None, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input layer shape:\", model.input_shape)\n",
    "print(\"Output layer shape:\", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "from keras import metrics\n",
    "from keras.metrics import Precision, AUC, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length\n",
       "61           62           5.9          3.0           4.2\n",
       "92           93           5.8          2.6           4.0\n",
       "112         113           6.8          3.0           5.5\n",
       "2             3           4.7          3.2           1.3\n",
       "141         142           6.9          3.1           5.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "X_train = normalize(np.array(X_train), axis=1)\n",
    "X_test = normalize(np.array(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9921016 , 0.09440967, 0.04800492, 0.06720688],\n",
       "       [0.99675537, 0.06216324, 0.02786628, 0.0428712 ],\n",
       "       [0.99666916, 0.05997655, 0.02646024, 0.04851045],\n",
       "       [0.45738935, 0.71657665, 0.48788198, 0.19820205],\n",
       "       [0.99794254, 0.04849157, 0.02178607, 0.0358416 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling a simple model without customizing the optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Compile defines the loss function, the optimizer and the metrics\n",
    "# You need a compiled model to train because training uses the loss function and the optimizer\n",
    "\n",
    "# optimizer - name of optimizer or optimizer instance:'SGD','RMSprop','Adam'\n",
    "\n",
    "# loss - name of objective function or objective function or `Loss` instance:\n",
    "# Classification - binary_crossentropy, categorical_crossentropy\n",
    "# Regression - mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# metrics - List of metrics to be evaluated by the model during training and testing\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining optimizers with learning_rate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can separately define optimizers\n",
    "opt_SGD = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, name=\"SGD\")\n",
    "# rho is beta of RMSprop\n",
    "opt_RMSprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, \n",
    "                                          epsilon=1e-07, name=\"RMSprop\")\n",
    "opt_Adam = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, \n",
    "                                    epsilon=1e-07, name=\"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Learning rate schedules -- going to use after defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify learning rate schedules\n",
    "# a)exponential decay schedule\n",
    "# initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "# If staircase = True then (step / decay_steps) will be integer\n",
    "initial_learning_rate = 0.1\n",
    "lr_schedule1 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate,\n",
    "                decay_steps=100000,\n",
    "                decay_rate=0.96,\n",
    "                staircase=True)\n",
    "\n",
    "# b) Polynomial Decay\n",
    "# (initial_learning_rate - end_learning_rate)*(1 - step/decay_steps)^(power) + end_learning_rate\n",
    "\n",
    "starter_learning_rate = 0.1\n",
    "end_learning_rate = 0.01\n",
    "decay_steps = 10000\n",
    "lr_schedule2 = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "                starter_learning_rate,\n",
    "                decay_steps,\n",
    "                end_learning_rate,\n",
    "                power=0.5)\n",
    "\n",
    "# c)Inverse Time Decay\n",
    "# initial_learning_rate / (1 + decay_rate * step / decay_step)\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "decay_steps = 1.0\n",
    "decay_rate = 0.5\n",
    "lr_schedule3 = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                  initial_learning_rate, \n",
    "                  decay_steps, \n",
    "                  decay_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Optimizers with learning rate schedules instead of just learning_rate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can separately define optimizers with learning rate schedule defined\n",
    "opt_SGD1 = tf.keras.optimizers.SGD(learning_rate=lr_schedule1, momentum=0.9, name=\"SGD\")\n",
    "# rho is beta of RMSprop\n",
    "opt_RMSprop1 = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule2, rho=0.9, momentum=0.9, \n",
    "                                          epsilon=1e-07, name=\"RMSprop\")\n",
    "opt_Adam1 = tf.keras.optimizers.Adam(learning_rate=lr_schedule3, beta_1=0.9, beta_2=0.999, \n",
    "                                    epsilon=1e-07, name=\"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model using defined customized optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model with with defined optimizers\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt_SGD1,\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: model has not seen the test set anywhere.. we will fit it on training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# 1 eopch = 1 passs through the entire training set\n",
    "# batch_size - for mini-batch gradient descent\n",
    "# validation_split: Fraction of the training data to be used as validation data.\n",
    "# The model will set apart this fraction of the training data, will not train on it, \n",
    "# and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
    "\n",
    "keras_do_model= model.fit(X_train, y_train, \n",
    "                          epochs=500, batch_size = 20, \n",
    "                          validation_split = 0.2, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31332493 0.26344475 0.42323038]\n",
      " [0.31332493 0.26344475 0.42323038]\n",
      " [0.31332493 0.26344475 0.42323038]\n",
      " [0.31332493 0.26344475 0.42323038]\n",
      " [0.31332493 0.26344475 0.42323038]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 89us/step\n",
      "Training Metrics: \n",
      "  accuracy 0.3660714328289032 \n",
      "  auc_4 0.5248908400535583 \n",
      "  precision_4 0.0 \n",
      "  recall_4 0.0 \n",
      " \n",
      "38/38 [==============================] - 0s 131us/step\n",
      "Test Metrics: \n",
      "  accuracy 0.2368421107530594 \n",
      "  auc_4 0.5248249173164368 \n",
      "  precision_4 0.0 \n",
      "  recall_4 0.0 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "print(\"Training Metrics: \\n \", model.metrics_names[1], scores_train[1], \"\\n \",\n",
    "      model.metrics_names[2], scores_train[2], \"\\n \",\n",
    "      model.metrics_names[3], scores_train[3], \"\\n \",\n",
    "      model.metrics_names[4], scores_train[4], \"\\n \")\n",
    "scores_test = model.evaluate(X_test, y_test)\n",
    "print(\"Test Metrics: \\n \", model.metrics_names[1], scores_test[1], \"\\n \",\n",
    "      model.metrics_names[2], scores_test[2], \"\\n \",\n",
    "      model.metrics_names[3], scores_test[3], \"\\n \",\n",
    "      model.metrics_names[4], scores_test[4], \"\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "HL1 (Dense)                  (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "HL2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "OL (Dense)                   (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Note that the Input Layer is not displayed as part of model layers, since it isn't a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is output shape = (None, 6) in above summary?? i.e. why None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz\n",
    "ann_viz(model, title=\"Shallow Neural Network\", view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization\n",
    "# add to dense layer: \n",
    "# for L2 regularization: kernel_regularizer=tf.keras.regularizers.l2(l=0.1)\n",
    "# for L1 regularization: kernel_regularizer=tf.keras.regularizers.l1(l=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1. Batch Regularize??\n",
    "# 2. l=0.1 in both --> l=1 in both layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6c9ba74b9faa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model.add(Dense(6, input_dim=4, activation='sigmoid',\n\u001b[0;32m      3\u001b[0m                 kernel_regularizer=tf.keras.regularizers.l2(l=0.1),name=\"HL1\"))\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.add(Dense(6, activation='relu', \n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=4, activation='sigmoid',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.1),name=\"HL1\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='relu', \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.1), name=\"HL2\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax', name=\"OL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_do_reg_model= model.fit(X_train, y_train, \n",
    "                          epochs=500, batch_size = 20, \n",
    "                          validation_split = 0.1, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 189us/step\n",
      "Training Metrics: \n",
      "  accuracy 0.3660714328289032 \n",
      "  auc_5 0.5279216766357422 \n",
      "  precision_5 0.26966291666030884 \n",
      "  recall_5 0.0004279906861484051 \n",
      " \n",
      "38/38 [==============================] - 0s 131us/step\n",
      "Test Metrics: \n",
      "  accuracy 0.2368421107530594 \n",
      "  auc_5 0.5278059244155884 \n",
      "  precision_5 0.26966291666030884 \n",
      "  recall_5 0.00042744935490190983 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "print(\"Training Metrics: \\n \", model.metrics_names[1], scores_train[1], \"\\n \",\n",
    "      model.metrics_names[2], scores_train[2], \"\\n \",\n",
    "      model.metrics_names[3], scores_train[3], \"\\n \",\n",
    "      model.metrics_names[4], scores_train[4], \"\\n \")\n",
    "scores_test = model.evaluate(X_test, y_test)\n",
    "print(\"Test Metrics: \\n \", model.metrics_names[1], scores_test[1], \"\\n \",\n",
    "      model.metrics_names[2], scores_test[2], \"\\n \",\n",
    "      model.metrics_names[3], scores_test[3], \"\\n \",\n",
    "      model.metrics_names[4], scores_test[4], \"\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "HL1 (Dense)                  (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "HL2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "OL (Dense)                   (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(model, title=\"Shallow Neural Network\", view = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainable = True: the variables will be marked as trainable\n",
    "batch_norm = tf.keras.layers.BatchNormalization(\n",
    "                axis=1,\n",
    "                momentum=0.99,\n",
    "                epsilon=0.001,\n",
    "                center=True,\n",
    "                scale=True,\n",
    "                beta_initializer=\"zeros\",\n",
    "                gamma_initializer=\"ones\",\n",
    "                moving_mean_initializer=\"zeros\",\n",
    "                moving_variance_initializer=\"ones\",\n",
    "                trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=4, activation='sigmoid',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.01),name=\"HL1\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='relu', \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.01), name=\"HL2\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax', name=\"OL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_do_bn_reg_model= model.fit(X_train, y_train, \n",
    "                                 epochs=500, batch_size = 20, \n",
    "                                 validation_split = 0.1, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 107us/step\n",
      "Training Metrics: \n",
      "  accuracy 0.9464285969734192 \n",
      "  auc_6 0.9147660136222839 \n",
      "  precision_6 0.8004037141799927 \n",
      "  recall_6 0.66461580991745 \n",
      " \n",
      "38/38 [==============================] - 0s 131us/step\n",
      "Test Metrics: \n",
      "  accuracy 0.8947368264198303 \n",
      "  auc_6 0.9148874282836914 \n",
      "  precision_6 0.8006412982940674 \n",
      "  recall_6 0.6648886203765869 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "print(\"Training Metrics: \\n \", model.metrics_names[1], scores_train[1], \"\\n \",\n",
    "      model.metrics_names[2], scores_train[2], \"\\n \",\n",
    "      model.metrics_names[3], scores_train[3], \"\\n \",\n",
    "      model.metrics_names[4], scores_train[4], \"\\n \")\n",
    "scores_test = model.evaluate(X_test, y_test)\n",
    "print(\"Test Metrics: \\n \", model.metrics_names[1], scores_test[1], \"\\n \",\n",
    "      model.metrics_names[2], scores_test[2], \"\\n \",\n",
    "      model.metrics_names[3], scores_test[3], \"\\n \",\n",
    "      model.metrics_names[4], scores_test[4], \"\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "HL1 (Dense)                  (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "HL2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "OL (Dense)                   (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 117\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# In Batch Normalization layer 12 parameters are trainable \n",
    "# and 12 are not trainable. Trainable parameters are gamma and beta\n",
    "# Not trainable are running weighted mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_viz is not designed for batch_norm\n",
    "# ann_viz(model, title=\"Shallow Neural Network\", view = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
