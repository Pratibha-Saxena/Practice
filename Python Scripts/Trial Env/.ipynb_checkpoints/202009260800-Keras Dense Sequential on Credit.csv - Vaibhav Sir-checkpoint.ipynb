{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID   Income  Limit  Rating  Cards  Age  Education  Gender  \\\n",
       "0           1   1   14.891   3606     283      2   34         11    Male   \n",
       "1           2   2  106.025   6645     483      3   82         15  Female   \n",
       "2           3   3  104.593   7075     514      4   71         11    Male   \n",
       "3           4   4  148.924   9504     681      3   36         11  Female   \n",
       "4           5   5   55.882   4897     357      2   68         16    Male   \n",
       "\n",
       "  Student Married  Ethnicity  Balance  \n",
       "0      No     Yes  Caucasian      333  \n",
       "1     Yes     Yes      Asian      903  \n",
       "2      No      No      Asian      580  \n",
       "3      No      No      Asian      964  \n",
       "4      No     Yes  Caucasian      331  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/Admin/Documents/Datasets/Credit.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide columns into cat | con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "con = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes == \"object\":\n",
    "        cat.append(i)\n",
    "    else:\n",
    "        con.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding of all cat columns (Except y column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.remove(\"Student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHEcols = pd.get_dummies(df[cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join these columns with continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[con]\n",
    "con.remove(\"Unnamed: 0\")\n",
    "con.remove(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "df[con] = ss.fit_transform(df[con])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[con].join(OHEcols)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = df[[\"Student\"]]\n",
    "y = y.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Gender_ Male</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Married_No</th>\n",
       "      <th>Married_Yes</th>\n",
       "      <th>Ethnicity_African American</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Caucasian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.861583</td>\n",
       "      <td>-0.489999</td>\n",
       "      <td>-0.465539</td>\n",
       "      <td>-0.699130</td>\n",
       "      <td>-1.257674</td>\n",
       "      <td>-0.784930</td>\n",
       "      <td>-0.407277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.727437</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.828703</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>1.528451</td>\n",
       "      <td>0.496588</td>\n",
       "      <td>0.834056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686756</td>\n",
       "      <td>1.014787</td>\n",
       "      <td>1.029311</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.889964</td>\n",
       "      <td>-0.784930</td>\n",
       "      <td>0.130634</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.946152</td>\n",
       "      <td>2.068440</td>\n",
       "      <td>2.110003</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>-1.141586</td>\n",
       "      <td>-0.784930</td>\n",
       "      <td>0.966900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302928</td>\n",
       "      <td>0.070012</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.699130</td>\n",
       "      <td>0.715831</td>\n",
       "      <td>0.816968</td>\n",
       "      <td>-0.411633</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.940986</td>\n",
       "      <td>-0.275711</td>\n",
       "      <td>-0.310230</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>-1.373763</td>\n",
       "      <td>-0.144171</td>\n",
       "      <td>0.087078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-0.904963</td>\n",
       "      <td>-0.389362</td>\n",
       "      <td>-0.381413</td>\n",
       "      <td>1.491355</td>\n",
       "      <td>0.541698</td>\n",
       "      <td>1.137347</td>\n",
       "      <td>-0.087144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.359462</td>\n",
       "      <td>-0.244913</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>1.491355</td>\n",
       "      <td>0.657787</td>\n",
       "      <td>-0.464550</td>\n",
       "      <td>-0.831944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-0.212808</td>\n",
       "      <td>-0.958916</td>\n",
       "      <td>-1.054419</td>\n",
       "      <td>-1.429291</td>\n",
       "      <td>-0.677231</td>\n",
       "      <td>-0.144171</td>\n",
       "      <td>-1.132477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-0.753345</td>\n",
       "      <td>0.341993</td>\n",
       "      <td>0.388661</td>\n",
       "      <td>1.491355</td>\n",
       "      <td>0.483654</td>\n",
       "      <td>-2.066448</td>\n",
       "      <td>0.971256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income     Limit    Rating     Cards       Age  Education   Balance  \\\n",
       "0   -0.861583 -0.489999 -0.465539 -0.699130 -1.257674  -0.784930 -0.407277   \n",
       "1    1.727437  0.828261  0.828703  0.031032  1.528451   0.496588  0.834056   \n",
       "2    1.686756  1.014787  1.029311  0.761194  0.889964  -0.784930  0.130634   \n",
       "3    2.946152  2.068440  2.110003  0.031032 -1.141586  -0.784930  0.966900   \n",
       "4    0.302928  0.070012  0.013331 -0.699130  0.715831   0.816968 -0.411633   \n",
       "..        ...       ...       ...       ...       ...        ...       ...   \n",
       "395 -0.940986 -0.275711 -0.310230  0.031032 -1.373763  -0.144171  0.087078   \n",
       "396 -0.904963 -0.389362 -0.381413  1.491355  0.541698   1.137347 -0.087144   \n",
       "397  0.359462 -0.244913 -0.219633  1.491355  0.657787  -0.464550 -0.831944   \n",
       "398 -0.212808 -0.958916 -1.054419 -1.429291 -0.677231  -0.144171 -1.132477   \n",
       "399 -0.753345  0.341993  0.388661  1.491355  0.483654  -2.066448  0.971256   \n",
       "\n",
       "     Gender_ Male  Gender_Female  Married_No  Married_Yes  \\\n",
       "0               1              0           0            1   \n",
       "1               0              1           0            1   \n",
       "2               1              0           1            0   \n",
       "3               0              1           1            0   \n",
       "4               1              0           0            1   \n",
       "..            ...            ...         ...          ...   \n",
       "395             1              0           0            1   \n",
       "396             1              0           1            0   \n",
       "397             0              1           0            1   \n",
       "398             1              0           0            1   \n",
       "399             0              1           1            0   \n",
       "\n",
       "     Ethnicity_African American  Ethnicity_Asian  Ethnicity_Caucasian  \n",
       "0                             0                0                    1  \n",
       "1                             0                1                    0  \n",
       "2                             0                1                    0  \n",
       "3                             0                1                    0  \n",
       "4                             0                0                    1  \n",
       "..                          ...              ...                  ...  \n",
       "395                           0                0                    1  \n",
       "396                           1                0                    0  \n",
       "397                           0                0                    1  \n",
       "398                           0                0                    1  \n",
       "399                           0                1                    0  \n",
       "\n",
       "[400 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide data into training and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Student\n",
       "0          0\n",
       "1          1\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "..       ...\n",
       "395        0\n",
       "396        0\n",
       "397        0\n",
       "398        0\n",
       "399        0\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last time we did like dis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 120, 50, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now.. using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\", input_dim=14))\n",
    "model.add(Dense(120, activation=\"relu\"))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(30, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "320/320 [==============================] - 0s 761us/step - loss: 0.6424 - accuracy: 0.8719\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 0s 73us/step - loss: 0.5927 - accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 0s 69us/step - loss: 0.5511 - accuracy: 0.8906\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 0s 81us/step - loss: 0.5153 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.4845 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.4588 - accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.4371 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "320/320 [==============================] - 0s 67us/step - loss: 0.4194 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.4051 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.90 - 0s 60us/step - loss: 0.3936 - accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "model_nn = model.fit(X_train, y_train, validation_freq=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_proba = model.predict(X_test)\n",
    "pred = [int(i>0.5) for i in pred_proba]\n",
    "# pred1 = []\n",
    "# for i in pred:\n",
    "#    if(i > 0.5):\n",
    "#        pred1.append(1)\n",
    "#    else:\n",
    "#        pred1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [ 5  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "256/256 [==============================] - 0s 333us/step - loss: 0.3804 - accuracy: 0.8945 - val_loss: 0.4016 - val_accuracy: 0.8750\n",
      "Epoch 2/100\n",
      "256/256 [==============================] - 0s 134us/step - loss: 0.3739 - accuracy: 0.8945 - val_loss: 0.3972 - val_accuracy: 0.8750\n",
      "Epoch 3/100\n",
      "256/256 [==============================] - 0s 117us/step - loss: 0.3689 - accuracy: 0.8945 - val_loss: 0.3937 - val_accuracy: 0.8750\n",
      "Epoch 4/100\n",
      "256/256 [==============================] - 0s 91us/step - loss: 0.3640 - accuracy: 0.8945 - val_loss: 0.3908 - val_accuracy: 0.8750\n",
      "Epoch 5/100\n",
      "256/256 [==============================] - 0s 80us/step - loss: 0.3601 - accuracy: 0.8945 - val_loss: 0.3885 - val_accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "256/256 [==============================] - 0s 88us/step - loss: 0.3571 - accuracy: 0.8945 - val_loss: 0.3866 - val_accuracy: 0.8750\n",
      "Epoch 7/100\n",
      "256/256 [==============================] - 0s 89us/step - loss: 0.3542 - accuracy: 0.8945 - val_loss: 0.3849 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "256/256 [==============================] - 0s 100us/step - loss: 0.3516 - accuracy: 0.8945 - val_loss: 0.3835 - val_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "256/256 [==============================] - 0s 95us/step - loss: 0.3493 - accuracy: 0.8945 - val_loss: 0.3822 - val_accuracy: 0.8750\n",
      "Epoch 10/100\n",
      "256/256 [==============================] - 0s 90us/step - loss: 0.3470 - accuracy: 0.8945 - val_loss: 0.3810 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "256/256 [==============================] - 0s 85us/step - loss: 0.3450 - accuracy: 0.8945 - val_loss: 0.3799 - val_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "256/256 [==============================] - 0s 115us/step - loss: 0.3427 - accuracy: 0.8945 - val_loss: 0.3789 - val_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "256/256 [==============================] - 0s 75us/step - loss: 0.3408 - accuracy: 0.8945 - val_loss: 0.3780 - val_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "256/256 [==============================] - 0s 80us/step - loss: 0.3393 - accuracy: 0.8945 - val_loss: 0.3771 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "256/256 [==============================] - 0s 94us/step - loss: 0.3375 - accuracy: 0.8945 - val_loss: 0.3762 - val_accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "256/256 [==============================] - 0s 105us/step - loss: 0.3360 - accuracy: 0.8945 - val_loss: 0.3753 - val_accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "256/256 [==============================] - 0s 97us/step - loss: 0.3344 - accuracy: 0.8945 - val_loss: 0.3744 - val_accuracy: 0.8750\n",
      "Epoch 18/100\n",
      "256/256 [==============================] - 0s 99us/step - loss: 0.3328 - accuracy: 0.8945 - val_loss: 0.3736 - val_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "256/256 [==============================] - 0s 99us/step - loss: 0.3314 - accuracy: 0.8945 - val_loss: 0.3728 - val_accuracy: 0.8750\n",
      "Epoch 20/100\n",
      "256/256 [==============================] - 0s 69us/step - loss: 0.3298 - accuracy: 0.8945 - val_loss: 0.3719 - val_accuracy: 0.8750\n",
      "Epoch 21/100\n",
      "256/256 [==============================] - 0s 91us/step - loss: 0.3284 - accuracy: 0.8945 - val_loss: 0.3711 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "256/256 [==============================] - 0s 99us/step - loss: 0.3276 - accuracy: 0.8945 - val_loss: 0.3702 - val_accuracy: 0.8750\n",
      "Epoch 23/100\n",
      "256/256 [==============================] - 0s 80us/step - loss: 0.3257 - accuracy: 0.8945 - val_loss: 0.3695 - val_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "256/256 [==============================] - 0s 107us/step - loss: 0.3241 - accuracy: 0.8945 - val_loss: 0.3688 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "256/256 [==============================] - 0s 84us/step - loss: 0.3233 - accuracy: 0.8945 - val_loss: 0.3682 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "256/256 [==============================] - 0s 84us/step - loss: 0.3217 - accuracy: 0.8945 - val_loss: 0.3675 - val_accuracy: 0.8750\n",
      "Epoch 27/100\n",
      "256/256 [==============================] - 0s 84us/step - loss: 0.3204 - accuracy: 0.8945 - val_loss: 0.3668 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "256/256 [==============================] - 0s 78us/step - loss: 0.3195 - accuracy: 0.8945 - val_loss: 0.3662 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "256/256 [==============================] - 0s 103us/step - loss: 0.3180 - accuracy: 0.8945 - val_loss: 0.3656 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "256/256 [==============================] - 0s 81us/step - loss: 0.3166 - accuracy: 0.8945 - val_loss: 0.3650 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "256/256 [==============================] - 0s 105us/step - loss: 0.3154 - accuracy: 0.8945 - val_loss: 0.3644 - val_accuracy: 0.8750\n",
      "Epoch 32/100\n",
      "256/256 [==============================] - 0s 83us/step - loss: 0.3147 - accuracy: 0.8945 - val_loss: 0.3638 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "256/256 [==============================] - 0s 97us/step - loss: 0.3130 - accuracy: 0.8945 - val_loss: 0.3631 - val_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "256/256 [==============================] - 0s 84us/step - loss: 0.3120 - accuracy: 0.8945 - val_loss: 0.3625 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "256/256 [==============================] - 0s 109us/step - loss: 0.3105 - accuracy: 0.8945 - val_loss: 0.3618 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "256/256 [==============================] - 0s 124us/step - loss: 0.3095 - accuracy: 0.8945 - val_loss: 0.3612 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "256/256 [==============================] - 0s 79us/step - loss: 0.3082 - accuracy: 0.8945 - val_loss: 0.3605 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "256/256 [==============================] - 0s 102us/step - loss: 0.3070 - accuracy: 0.8945 - val_loss: 0.3599 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "256/256 [==============================] - 0s 81us/step - loss: 0.3057 - accuracy: 0.8945 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "256/256 [==============================] - 0s 102us/step - loss: 0.3049 - accuracy: 0.8945 - val_loss: 0.3589 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "256/256 [==============================] - 0s 140us/step - loss: 0.3035 - accuracy: 0.8945 - val_loss: 0.3581 - val_accuracy: 0.8750\n",
      "Epoch 42/100\n",
      "256/256 [==============================] - 0s 103us/step - loss: 0.3023 - accuracy: 0.8945 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "256/256 [==============================] - 0s 87us/step - loss: 0.3012 - accuracy: 0.8945 - val_loss: 0.3569 - val_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "256/256 [==============================] - 0s 97us/step - loss: 0.2998 - accuracy: 0.8945 - val_loss: 0.3562 - val_accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "256/256 [==============================] - 0s 99us/step - loss: 0.2988 - accuracy: 0.8945 - val_loss: 0.3556 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "256/256 [==============================] - 0s 93us/step - loss: 0.2976 - accuracy: 0.8945 - val_loss: 0.3550 - val_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "256/256 [==============================] - 0s 68us/step - loss: 0.2964 - accuracy: 0.8945 - val_loss: 0.3542 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "256/256 [==============================] - 0s 101us/step - loss: 0.2950 - accuracy: 0.8945 - val_loss: 0.3534 - val_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "256/256 [==============================] - 0s 108us/step - loss: 0.2939 - accuracy: 0.8945 - val_loss: 0.3527 - val_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "256/256 [==============================] - 0s 85us/step - loss: 0.2927 - accuracy: 0.8945 - val_loss: 0.3519 - val_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "256/256 [==============================] - 0s 105us/step - loss: 0.2915 - accuracy: 0.8945 - val_loss: 0.3514 - val_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "256/256 [==============================] - 0s 99us/step - loss: 0.2903 - accuracy: 0.8945 - val_loss: 0.3508 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "256/256 [==============================] - 0s 102us/step - loss: 0.2891 - accuracy: 0.8945 - val_loss: 0.3502 - val_accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "256/256 [==============================] - 0s 85us/step - loss: 0.2877 - accuracy: 0.8945 - val_loss: 0.3494 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "256/256 [==============================] - 0s 103us/step - loss: 0.2863 - accuracy: 0.8945 - val_loss: 0.3486 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "256/256 [==============================] - 0s 102us/step - loss: 0.2851 - accuracy: 0.8945 - val_loss: 0.3479 - val_accuracy: 0.8750\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 0s 115us/step - loss: 0.2840 - accuracy: 0.8945 - val_loss: 0.3472 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "256/256 [==============================] - 0s 104us/step - loss: 0.2829 - accuracy: 0.8945 - val_loss: 0.3465 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "256/256 [==============================] - 0s 106us/step - loss: 0.2812 - accuracy: 0.8945 - val_loss: 0.3457 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "256/256 [==============================] - 0s 115us/step - loss: 0.2801 - accuracy: 0.8945 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
      "Epoch 61/100\n",
      "256/256 [==============================] - 0s 120us/step - loss: 0.2786 - accuracy: 0.8945 - val_loss: 0.3442 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "256/256 [==============================] - 0s 191us/step - loss: 0.2775 - accuracy: 0.8945 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
      "Epoch 63/100\n",
      "256/256 [==============================] - 0s 131us/step - loss: 0.2762 - accuracy: 0.8945 - val_loss: 0.3430 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "256/256 [==============================] - 0s 125us/step - loss: 0.2750 - accuracy: 0.8945 - val_loss: 0.3419 - val_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "256/256 [==============================] - 0s 107us/step - loss: 0.2734 - accuracy: 0.8945 - val_loss: 0.3412 - val_accuracy: 0.8750\n",
      "Epoch 66/100\n",
      "256/256 [==============================] - 0s 116us/step - loss: 0.2720 - accuracy: 0.8945 - val_loss: 0.3406 - val_accuracy: 0.8750\n",
      "Epoch 67/100\n",
      "256/256 [==============================] - 0s 122us/step - loss: 0.2707 - accuracy: 0.8945 - val_loss: 0.3400 - val_accuracy: 0.8750\n",
      "Epoch 68/100\n",
      "256/256 [==============================] - 0s 119us/step - loss: 0.2694 - accuracy: 0.8945 - val_loss: 0.3391 - val_accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "256/256 [==============================] - 0s 115us/step - loss: 0.2683 - accuracy: 0.8945 - val_loss: 0.3383 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "256/256 [==============================] - 0s 117us/step - loss: 0.2671 - accuracy: 0.8945 - val_loss: 0.3374 - val_accuracy: 0.8750\n",
      "Epoch 71/100\n",
      "256/256 [==============================] - 0s 126us/step - loss: 0.2649 - accuracy: 0.8945 - val_loss: 0.3364 - val_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "256/256 [==============================] - 0s 111us/step - loss: 0.2636 - accuracy: 0.8945 - val_loss: 0.3357 - val_accuracy: 0.8750\n",
      "Epoch 73/100\n",
      "256/256 [==============================] - 0s 128us/step - loss: 0.2622 - accuracy: 0.8945 - val_loss: 0.3349 - val_accuracy: 0.8750\n",
      "Epoch 74/100\n",
      "256/256 [==============================] - 0s 118us/step - loss: 0.2606 - accuracy: 0.8945 - val_loss: 0.3340 - val_accuracy: 0.8750\n",
      "Epoch 75/100\n",
      "256/256 [==============================] - 0s 122us/step - loss: 0.2589 - accuracy: 0.8945 - val_loss: 0.3332 - val_accuracy: 0.8750\n",
      "Epoch 76/100\n",
      "256/256 [==============================] - 0s 112us/step - loss: 0.2576 - accuracy: 0.8945 - val_loss: 0.3321 - val_accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "256/256 [==============================] - 0s 116us/step - loss: 0.2562 - accuracy: 0.8945 - val_loss: 0.3315 - val_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "256/256 [==============================] - 0s 111us/step - loss: 0.2550 - accuracy: 0.8945 - val_loss: 0.3303 - val_accuracy: 0.8750\n",
      "Epoch 79/100\n",
      "256/256 [==============================] - 0s 136us/step - loss: 0.2531 - accuracy: 0.8945 - val_loss: 0.3296 - val_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "256/256 [==============================] - 0s 130us/step - loss: 0.2516 - accuracy: 0.8945 - val_loss: 0.3284 - val_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "256/256 [==============================] - 0s 128us/step - loss: 0.2504 - accuracy: 0.8945 - val_loss: 0.3272 - val_accuracy: 0.8750\n",
      "Epoch 82/100\n",
      "256/256 [==============================] - 0s 127us/step - loss: 0.2484 - accuracy: 0.8945 - val_loss: 0.3265 - val_accuracy: 0.8750\n",
      "Epoch 83/100\n",
      "256/256 [==============================] - 0s 126us/step - loss: 0.2471 - accuracy: 0.8945 - val_loss: 0.3254 - val_accuracy: 0.8750\n",
      "Epoch 84/100\n",
      "256/256 [==============================] - 0s 122us/step - loss: 0.2454 - accuracy: 0.8945 - val_loss: 0.3245 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "256/256 [==============================] - 0s 113us/step - loss: 0.2435 - accuracy: 0.8945 - val_loss: 0.3235 - val_accuracy: 0.8750\n",
      "Epoch 86/100\n",
      "256/256 [==============================] - 0s 124us/step - loss: 0.2420 - accuracy: 0.8945 - val_loss: 0.3226 - val_accuracy: 0.8750\n",
      "Epoch 87/100\n",
      "256/256 [==============================] - 0s 119us/step - loss: 0.2403 - accuracy: 0.8945 - val_loss: 0.3214 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "256/256 [==============================] - 0s 119us/step - loss: 0.2386 - accuracy: 0.8945 - val_loss: 0.3205 - val_accuracy: 0.8750\n",
      "Epoch 89/100\n",
      "256/256 [==============================] - 0s 138us/step - loss: 0.2368 - accuracy: 0.8945 - val_loss: 0.3194 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "256/256 [==============================] - 0s 117us/step - loss: 0.2350 - accuracy: 0.8945 - val_loss: 0.3187 - val_accuracy: 0.8750\n",
      "Epoch 91/100\n",
      "256/256 [==============================] - 0s 116us/step - loss: 0.2337 - accuracy: 0.8945 - val_loss: 0.3172 - val_accuracy: 0.8750\n",
      "Epoch 92/100\n",
      "256/256 [==============================] - 0s 106us/step - loss: 0.2318 - accuracy: 0.8945 - val_loss: 0.3161 - val_accuracy: 0.8750\n",
      "Epoch 93/100\n",
      "256/256 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.8945 - val_loss: 0.3146 - val_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "256/256 [==============================] - 0s 101us/step - loss: 0.2280 - accuracy: 0.8945 - val_loss: 0.3135 - val_accuracy: 0.8750\n",
      "Epoch 95/100\n",
      "256/256 [==============================] - 0s 105us/step - loss: 0.2263 - accuracy: 0.8945 - val_loss: 0.3121 - val_accuracy: 0.8750\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 0s 100us/step - loss: 0.2239 - accuracy: 0.8945 - val_loss: 0.3109 - val_accuracy: 0.8750\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 0s 97us/step - loss: 0.2220 - accuracy: 0.8945 - val_loss: 0.3097 - val_accuracy: 0.8750\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 0s 102us/step - loss: 0.2204 - accuracy: 0.8945 - val_loss: 0.3086 - val_accuracy: 0.8750\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 0s 112us/step - loss: 0.2184 - accuracy: 0.8945 - val_loss: 0.3068 - val_accuracy: 0.8750\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 0s 100us/step - loss: 0.2160 - accuracy: 0.8945 - val_loss: 0.3052 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "model_nn = model.fit(X_train, y_train, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [ 5  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pred_proba = model.predict(X_test)\n",
    "pred = [int(i>0.5) for i in pred_proba]\n",
    "print(confusion_matrix(y_test, pred))\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 64 samples\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2180 - accuracy: 0.9062 - val_loss: 0.2833 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 0s 119us/step - loss: 0.1799 - accuracy: 0.9258 - val_loss: 0.2760 - val_accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 0s 99us/step - loss: 0.1430 - accuracy: 0.9375 - val_loss: 0.2481 - val_accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.90 - 0s 84us/step - loss: 0.1108 - accuracy: 0.9570 - val_loss: 0.2457 - val_accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 0s 91us/step - loss: 0.0808 - accuracy: 0.9766 - val_loss: 0.2246 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 0s 101us/step - loss: 0.0595 - accuracy: 0.9922 - val_loss: 0.2106 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 0s 93us/step - loss: 0.0392 - accuracy: 0.9961 - val_loss: 0.2123 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 0s 100us/step - loss: 0.0289 - accuracy: 0.9961 - val_loss: 0.2048 - val_accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 0s 89us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 0s 95us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_nn = model.fit(X_train, y_train, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [ 5  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pred_proba = model.predict(X_test)\n",
    "pred = [int(i>0.5) for i in pred]\n",
    "print(confusion_matrix(y_test, pred))\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
