{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv(\"C:/Users/Admin/Documents/Datasets/iris.csv\")\n",
    "iris = iris.drop(labels=[\"Unnamed: 0\"], axis=1)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>Species1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species  Species1\n",
       "0           5.1          3.5           1.4          0.2  setosa         0\n",
       "1           4.9          3.0           1.4          0.2  setosa         0\n",
       "2           4.7          3.2           1.3          0.2  setosa         0\n",
       "3           4.6          3.1           1.5          0.2  setosa         0\n",
       "4           5.0          3.6           1.4          0.2  setosa         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "iris.Species = iris.Species.astype(\"category\")\n",
    "iris[\"Species1\"] = np.repeat([0, 1, 2], 50)  # for first 50 observations = 0; for next 50 = 1; for last 50 = 2\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is built in Pyhton and on top of TensorFlow 2.0\n",
    "# Keras is neural network library while\n",
    "# TensorFlow is the open source library for a number of tasks in machine learning.\n",
    "# Both framewrks provide high-level APIs for building and training models with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Species1, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: Species1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = iris.iloc[:, :4]\n",
    "y = iris.iloc[:, -1]\n",
    "display(X.head())\n",
    "display(y.head())\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  0  0\n",
       "1  1  0  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n",
      "(112, 3)\n",
      "(38, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2\n",
       "114  0  0  1\n",
       "62   0  1  0\n",
       "33   1  0  0\n",
       "107  0  0  1\n",
       "7    1  0  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating MLP in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating MLP in Keras\n",
    "# Sequential function groups a linear stack of layers into a Keras model\n",
    "# Sequential model provides training and inference features on this model\n",
    "from keras.models import Sequential\n",
    "# A dense layer is just a layer of neurons in a neural network\n",
    "# Each neuron recieves an input from all the neurons in previous layer, thus densely connected.\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In first Dense layer, the dimension of input layer can be given\n",
    "# tesorflow: large dropout rate: 0.8 (i.e. >0.5).\n",
    "# In Tensorflow 2.x, dropout() uses dropout rate instead of keep_prob.\n",
    "# Please ensure that this is intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(6, input_dim=4, activation=\"sigmoid\", name=\"HL1\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation=\"relu\", name=\"HL2\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\", name=\"OL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'HL1/kernel:0' shape=(4, 6) dtype=float32, numpy=\n",
      "array([[ 0.75721276,  0.6253556 , -0.30697662, -0.7678474 , -0.6735275 ,\n",
      "        -0.69091046],\n",
      "       [ 0.6498194 ,  0.2593193 , -0.13429397, -0.14790952,  0.5050874 ,\n",
      "         0.714748  ],\n",
      "       [-0.3803683 ,  0.2902664 , -0.1643402 ,  0.3778746 ,  0.66825914,\n",
      "        -0.11448741],\n",
      "       [ 0.01783991, -0.03609776,  0.23856127, -0.69726396,  0.76785684,\n",
      "        -0.4933757 ]], dtype=float32)>, <tf.Variable 'HL1/bias:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'HL2/kernel:0' shape=(6, 6) dtype=float32, numpy=\n",
      "array([[ 0.31574517,  0.42839164, -0.09273809,  0.00258982, -0.67941934,\n",
      "         0.21887279],\n",
      "       [ 0.32550484,  0.11600953,  0.61612755,  0.2641245 ,  0.6335042 ,\n",
      "         0.15417045],\n",
      "       [ 0.35684997,  0.5547914 , -0.09906328,  0.26748836, -0.17071342,\n",
      "        -0.0695647 ],\n",
      "       [-0.6621524 ,  0.6080976 , -0.19545215, -0.24087986,  0.3806762 ,\n",
      "        -0.6985958 ],\n",
      "       [-0.7035978 , -0.31463027, -0.543524  ,  0.3761124 ,  0.6584129 ,\n",
      "        -0.10319591],\n",
      "       [ 0.3387341 , -0.45296615,  0.5091644 ,  0.4252519 ,  0.7044303 ,\n",
      "         0.18355507]], dtype=float32)>, <tf.Variable 'HL2/bias:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'OL/kernel:0' shape=(6, 3) dtype=float32, numpy=\n",
      "array([[-0.32704082, -0.0587253 , -0.12514132],\n",
      "       [-0.484183  ,  0.33713877,  0.31177962],\n",
      "       [-0.4199716 , -0.28306532,  0.38950336],\n",
      "       [ 0.01293683,  0.55409896,  0.31183195],\n",
      "       [-0.21600395, -0.41569883, -0.46081877],\n",
      "       [ 0.00099689, -0.5854896 , -0.43547514]], dtype=float32)>, <tf.Variable 'OL/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# initialized weights\n",
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape:  (None, 4)\n",
      "Output layer shape:  (None, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input layer shape: \", model.input_shape)\n",
    "print(\"Output layer shape: \", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "from keras import metrics\n",
    "from keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
       "61            5.9          3.0           4.2          1.5\n",
       "92            5.8          2.6           4.0          1.2\n",
       "112           6.8          3.0           5.5          2.1\n",
       "2             4.7          3.2           1.3          0.2\n",
       "141           6.9          3.1           5.1          2.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input data\n",
    "from keras.utils import normalize\n",
    "X_train = normalize(np.array(X_train), axis=1)\n",
    "X_test = normalize(np.array(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73923462, 0.37588201, 0.52623481, 0.187941  ],\n",
       "       [0.76262994, 0.34186859, 0.52595168, 0.1577855 ],\n",
       "       [0.71718148, 0.31640359, 0.58007326, 0.22148252],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.73337886, 0.32948905, 0.54206264, 0.24445962]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling a simple model without customizing the optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Compile defines the loss function, the activation and the metrics\n",
    "# You need a compiled model to train because training uses the loss function and the optimizer\n",
    "\n",
    "# optimizer - name of optimizer or optimizer instance: 'SGD', 'RMSProp', 'Adam'\n",
    "\n",
    "# loss - name of objective function or objective function or `Loss` instance:\n",
    "# Classification - binary_crossentropy, categorical_crossentropy\n",
    "# Regression - mean_squared_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# metrics - list of metrics to be evaluated by the model during training and testing\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\", tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining optimizers with fixed learning_rate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can separately define optimizers\n",
    "# These are not default optimizers but custom optimizers\n",
    "opt_SGD = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, name=\"SGD\")\n",
    "\n",
    "# rho is beta of RMSProp\n",
    "# momentum and rho are applied in sequence one after other\n",
    "# In Adam optimization, both are used in same formula\n",
    "\n",
    "opt_RMSProp = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, name=\"RMSProp\")\n",
    "\n",
    "opt_Adam = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Learning rate schedules -- going to user after defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify learning rate schedules\n",
    "# a) exponential decay schedule\n",
    "# initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "# If staircase=True then, (step / decay_steps) will be integer. So, when step reaches decay_step then it will reduce first time.\n",
    "# staircase=True - It is like a floor operation on (step/decay_steps)\n",
    "# So, initially learning_rate = initial_learning_rate * decay_rate ^ 0 = initial_learning_rate\n",
    "# Then, after some steps, when step > 100000, (step/decay_steps will become 1)\n",
    "#  and then, learning_rate = initial_learning_rate * decay_rate ^ 1 = initial_learning_rate * 0.96\n",
    "# Then, after few more steps, when step reaches 2*decay_steps,\n",
    "#              learning_rate = initial_learning_rate * 0.96^2\n",
    "\n",
    "# And if staircase=False, then, decay of learning_rate will increase at each step.\n",
    "# Initially, step/decay_steps will remain near to zero and decay_rate^(~0)  will be almost 1.\n",
    "#           And so, learning_rate will be just like initial_learning_rate\n",
    "# Then, at each step, step/decay_steps will increase and decay_rate^(step/decay_steps) will get small small small..\n",
    "#           And so, the learning_rate will decay gradually with increasing number of steps.\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "lr_schedule1 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# b) Polynomial decay\n",
    "# (initial_learning_rate - end_learning_rate) * (1 - (step/decay_steps))^(power) + end_learning_rate\n",
    "\n",
    "starter_learning_rate = 0.1\n",
    "end_learning_rate = 0.01\n",
    "decay_steps = 10000\n",
    "lr_schedule2 = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=starter_learning_rate,\n",
    "    end_learning_rate=end_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    power=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Inverse Time Decay\n",
    "# initial_learning_rate / (1 + (decay_rate * (step / decay_steps)))\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "decay_steps = 1.0\n",
    "decay_rate = 0.5\n",
    "lr_schedule3 = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_rate=decay_rate,\n",
    "    decay_steps=decay_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Optimizers with learning rate schedules instead of just learning_rate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can separately define optimizers with learning rate schedule defined\n",
    "opt_SGD1 = tf.keras.optimizers.SGD(learning_rate=lr_schedule1, momentum=0.9, name=\"SGD\")\n",
    "# rho is beta of RMSProp\n",
    "opt_RMSProp1 = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule2, rho=0.9, momentum=0.9, epsilon=1e-07, name=\"RMSProp\")\n",
    "\n",
    "opt_Adam1 = tf.keras.optimizers.Adam(learning_rate=lr_schedule3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model using defined customized optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with defined customized optimizers\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt_SGD1, \n",
    "              metrics=[\"accuracy\",\n",
    "                       tf.keras.metrics.AUC(),\n",
    "                       tf.keras.metrics.Precision(),\n",
    "                       tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: model has not seen the test set anywhere.. we will fit it on training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# 1 epoch = 1 pass through the entire training set\n",
    "# batch_size - for mini-batch gradient descent\n",
    "# validation-split: Fraction of the training dat to be used as validation data\n",
    "# The model will set apart this fraction of training data, will not train on it,\n",
    "# and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
    "\n",
    "# np.random.seed(0)  --???\n",
    "keras_do_model = model.fit(X_train, y_train,\n",
    "                          epochs=500, batch_size=20,\n",
    "                          validation_split=0.1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04712725 0.4627474  0.4901253 ]\n",
      " [0.04712725 0.4627474  0.4901253 ]\n",
      " [0.38510284 0.613284   0.00161313]\n",
      " [0.04712725 0.4627474  0.4901253 ]\n",
      " [0.3482165  0.64891756 0.00286594]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 134us/step\n",
      "[('loss', 0.8448598555156163), ('accuracy', 0.3660714328289032), ('auc_1', 0.8257098197937012), ('precision_1', 0.7510448098182678), ('recall_1', 0.41825392842292786)]\n",
      "Training Metrics: \n",
      " loss 0.8448598555156163 \n",
      " accuracy 0.3660714328289032 \n",
      " auc_1 0.8257098197937012 \n",
      " precision_1 0.41825392842292786 \n",
      " recall_1 0.41825392842292786 \n",
      "\n",
      "38/38 [==============================] - 0s 210us/step\n",
      "[('loss', 0.8536271139195091), ('accuracy', 0.2368421107530594), ('auc_1', 0.8255557417869568), ('precision_1', 0.7504399418830872), ('recall_1', 0.41774269938468933)]\n",
      "Testing Metrics: \n",
      " loss 0.8536271139195091 \n",
      " accuracy 0.2368421107530594 \n",
      " auc_1 0.8255557417869568 \n",
      " precision_1 0.41774269938468933 \n",
      " recall_1 0.41774269938468933 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "#     That is the evaluate() method is runs the model in test mode\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "print(list(zip(model.metrics_names, scores_train)))\n",
    "print(\"Training Metrics: \\n\", model.metrics_names[0], scores_train[0], \"\\n\",\n",
    "      model.metrics_names[1], scores_train[1], \"\\n\",\n",
    "      model.metrics_names[2], scores_train[2], \"\\n\",\n",
    "      model.metrics_names[3], scores_train[4], \"\\n\",\n",
    "      model.metrics_names[4], scores_train[4], \"\\n\")\n",
    "\n",
    "scores_test = model.evaluate(X_test, y_test)\n",
    "print(list(zip(model.metrics_names, scores_test)))\n",
    "print(\"Testing Metrics: \\n\", model.metrics_names[0], scores_test[0], \"\\n\",\n",
    "      model.metrics_names[1], scores_test[1], \"\\n\",\n",
    "      model.metrics_names[2], scores_test[2], \"\\n\",\n",
    "      model.metrics_names[3], scores_test[4], \"\\n\",\n",
    "      model.metrics_names[4], scores_test[4], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "HL1 (Dense)                  (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "HL2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "OL (Dense)                   (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Note that the input layer is not displayed as part of model-layers, since it isn't a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is output shape = (None, 6) in above summary?? i.e. why None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz\n",
    "ann_viz(model, title=\"Shallow Neural Network\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization\n",
    "# add to dense layer\n",
    "# for l2 regularization: kernel_regularizer=tf.keras.regularizers.l2(default l=0.01)\n",
    "# for l1 regularization: kernel_regularizer=tf.keras.regularizers.l1(default l=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=4, activation=\"sigmoid\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.00001),\n",
    "                name=\"HL1\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"relu\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.0001),\n",
    "               name=\"HL2\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\", name=\"OL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularizing using original default optimizer\n",
    "#       (not the custom ones, just for showing the results of adding ragularization)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics = [\"accuracy\", tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_do_model = model.fit(X_train, y_train, epochs=500, batch_size=20, validation_split=0.1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 107us/step\n",
      "[('loss', 0.47673127480915617), ('accuracy', 0.6964285969734192), ('auc_2', 0.800546407699585), ('precision_2', 0.7095050811767578), ('recall_2', 0.34869182109832764)]\n",
      "Training Metrics: \n",
      " loss 0.47673127480915617 \n",
      " accuracy 0.6964285969734192 \n",
      " auc_2 0.800546407699585 \n",
      " precision_2 0.34869182109832764 \n",
      " recall_2 0.34869182109832764 \n",
      "\n",
      "38/38 [==============================] - 0s 131us/step\n",
      "[('loss', 0.5303967344133478), ('accuracy', 0.5789473652839661), ('auc_2', 0.8007513284683228), ('precision_2', 0.7093014717102051), ('recall_2', 0.34904801845550537)]\n",
      "Testing Metrics: \n",
      " loss 0.5303967344133478 \n",
      " accuracy 0.5789473652839661 \n",
      " auc_2 0.8007513284683228 \n",
      " precision_2 0.34904801845550537 \n",
      " recall_2 0.34904801845550537 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# Returns the loss value and metrics values for the model in test mode\n",
    "#     That is the evaluate() method is runs the model in test mode\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "print(list(zip(model.metrics_names, scores_train)))\n",
    "print(\"Training Metrics: \\n\", model.metrics_names[0], scores_train[0], \"\\n\",\n",
    "      model.metrics_names[1], scores_train[1], \"\\n\",\n",
    "      model.metrics_names[2], scores_train[2], \"\\n\",\n",
    "      model.metrics_names[3], scores_train[4], \"\\n\",\n",
    "      model.metrics_names[4], scores_train[4], \"\\n\")\n",
    "\n",
    "scores_test = model.evaluate(X_test, y_test)\n",
    "print(list(zip(model.metrics_names, scores_test)))\n",
    "print(\"Testing Metrics: \\n\", model.metrics_names[0], scores_test[0], \"\\n\",\n",
    "      model.metrics_names[1], scores_test[1], \"\\n\",\n",
    "      model.metrics_names[2], scores_test[2], \"\\n\",\n",
    "      model.metrics_names[3], scores_test[4], \"\\n\",\n",
    "      model.metrics_names[4], scores_test[4], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "HL1 (Dense)                  (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "HL2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "OL (Dense)                   (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(model, title=\"Shallow Neural Network\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes lesser time\n",
    "\n",
    "# We do not want the hidden units to have mean=0 and variance=1 always.\n",
    "# We may want it to have some other distribution values of mean and variance.\n",
    "# It is not necessary that our distribution is normal only. Sometimes we need to learn the type of distribution.\n",
    "# In batch-normalization, we normalize the outputs of each layer\n",
    "# and then, learn the distribution: z_learned = gamma * z_norm + beta  where gamma and beta are learnable parameters of the model.\n",
    "# So, in back-propagation, gamma and beta are also updated along with weights and biases\n",
    "# This way we learn the distribution by learning gamma and beta in back-prop.\n",
    "# So, alpha is applicable on gamma and beta as well.\n",
    "\n",
    "\n",
    "# Co-Variate Shift:\n",
    "    # Change in data distribution for X and y is known as covariate shift\n",
    "    # Mean and Standard devaition are the non-learnable parameters here...\n",
    "    # Since, with each back-prop, distribution itself is getting learned which means the distribution changes after every back-prop.\n",
    "    # So, it effects the learning of weights and biases also.... in some way\n",
    "    # So, batch-norm actually tries to keep mean and standard deviation minimal effected from the effect of changing distribution.\n",
    "    # So, that it won't effect the rest of learning in some way(which is not clear to me).\n",
    "    # More description in pdf reagrding mean and standard deviation.\n",
    "\n",
    "# This algorithm works with Momentum, RMSProp and Adam optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainable = True: The variables will be marked as trainable\n",
    "# Sample DEFAULT BATCH-NORMALIZATION settings. Just for referenec. Not Used anywhere.\n",
    "# batch_norm = tf.keras.layers.BatchNormalization(\n",
    "#     axis=1,\n",
    "#     momentum=0.9,\n",
    "#     epsilon=1e-07,\n",
    "#     center=True,\n",
    "#     scale=True,\n",
    "#     beta_initializer=\"zeros\",\n",
    "#     gamma_initializer=\"ones\",\n",
    "#     moving_mean_initializer=\"zeros\",\n",
    "#     moving_variance_initializer=\"ones\",\n",
    "#     trainable=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=4, activation=\"sigmoid\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=0.01), name=\"HL1\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation=\"relu\",\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l=0.01), name=\"HL2\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\", name=\"OL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\", tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 12 samples\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.3103 - accuracy: 0.8500 - auc_3: 0.9610 - precision_3: 0.8569 - recall_3: 0.7972 - val_loss: 0.1653 - val_accuracy: 0.9167 - val_auc_3: 0.9610 - val_precision_3: 0.8569 - val_recall_3: 0.7973\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 0s 160us/step - loss: 0.3942 - accuracy: 0.8900 - auc_3: 0.9610 - precision_3: 0.8570 - recall_3: 0.7974 - val_loss: 0.1662 - val_accuracy: 0.9167 - val_auc_3: 0.9610 - val_precision_3: 0.8570 - val_recall_3: 0.7975\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2551 - accuracy: 0.8700 - auc_3: 0.9610 - precision_3: 0.8571 - recall_3: 0.7976 - val_loss: 0.1598 - val_accuracy: 0.9167 - val_auc_3: 0.9611 - val_precision_3: 0.8571 - val_recall_3: 0.7976\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2430 - accuracy: 0.9000 - auc_3: 0.9611 - precision_3: 0.8571 - recall_3: 0.7977 - val_loss: 0.1551 - val_accuracy: 0.9167 - val_auc_3: 0.9611 - val_precision_3: 0.8572 - val_recall_3: 0.7978\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3583 - accuracy: 0.8500 - auc_3: 0.9611 - precision_3: 0.8572 - recall_3: 0.7978 - val_loss: 0.1580 - val_accuracy: 0.9167 - val_auc_3: 0.9612 - val_precision_3: 0.8572 - val_recall_3: 0.7979\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.3289 - accuracy: 0.8900 - auc_3: 0.9612 - precision_3: 0.8573 - recall_3: 0.7980 - val_loss: 0.1592 - val_accuracy: 0.9167 - val_auc_3: 0.9612 - val_precision_3: 0.8573 - val_recall_3: 0.7981\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3780 - accuracy: 0.8000 - auc_3: 0.9612 - precision_3: 0.8573 - recall_3: 0.7981 - val_loss: 0.1590 - val_accuracy: 0.9167 - val_auc_3: 0.9612 - val_precision_3: 0.8572 - val_recall_3: 0.7981\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.3802 - accuracy: 0.8900 - auc_3: 0.9612 - precision_3: 0.8573 - recall_3: 0.7982 - val_loss: 0.1619 - val_accuracy: 0.9167 - val_auc_3: 0.9612 - val_precision_3: 0.8573 - val_recall_3: 0.7983\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3004 - accuracy: 0.8800 - auc_3: 0.9612 - precision_3: 0.8573 - recall_3: 0.7984 - val_loss: 0.1736 - val_accuracy: 0.9167 - val_auc_3: 0.9612 - val_precision_3: 0.8573 - val_recall_3: 0.7984\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2505 - accuracy: 0.9000 - auc_3: 0.9613 - precision_3: 0.8574 - recall_3: 0.7985 - val_loss: 0.1700 - val_accuracy: 0.9167 - val_auc_3: 0.9613 - val_precision_3: 0.8574 - val_recall_3: 0.7986\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3070 - accuracy: 0.8800 - auc_3: 0.9613 - precision_3: 0.8574 - recall_3: 0.7987 - val_loss: 0.1693 - val_accuracy: 0.9167 - val_auc_3: 0.9614 - val_precision_3: 0.8575 - val_recall_3: 0.7988\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2682 - accuracy: 0.8900 - auc_3: 0.9614 - precision_3: 0.8575 - recall_3: 0.7988 - val_loss: 0.1750 - val_accuracy: 0.9167 - val_auc_3: 0.9614 - val_precision_3: 0.8576 - val_recall_3: 0.7990\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3883 - accuracy: 0.8400 - auc_3: 0.9614 - precision_3: 0.8576 - recall_3: 0.7990 - val_loss: 0.1758 - val_accuracy: 0.9167 - val_auc_3: 0.9614 - val_precision_3: 0.8576 - val_recall_3: 0.7990\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2277 - accuracy: 0.9200 - auc_3: 0.9615 - precision_3: 0.8576 - recall_3: 0.7991 - val_loss: 0.1673 - val_accuracy: 0.9167 - val_auc_3: 0.9615 - val_precision_3: 0.8577 - val_recall_3: 0.7993\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3114 - accuracy: 0.8900 - auc_3: 0.9615 - precision_3: 0.8578 - recall_3: 0.7994 - val_loss: 0.1528 - val_accuracy: 0.9167 - val_auc_3: 0.9615 - val_precision_3: 0.8578 - val_recall_3: 0.7994\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.2189 - accuracy: 0.9300 - auc_3: 0.9616 - precision_3: 0.8579 - recall_3: 0.7996 - val_loss: 0.1404 - val_accuracy: 0.9167 - val_auc_3: 0.9616 - val_precision_3: 0.8579 - val_recall_3: 0.7997\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.3105 - accuracy: 0.8600 - auc_3: 0.9616 - precision_3: 0.8580 - recall_3: 0.7997 - val_loss: 0.1362 - val_accuracy: 1.0000 - val_auc_3: 0.9617 - val_precision_3: 0.8580 - val_recall_3: 0.7998\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 0s 150us/step - loss: 0.2608 - accuracy: 0.8900 - auc_3: 0.9617 - precision_3: 0.8581 - recall_3: 0.7999 - val_loss: 0.1368 - val_accuracy: 1.0000 - val_auc_3: 0.9617 - val_precision_3: 0.8581 - val_recall_3: 0.8000\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.3775 - accuracy: 0.8600 - auc_3: 0.9617 - precision_3: 0.8581 - recall_3: 0.8001 - val_loss: 0.1399 - val_accuracy: 1.0000 - val_auc_3: 0.9617 - val_precision_3: 0.8582 - val_recall_3: 0.8001\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2382 - accuracy: 0.9000 - auc_3: 0.9618 - precision_3: 0.8582 - recall_3: 0.8003 - val_loss: 0.1416 - val_accuracy: 1.0000 - val_auc_3: 0.9618 - val_precision_3: 0.8583 - val_recall_3: 0.8003\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2673 - accuracy: 0.8900 - auc_3: 0.9618 - precision_3: 0.8583 - recall_3: 0.8004 - val_loss: 0.1469 - val_accuracy: 1.0000 - val_auc_3: 0.9619 - val_precision_3: 0.8584 - val_recall_3: 0.8005\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 0s 169us/step - loss: 0.2222 - accuracy: 0.9300 - auc_3: 0.9619 - precision_3: 0.8585 - recall_3: 0.8006 - val_loss: 0.1487 - val_accuracy: 1.0000 - val_auc_3: 0.9619 - val_precision_3: 0.8585 - val_recall_3: 0.8007\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.4318 - accuracy: 0.8100 - auc_3: 0.9619 - precision_3: 0.8585 - recall_3: 0.8007 - val_loss: 0.1375 - val_accuracy: 1.0000 - val_auc_3: 0.9619 - val_precision_3: 0.8585 - val_recall_3: 0.8008\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2345 - accuracy: 0.9100 - auc_3: 0.9620 - precision_3: 0.8586 - recall_3: 0.8009 - val_loss: 0.1342 - val_accuracy: 0.9167 - val_auc_3: 0.9620 - val_precision_3: 0.8587 - val_recall_3: 0.8010\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2683 - accuracy: 0.8700 - auc_3: 0.9620 - precision_3: 0.8587 - recall_3: 0.8011 - val_loss: 0.1375 - val_accuracy: 0.9167 - val_auc_3: 0.9620 - val_precision_3: 0.8587 - val_recall_3: 0.8011\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.2640 - accuracy: 0.8800 - auc_3: 0.9621 - precision_3: 0.8587 - recall_3: 0.8012 - val_loss: 0.1427 - val_accuracy: 0.9167 - val_auc_3: 0.9621 - val_precision_3: 0.8587 - val_recall_3: 0.8013\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2362 - accuracy: 0.9200 - auc_3: 0.9621 - precision_3: 0.8588 - recall_3: 0.8013 - val_loss: 0.1474 - val_accuracy: 0.9167 - val_auc_3: 0.9622 - val_precision_3: 0.8589 - val_recall_3: 0.8015\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.2965 - accuracy: 0.8900 - auc_3: 0.9622 - precision_3: 0.8589 - recall_3: 0.8016 - val_loss: 0.1527 - val_accuracy: 0.9167 - val_auc_3: 0.9622 - val_precision_3: 0.8589 - val_recall_3: 0.8016\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2663 - accuracy: 0.8800 - auc_3: 0.9622 - precision_3: 0.8590 - recall_3: 0.8017 - val_loss: 0.1553 - val_accuracy: 0.9167 - val_auc_3: 0.9623 - val_precision_3: 0.8590 - val_recall_3: 0.8018\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.3195 - accuracy: 0.9000 - auc_3: 0.9623 - precision_3: 0.8591 - recall_3: 0.8019 - val_loss: 0.1623 - val_accuracy: 0.9167 - val_auc_3: 0.9623 - val_precision_3: 0.8591 - val_recall_3: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "100/100 [==============================] - 0s 160us/step - loss: 0.2450 - accuracy: 0.9200 - auc_3: 0.9623 - precision_3: 0.8591 - recall_3: 0.8020 - val_loss: 0.1510 - val_accuracy: 0.9167 - val_auc_3: 0.9624 - val_precision_3: 0.8592 - val_recall_3: 0.8022\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3345 - accuracy: 0.8900 - auc_3: 0.9624 - precision_3: 0.8593 - recall_3: 0.8022 - val_loss: 0.1520 - val_accuracy: 0.9167 - val_auc_3: 0.9624 - val_precision_3: 0.8593 - val_recall_3: 0.8023\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.3270 - accuracy: 0.8700 - auc_3: 0.9624 - precision_3: 0.8594 - recall_3: 0.8023 - val_loss: 0.1545 - val_accuracy: 0.9167 - val_auc_3: 0.9624 - val_precision_3: 0.8594 - val_recall_3: 0.8024\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2786 - accuracy: 0.8600 - auc_3: 0.9625 - precision_3: 0.8594 - recall_3: 0.8025 - val_loss: 0.1653 - val_accuracy: 0.9167 - val_auc_3: 0.9625 - val_precision_3: 0.8594 - val_recall_3: 0.8025\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.3639 - accuracy: 0.8200 - auc_3: 0.9625 - precision_3: 0.8594 - recall_3: 0.8025 - val_loss: 0.1675 - val_accuracy: 0.9167 - val_auc_3: 0.9625 - val_precision_3: 0.8594 - val_recall_3: 0.8026\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2538 - accuracy: 0.9000 - auc_3: 0.9625 - precision_3: 0.8594 - recall_3: 0.8026 - val_loss: 0.1847 - val_accuracy: 0.9167 - val_auc_3: 0.9626 - val_precision_3: 0.8595 - val_recall_3: 0.8027\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.3544 - accuracy: 0.8700 - auc_3: 0.9625 - precision_3: 0.8595 - recall_3: 0.8027 - val_loss: 0.2204 - val_accuracy: 0.9167 - val_auc_3: 0.9626 - val_precision_3: 0.8595 - val_recall_3: 0.8028\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3828 - accuracy: 0.8300 - auc_3: 0.9626 - precision_3: 0.8596 - recall_3: 0.8029 - val_loss: 0.2538 - val_accuracy: 0.9167 - val_auc_3: 0.9626 - val_precision_3: 0.8595 - val_recall_3: 0.8029\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.3499 - accuracy: 0.8900 - auc_3: 0.9626 - precision_3: 0.8596 - recall_3: 0.8030 - val_loss: 0.2397 - val_accuracy: 0.9167 - val_auc_3: 0.9626 - val_precision_3: 0.8596 - val_recall_3: 0.8030\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.2057 - accuracy: 0.9300 - auc_3: 0.9626 - precision_3: 0.8597 - recall_3: 0.8032 - val_loss: 0.2193 - val_accuracy: 0.9167 - val_auc_3: 0.9627 - val_precision_3: 0.8597 - val_recall_3: 0.8033\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.2699 - accuracy: 0.8800 - auc_3: 0.9627 - precision_3: 0.8598 - recall_3: 0.8033 - val_loss: 0.2119 - val_accuracy: 0.9167 - val_auc_3: 0.9627 - val_precision_3: 0.8598 - val_recall_3: 0.8034\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.2307 - accuracy: 0.9100 - auc_3: 0.9628 - precision_3: 0.8599 - recall_3: 0.8035 - val_loss: 0.2110 - val_accuracy: 0.9167 - val_auc_3: 0.9628 - val_precision_3: 0.8599 - val_recall_3: 0.8036\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.2911 - accuracy: 0.8700 - auc_3: 0.9628 - precision_3: 0.8600 - recall_3: 0.8037 - val_loss: 0.2119 - val_accuracy: 0.9167 - val_auc_3: 0.9628 - val_precision_3: 0.8600 - val_recall_3: 0.8037\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2998 - accuracy: 0.8800 - auc_3: 0.9628 - precision_3: 0.8600 - recall_3: 0.8038 - val_loss: 0.2229 - val_accuracy: 0.9167 - val_auc_3: 0.9628 - val_precision_3: 0.8600 - val_recall_3: 0.8039\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2375 - accuracy: 0.9000 - auc_3: 0.9629 - precision_3: 0.8601 - recall_3: 0.8039 - val_loss: 0.2200 - val_accuracy: 0.9167 - val_auc_3: 0.9629 - val_precision_3: 0.8601 - val_recall_3: 0.8040\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.2467 - accuracy: 0.9000 - auc_3: 0.9629 - precision_3: 0.8602 - recall_3: 0.8041 - val_loss: 0.2200 - val_accuracy: 0.9167 - val_auc_3: 0.9630 - val_precision_3: 0.8602 - val_recall_3: 0.8042\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2751 - accuracy: 0.8800 - auc_3: 0.9630 - precision_3: 0.8602 - recall_3: 0.8042 - val_loss: 0.2137 - val_accuracy: 0.9167 - val_auc_3: 0.9630 - val_precision_3: 0.8603 - val_recall_3: 0.8043\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 0s 190us/step - loss: 0.1574 - accuracy: 0.9600 - auc_3: 0.9630 - precision_3: 0.8604 - recall_3: 0.8045 - val_loss: 0.2170 - val_accuracy: 0.9167 - val_auc_3: 0.9631 - val_precision_3: 0.8604 - val_recall_3: 0.8046\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2141 - accuracy: 0.9300 - auc_3: 0.9631 - precision_3: 0.8605 - recall_3: 0.8047 - val_loss: 0.2082 - val_accuracy: 0.9167 - val_auc_3: 0.9631 - val_precision_3: 0.8606 - val_recall_3: 0.8048\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.2427 - accuracy: 0.9300 - auc_3: 0.9632 - precision_3: 0.8607 - recall_3: 0.8049 - val_loss: 0.2028 - val_accuracy: 0.9167 - val_auc_3: 0.9632 - val_precision_3: 0.8608 - val_recall_3: 0.8050\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3471 - accuracy: 0.8800 - auc_3: 0.9632 - precision_3: 0.8608 - recall_3: 0.8051 - val_loss: 0.1973 - val_accuracy: 0.9167 - val_auc_3: 0.9632 - val_precision_3: 0.8608 - val_recall_3: 0.8052\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2790 - accuracy: 0.8700 - auc_3: 0.9633 - precision_3: 0.8609 - recall_3: 0.8053 - val_loss: 0.1955 - val_accuracy: 0.9167 - val_auc_3: 0.9633 - val_precision_3: 0.8609 - val_recall_3: 0.8053\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3185 - accuracy: 0.8700 - auc_3: 0.9633 - precision_3: 0.8609 - recall_3: 0.8054 - val_loss: 0.1956 - val_accuracy: 0.9167 - val_auc_3: 0.9633 - val_precision_3: 0.8609 - val_recall_3: 0.8054\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.1971 - accuracy: 0.9300 - auc_3: 0.9633 - precision_3: 0.8610 - recall_3: 0.8055 - val_loss: 0.2018 - val_accuracy: 0.9167 - val_auc_3: 0.9634 - val_precision_3: 0.8611 - val_recall_3: 0.8056\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.5544 - accuracy: 0.7800 - auc_3: 0.9633 - precision_3: 0.8610 - recall_3: 0.8056 - val_loss: 0.2318 - val_accuracy: 0.9167 - val_auc_3: 0.9633 - val_precision_3: 0.8610 - val_recall_3: 0.8056\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2577 - accuracy: 0.9000 - auc_3: 0.9633 - precision_3: 0.8610 - recall_3: 0.8057 - val_loss: 0.2303 - val_accuracy: 0.9167 - val_auc_3: 0.9634 - val_precision_3: 0.8611 - val_recall_3: 0.8058\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2197 - accuracy: 0.9000 - auc_3: 0.9634 - precision_3: 0.8611 - recall_3: 0.8058 - val_loss: 0.2288 - val_accuracy: 0.9167 - val_auc_3: 0.9634 - val_precision_3: 0.8611 - val_recall_3: 0.8059\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2840 - accuracy: 0.9100 - auc_3: 0.9634 - precision_3: 0.8612 - recall_3: 0.8060 - val_loss: 0.2349 - val_accuracy: 0.9167 - val_auc_3: 0.9635 - val_precision_3: 0.8612 - val_recall_3: 0.8061\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.2736 - accuracy: 0.9100 - auc_3: 0.9635 - precision_3: 0.8613 - recall_3: 0.8062 - val_loss: 0.2295 - val_accuracy: 0.9167 - val_auc_3: 0.9635 - val_precision_3: 0.8614 - val_recall_3: 0.8063\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2934 - accuracy: 0.9100 - auc_3: 0.9635 - precision_3: 0.8614 - recall_3: 0.8064 - val_loss: 0.2114 - val_accuracy: 0.9167 - val_auc_3: 0.9635 - val_precision_3: 0.8615 - val_recall_3: 0.8064\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 259us/step - loss: 0.2379 - accuracy: 0.8900 - auc_3: 0.9636 - precision_3: 0.8615 - recall_3: 0.8065 - val_loss: 0.1989 - val_accuracy: 0.9167 - val_auc_3: 0.9636 - val_precision_3: 0.8615 - val_recall_3: 0.8066\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3448 - accuracy: 0.8800 - auc_3: 0.9636 - precision_3: 0.8615 - recall_3: 0.8066 - val_loss: 0.2019 - val_accuracy: 0.9167 - val_auc_3: 0.9636 - val_precision_3: 0.8616 - val_recall_3: 0.8067\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2596 - accuracy: 0.8800 - auc_3: 0.9636 - precision_3: 0.8616 - recall_3: 0.8067 - val_loss: 0.2014 - val_accuracy: 0.9167 - val_auc_3: 0.9637 - val_precision_3: 0.8616 - val_recall_3: 0.8068\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2404 - accuracy: 0.9000 - auc_3: 0.9637 - precision_3: 0.8616 - recall_3: 0.8069 - val_loss: 0.2023 - val_accuracy: 0.9167 - val_auc_3: 0.9637 - val_precision_3: 0.8617 - val_recall_3: 0.8070\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3290 - accuracy: 0.8700 - auc_3: 0.9637 - precision_3: 0.8617 - recall_3: 0.8070 - val_loss: 0.1851 - val_accuracy: 0.9167 - val_auc_3: 0.9637 - val_precision_3: 0.8617 - val_recall_3: 0.8071\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2421 - accuracy: 0.9100 - auc_3: 0.9637 - precision_3: 0.8617 - recall_3: 0.8071 - val_loss: 0.1799 - val_accuracy: 0.9167 - val_auc_3: 0.9638 - val_precision_3: 0.8618 - val_recall_3: 0.8072\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.5898 - accuracy: 0.7700 - auc_3: 0.9638 - precision_3: 0.8618 - recall_3: 0.8072 - val_loss: 0.1812 - val_accuracy: 0.9167 - val_auc_3: 0.9637 - val_precision_3: 0.8617 - val_recall_3: 0.8071\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2330 - accuracy: 0.9500 - auc_3: 0.9638 - precision_3: 0.8618 - recall_3: 0.8073 - val_loss: 0.1902 - val_accuracy: 0.9167 - val_auc_3: 0.9638 - val_precision_3: 0.8618 - val_recall_3: 0.8074\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.3132 - accuracy: 0.8600 - auc_3: 0.9638 - precision_3: 0.8618 - recall_3: 0.8074 - val_loss: 0.1949 - val_accuracy: 0.9167 - val_auc_3: 0.9638 - val_precision_3: 0.8619 - val_recall_3: 0.8075\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2240 - accuracy: 0.9000 - auc_3: 0.9638 - precision_3: 0.8619 - recall_3: 0.8075 - val_loss: 0.2065 - val_accuracy: 0.9167 - val_auc_3: 0.9639 - val_precision_3: 0.8619 - val_recall_3: 0.8076\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2338 - accuracy: 0.9300 - auc_3: 0.9639 - precision_3: 0.8620 - recall_3: 0.8077 - val_loss: 0.2046 - val_accuracy: 0.9167 - val_auc_3: 0.9639 - val_precision_3: 0.8621 - val_recall_3: 0.8078\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.4062 - accuracy: 0.8300 - auc_3: 0.9639 - precision_3: 0.8620 - recall_3: 0.8078 - val_loss: 0.2019 - val_accuracy: 0.9167 - val_auc_3: 0.9639 - val_precision_3: 0.8620 - val_recall_3: 0.8079\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3887 - accuracy: 0.8700 - auc_3: 0.9639 - precision_3: 0.8620 - recall_3: 0.8079 - val_loss: 0.2200 - val_accuracy: 0.9167 - val_auc_3: 0.9639 - val_precision_3: 0.8621 - val_recall_3: 0.8080\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3616 - accuracy: 0.8700 - auc_3: 0.9639 - precision_3: 0.8621 - recall_3: 0.8080 - val_loss: 0.2147 - val_accuracy: 0.9167 - val_auc_3: 0.9639 - val_precision_3: 0.8621 - val_recall_3: 0.8081\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3009 - accuracy: 0.8800 - auc_3: 0.9639 - precision_3: 0.8621 - recall_3: 0.8081 - val_loss: 0.2069 - val_accuracy: 0.9167 - val_auc_3: 0.9640 - val_precision_3: 0.8621 - val_recall_3: 0.8082\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3340 - accuracy: 0.8800 - auc_3: 0.9640 - precision_3: 0.8622 - recall_3: 0.8083 - val_loss: 0.1981 - val_accuracy: 0.9167 - val_auc_3: 0.9640 - val_precision_3: 0.8622 - val_recall_3: 0.8083\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2749 - accuracy: 0.8700 - auc_3: 0.9640 - precision_3: 0.8622 - recall_3: 0.8084 - val_loss: 0.1834 - val_accuracy: 0.9167 - val_auc_3: 0.9640 - val_precision_3: 0.8622 - val_recall_3: 0.8084\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3450 - accuracy: 0.8300 - auc_3: 0.9640 - precision_3: 0.8622 - recall_3: 0.8084 - val_loss: 0.1804 - val_accuracy: 0.9167 - val_auc_3: 0.9640 - val_precision_3: 0.8622 - val_recall_3: 0.8085\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.3583 - accuracy: 0.8500 - auc_3: 0.9640 - precision_3: 0.8622 - recall_3: 0.8085 - val_loss: 0.1897 - val_accuracy: 0.9167 - val_auc_3: 0.9640 - val_precision_3: 0.8622 - val_recall_3: 0.8086\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.4051 - accuracy: 0.8200 - auc_3: 0.9640 - precision_3: 0.8622 - recall_3: 0.8085 - val_loss: 0.1824 - val_accuracy: 0.9167 - val_auc_3: 0.9640 - val_precision_3: 0.8622 - val_recall_3: 0.8086\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.1951 - accuracy: 0.9200 - auc_3: 0.9641 - precision_3: 0.8623 - recall_3: 0.8087 - val_loss: 0.1850 - val_accuracy: 0.9167 - val_auc_3: 0.9641 - val_precision_3: 0.8623 - val_recall_3: 0.8087\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2490 - accuracy: 0.9100 - auc_3: 0.9641 - precision_3: 0.8624 - recall_3: 0.8088 - val_loss: 0.1890 - val_accuracy: 0.9167 - val_auc_3: 0.9641 - val_precision_3: 0.8624 - val_recall_3: 0.8089\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3691 - accuracy: 0.8800 - auc_3: 0.9641 - precision_3: 0.8624 - recall_3: 0.8090 - val_loss: 0.1893 - val_accuracy: 0.9167 - val_auc_3: 0.9642 - val_precision_3: 0.8624 - val_recall_3: 0.8090\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.3239 - accuracy: 0.8700 - auc_3: 0.9642 - precision_3: 0.8624 - recall_3: 0.8090 - val_loss: 0.1875 - val_accuracy: 0.9167 - val_auc_3: 0.9642 - val_precision_3: 0.8625 - val_recall_3: 0.8091\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.3501 - accuracy: 0.8500 - auc_3: 0.9642 - precision_3: 0.8625 - recall_3: 0.8091 - val_loss: 0.1888 - val_accuracy: 0.9167 - val_auc_3: 0.9642 - val_precision_3: 0.8625 - val_recall_3: 0.8092\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2180 - accuracy: 0.9200 - auc_3: 0.9642 - precision_3: 0.8626 - recall_3: 0.8093 - val_loss: 0.2039 - val_accuracy: 0.9167 - val_auc_3: 0.9642 - val_precision_3: 0.8626 - val_recall_3: 0.8094\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.3496 - accuracy: 0.9100 - auc_3: 0.9643 - precision_3: 0.8627 - recall_3: 0.8095 - val_loss: 0.2171 - val_accuracy: 0.9167 - val_auc_3: 0.9643 - val_precision_3: 0.8627 - val_recall_3: 0.8095\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.2875 - accuracy: 0.9200 - auc_3: 0.9643 - precision_3: 0.8628 - recall_3: 0.8096 - val_loss: 0.2293 - val_accuracy: 0.9167 - val_auc_3: 0.9643 - val_precision_3: 0.8628 - val_recall_3: 0.8096\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3142 - accuracy: 0.8300 - auc_3: 0.9643 - precision_3: 0.8628 - recall_3: 0.8097 - val_loss: 0.2286 - val_accuracy: 0.9167 - val_auc_3: 0.9643 - val_precision_3: 0.8628 - val_recall_3: 0.8097\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3304 - accuracy: 0.8900 - auc_3: 0.9643 - precision_3: 0.8629 - recall_3: 0.8098 - val_loss: 0.2163 - val_accuracy: 0.9167 - val_auc_3: 0.9644 - val_precision_3: 0.8629 - val_recall_3: 0.8098\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 279us/step - loss: 0.2370 - accuracy: 0.8800 - auc_3: 0.9644 - precision_3: 0.8629 - recall_3: 0.8099 - val_loss: 0.2038 - val_accuracy: 0.9167 - val_auc_3: 0.9644 - val_precision_3: 0.8629 - val_recall_3: 0.8099\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.2589 - accuracy: 0.8900 - auc_3: 0.9644 - precision_3: 0.8629 - recall_3: 0.8099 - val_loss: 0.1971 - val_accuracy: 0.9167 - val_auc_3: 0.9644 - val_precision_3: 0.8630 - val_recall_3: 0.8100\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2194 - accuracy: 0.9300 - auc_3: 0.9645 - precision_3: 0.8630 - recall_3: 0.8101 - val_loss: 0.1947 - val_accuracy: 0.9167 - val_auc_3: 0.9645 - val_precision_3: 0.8631 - val_recall_3: 0.8102\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2583 - accuracy: 0.8900 - auc_3: 0.9645 - precision_3: 0.8631 - recall_3: 0.8103 - val_loss: 0.1960 - val_accuracy: 0.9167 - val_auc_3: 0.9645 - val_precision_3: 0.8631 - val_recall_3: 0.8104\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2844 - accuracy: 0.8600 - auc_3: 0.9646 - precision_3: 0.8632 - recall_3: 0.8104 - val_loss: 0.2050 - val_accuracy: 0.9167 - val_auc_3: 0.9646 - val_precision_3: 0.8632 - val_recall_3: 0.8104\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.2148 - accuracy: 0.9300 - auc_3: 0.9646 - precision_3: 0.8632 - recall_3: 0.8105 - val_loss: 0.1967 - val_accuracy: 0.9167 - val_auc_3: 0.9646 - val_precision_3: 0.8633 - val_recall_3: 0.8106\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.2590 - accuracy: 0.8900 - auc_3: 0.9647 - precision_3: 0.8633 - recall_3: 0.8107 - val_loss: 0.2028 - val_accuracy: 0.9167 - val_auc_3: 0.9647 - val_precision_3: 0.8633 - val_recall_3: 0.8108\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.2749 - accuracy: 0.8900 - auc_3: 0.9647 - precision_3: 0.8634 - recall_3: 0.8108 - val_loss: 0.2013 - val_accuracy: 0.9167 - val_auc_3: 0.9647 - val_precision_3: 0.8634 - val_recall_3: 0.8109\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.2572 - accuracy: 0.8700 - auc_3: 0.9647 - precision_3: 0.8635 - recall_3: 0.8110 - val_loss: 0.2106 - val_accuracy: 0.9167 - val_auc_3: 0.9648 - val_precision_3: 0.8635 - val_recall_3: 0.8110\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2627 - accuracy: 0.9200 - auc_3: 0.9648 - precision_3: 0.8635 - recall_3: 0.8111 - val_loss: 0.2109 - val_accuracy: 0.9167 - val_auc_3: 0.9648 - val_precision_3: 0.8636 - val_recall_3: 0.8112\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2317 - accuracy: 0.9100 - auc_3: 0.9648 - precision_3: 0.8636 - recall_3: 0.8112 - val_loss: 0.2146 - val_accuracy: 0.9167 - val_auc_3: 0.9648 - val_precision_3: 0.8636 - val_recall_3: 0.8113\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.2820 - accuracy: 0.9000 - auc_3: 0.9649 - precision_3: 0.8637 - recall_3: 0.8114 - val_loss: 0.2237 - val_accuracy: 0.9167 - val_auc_3: 0.9649 - val_precision_3: 0.8637 - val_recall_3: 0.8115\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.2638 - accuracy: 0.9100 - auc_3: 0.9649 - precision_3: 0.8638 - recall_3: 0.8115 - val_loss: 0.2262 - val_accuracy: 0.9167 - val_auc_3: 0.9649 - val_precision_3: 0.8638 - val_recall_3: 0.8116\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 0s 306us/step - loss: 0.3898 - accuracy: 0.8200 - auc_3: 0.9649 - precision_3: 0.8638 - recall_3: 0.8116 - val_loss: 0.2330 - val_accuracy: 0.9167 - val_auc_3: 0.9649 - val_precision_3: 0.8638 - val_recall_3: 0.8117\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2065 - accuracy: 0.9300 - auc_3: 0.9650 - precision_3: 0.8638 - recall_3: 0.8118 - val_loss: 0.2337 - val_accuracy: 0.9167 - val_auc_3: 0.9650 - val_precision_3: 0.8639 - val_recall_3: 0.8119\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.1763 - accuracy: 0.9400 - auc_3: 0.9650 - precision_3: 0.8640 - recall_3: 0.8119 - val_loss: 0.2309 - val_accuracy: 0.9167 - val_auc_3: 0.9650 - val_precision_3: 0.8640 - val_recall_3: 0.8120\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2343 - accuracy: 0.8800 - auc_3: 0.9651 - precision_3: 0.8641 - recall_3: 0.8121 - val_loss: 0.2141 - val_accuracy: 0.9167 - val_auc_3: 0.9651 - val_precision_3: 0.8641 - val_recall_3: 0.8122\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 0s 234us/step - loss: 0.2089 - accuracy: 0.9100 - auc_3: 0.9651 - precision_3: 0.8641 - recall_3: 0.8123 - val_loss: 0.2081 - val_accuracy: 0.9167 - val_auc_3: 0.9651 - val_precision_3: 0.8642 - val_recall_3: 0.8123\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2946 - accuracy: 0.8800 - auc_3: 0.9652 - precision_3: 0.8642 - recall_3: 0.8124 - val_loss: 0.2147 - val_accuracy: 0.9167 - val_auc_3: 0.9652 - val_precision_3: 0.8642 - val_recall_3: 0.8124\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2969 - accuracy: 0.8500 - auc_3: 0.9652 - precision_3: 0.8642 - recall_3: 0.8124 - val_loss: 0.2159 - val_accuracy: 0.9167 - val_auc_3: 0.9652 - val_precision_3: 0.8642 - val_recall_3: 0.8125\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2174 - accuracy: 0.9200 - auc_3: 0.9652 - precision_3: 0.8642 - recall_3: 0.8126 - val_loss: 0.2138 - val_accuracy: 0.9167 - val_auc_3: 0.9652 - val_precision_3: 0.8643 - val_recall_3: 0.8126\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3560 - accuracy: 0.8200 - auc_3: 0.9653 - precision_3: 0.8643 - recall_3: 0.8126 - val_loss: 0.1920 - val_accuracy: 0.9167 - val_auc_3: 0.9653 - val_precision_3: 0.8642 - val_recall_3: 0.8127\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2225 - accuracy: 0.9100 - auc_3: 0.9653 - precision_3: 0.8643 - recall_3: 0.8127 - val_loss: 0.1600 - val_accuracy: 0.9167 - val_auc_3: 0.9653 - val_precision_3: 0.8643 - val_recall_3: 0.8128\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2142 - accuracy: 0.9100 - auc_3: 0.9653 - precision_3: 0.8644 - recall_3: 0.8129 - val_loss: 0.1430 - val_accuracy: 0.9167 - val_auc_3: 0.9654 - val_precision_3: 0.8644 - val_recall_3: 0.8130\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2276 - accuracy: 0.9200 - auc_3: 0.9654 - precision_3: 0.8645 - recall_3: 0.8130 - val_loss: 0.1369 - val_accuracy: 0.9167 - val_auc_3: 0.9654 - val_precision_3: 0.8645 - val_recall_3: 0.8131\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3474 - accuracy: 0.8800 - auc_3: 0.9654 - precision_3: 0.8645 - recall_3: 0.8132 - val_loss: 0.1365 - val_accuracy: 0.9167 - val_auc_3: 0.9654 - val_precision_3: 0.8645 - val_recall_3: 0.8132\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.3592 - accuracy: 0.8400 - auc_3: 0.9654 - precision_3: 0.8645 - recall_3: 0.8132 - val_loss: 0.1438 - val_accuracy: 0.9167 - val_auc_3: 0.9654 - val_precision_3: 0.8645 - val_recall_3: 0.8132\n",
      "Epoch 118/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3290 - accuracy: 0.8800 - auc_3: 0.9655 - precision_3: 0.8646 - recall_3: 0.8133 - val_loss: 0.1444 - val_accuracy: 0.9167 - val_auc_3: 0.9655 - val_precision_3: 0.8646 - val_recall_3: 0.8133\n",
      "Epoch 119/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2757 - accuracy: 0.8600 - auc_3: 0.9655 - precision_3: 0.8646 - recall_3: 0.8134 - val_loss: 0.1583 - val_accuracy: 0.9167 - val_auc_3: 0.9655 - val_precision_3: 0.8646 - val_recall_3: 0.8134\n",
      "Epoch 120/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3340 - accuracy: 0.8700 - auc_3: 0.9655 - precision_3: 0.8646 - recall_3: 0.8135 - val_loss: 0.2065 - val_accuracy: 0.9167 - val_auc_3: 0.9655 - val_precision_3: 0.8646 - val_recall_3: 0.8135\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 239us/step - loss: 0.3069 - accuracy: 0.8600 - auc_3: 0.9655 - precision_3: 0.8646 - recall_3: 0.8135 - val_loss: 0.2480 - val_accuracy: 0.9167 - val_auc_3: 0.9655 - val_precision_3: 0.8646 - val_recall_3: 0.8136\n",
      "Epoch 122/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2660 - accuracy: 0.9300 - auc_3: 0.9656 - precision_3: 0.8647 - recall_3: 0.8137 - val_loss: 0.2806 - val_accuracy: 0.9167 - val_auc_3: 0.9656 - val_precision_3: 0.8647 - val_recall_3: 0.8137\n",
      "Epoch 123/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2327 - accuracy: 0.8900 - auc_3: 0.9656 - precision_3: 0.8648 - recall_3: 0.8138 - val_loss: 0.3072 - val_accuracy: 0.9167 - val_auc_3: 0.9656 - val_precision_3: 0.8648 - val_recall_3: 0.8139\n",
      "Epoch 124/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2035 - accuracy: 0.9400 - auc_3: 0.9656 - precision_3: 0.8648 - recall_3: 0.8140 - val_loss: 0.3274 - val_accuracy: 0.9167 - val_auc_3: 0.9657 - val_precision_3: 0.8649 - val_recall_3: 0.8141\n",
      "Epoch 125/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2651 - accuracy: 0.8900 - auc_3: 0.9657 - precision_3: 0.8649 - recall_3: 0.8141 - val_loss: 0.3486 - val_accuracy: 0.9167 - val_auc_3: 0.9657 - val_precision_3: 0.8650 - val_recall_3: 0.8142\n",
      "Epoch 126/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2902 - accuracy: 0.8800 - auc_3: 0.9657 - precision_3: 0.8650 - recall_3: 0.8142 - val_loss: 0.3520 - val_accuracy: 0.9167 - val_auc_3: 0.9657 - val_precision_3: 0.8650 - val_recall_3: 0.8143\n",
      "Epoch 127/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2358 - accuracy: 0.9000 - auc_3: 0.9657 - precision_3: 0.8651 - recall_3: 0.8144 - val_loss: 0.3495 - val_accuracy: 0.9167 - val_auc_3: 0.9658 - val_precision_3: 0.8651 - val_recall_3: 0.8144\n",
      "Epoch 128/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.3088 - accuracy: 0.8800 - auc_3: 0.9658 - precision_3: 0.8651 - recall_3: 0.8145 - val_loss: 0.3219 - val_accuracy: 0.9167 - val_auc_3: 0.9658 - val_precision_3: 0.8651 - val_recall_3: 0.8145\n",
      "Epoch 129/500\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.3274 - accuracy: 0.8900 - auc_3: 0.9658 - precision_3: 0.8652 - recall_3: 0.8146 - val_loss: 0.3079 - val_accuracy: 0.9167 - val_auc_3: 0.9658 - val_precision_3: 0.8652 - val_recall_3: 0.8146\n",
      "Epoch 130/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3569 - accuracy: 0.8600 - auc_3: 0.9658 - precision_3: 0.8652 - recall_3: 0.8147 - val_loss: 0.2791 - val_accuracy: 0.9167 - val_auc_3: 0.9658 - val_precision_3: 0.8652 - val_recall_3: 0.8147\n",
      "Epoch 131/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2737 - accuracy: 0.8900 - auc_3: 0.9658 - precision_3: 0.8652 - recall_3: 0.8148 - val_loss: 0.2659 - val_accuracy: 0.9167 - val_auc_3: 0.9658 - val_precision_3: 0.8653 - val_recall_3: 0.8148\n",
      "Epoch 132/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2985 - accuracy: 0.8800 - auc_3: 0.9658 - precision_3: 0.8653 - recall_3: 0.8149 - val_loss: 0.2750 - val_accuracy: 0.9167 - val_auc_3: 0.9659 - val_precision_3: 0.8653 - val_recall_3: 0.8149\n",
      "Epoch 133/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.1986 - accuracy: 0.9200 - auc_3: 0.9659 - precision_3: 0.8654 - recall_3: 0.8150 - val_loss: 0.2742 - val_accuracy: 0.9167 - val_auc_3: 0.9659 - val_precision_3: 0.8654 - val_recall_3: 0.8151\n",
      "Epoch 134/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2306 - accuracy: 0.9200 - auc_3: 0.9659 - precision_3: 0.8655 - recall_3: 0.8152 - val_loss: 0.2654 - val_accuracy: 0.9167 - val_auc_3: 0.9660 - val_precision_3: 0.8655 - val_recall_3: 0.8152\n",
      "Epoch 135/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2165 - accuracy: 0.9200 - auc_3: 0.9660 - precision_3: 0.8656 - recall_3: 0.8153 - val_loss: 0.2490 - val_accuracy: 0.9167 - val_auc_3: 0.9660 - val_precision_3: 0.8656 - val_recall_3: 0.8154\n",
      "Epoch 136/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2274 - accuracy: 0.9400 - auc_3: 0.9660 - precision_3: 0.8657 - recall_3: 0.8155 - val_loss: 0.2363 - val_accuracy: 0.9167 - val_auc_3: 0.9660 - val_precision_3: 0.8657 - val_recall_3: 0.8156\n",
      "Epoch 137/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.3933 - accuracy: 0.8300 - auc_3: 0.9661 - precision_3: 0.8657 - recall_3: 0.8156 - val_loss: 0.2166 - val_accuracy: 0.9167 - val_auc_3: 0.9660 - val_precision_3: 0.8657 - val_recall_3: 0.8156\n",
      "Epoch 138/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2492 - accuracy: 0.8900 - auc_3: 0.9661 - precision_3: 0.8657 - recall_3: 0.8157 - val_loss: 0.1945 - val_accuracy: 0.9167 - val_auc_3: 0.9661 - val_precision_3: 0.8657 - val_recall_3: 0.8157\n",
      "Epoch 139/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2407 - accuracy: 0.8900 - auc_3: 0.9661 - precision_3: 0.8658 - recall_3: 0.8158 - val_loss: 0.1678 - val_accuracy: 0.9167 - val_auc_3: 0.9661 - val_precision_3: 0.8658 - val_recall_3: 0.8159\n",
      "Epoch 140/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2969 - accuracy: 0.8900 - auc_3: 0.9661 - precision_3: 0.8658 - recall_3: 0.8159 - val_loss: 0.1602 - val_accuracy: 0.9167 - val_auc_3: 0.9661 - val_precision_3: 0.8658 - val_recall_3: 0.8160\n",
      "Epoch 141/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2540 - accuracy: 0.9300 - auc_3: 0.9662 - precision_3: 0.8659 - recall_3: 0.8161 - val_loss: 0.1630 - val_accuracy: 0.9167 - val_auc_3: 0.9662 - val_precision_3: 0.8659 - val_recall_3: 0.8161\n",
      "Epoch 142/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2149 - accuracy: 0.9100 - auc_3: 0.9662 - precision_3: 0.8660 - recall_3: 0.8162 - val_loss: 0.1560 - val_accuracy: 0.9167 - val_auc_3: 0.9662 - val_precision_3: 0.8660 - val_recall_3: 0.8163\n",
      "Epoch 143/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2285 - accuracy: 0.8900 - auc_3: 0.9663 - precision_3: 0.8660 - recall_3: 0.8163 - val_loss: 0.1529 - val_accuracy: 0.9167 - val_auc_3: 0.9663 - val_precision_3: 0.8660 - val_recall_3: 0.8164\n",
      "Epoch 144/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3983 - accuracy: 0.8400 - auc_3: 0.9663 - precision_3: 0.8660 - recall_3: 0.8164 - val_loss: 0.1571 - val_accuracy: 0.9167 - val_auc_3: 0.9663 - val_precision_3: 0.8660 - val_recall_3: 0.8164\n",
      "Epoch 145/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2777 - accuracy: 0.9000 - auc_3: 0.9663 - precision_3: 0.8661 - recall_3: 0.8165 - val_loss: 0.1734 - val_accuracy: 0.9167 - val_auc_3: 0.9663 - val_precision_3: 0.8661 - val_recall_3: 0.8165\n",
      "Epoch 146/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2317 - accuracy: 0.9400 - auc_3: 0.9663 - precision_3: 0.8662 - recall_3: 0.8166 - val_loss: 0.1721 - val_accuracy: 0.9167 - val_auc_3: 0.9664 - val_precision_3: 0.8662 - val_recall_3: 0.8167\n",
      "Epoch 147/500\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.4765 - accuracy: 0.7600 - auc_3: 0.9663 - precision_3: 0.8661 - recall_3: 0.8167 - val_loss: 0.1722 - val_accuracy: 0.9167 - val_auc_3: 0.9663 - val_precision_3: 0.8661 - val_recall_3: 0.8167\n",
      "Epoch 148/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2222 - accuracy: 0.9200 - auc_3: 0.9663 - precision_3: 0.8661 - recall_3: 0.8167 - val_loss: 0.1691 - val_accuracy: 0.9167 - val_auc_3: 0.9664 - val_precision_3: 0.8662 - val_recall_3: 0.8168\n",
      "Epoch 149/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2913 - accuracy: 0.9300 - auc_3: 0.9664 - precision_3: 0.8663 - recall_3: 0.8169 - val_loss: 0.1635 - val_accuracy: 0.9167 - val_auc_3: 0.9664 - val_precision_3: 0.8663 - val_recall_3: 0.8169\n",
      "Epoch 150/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2812 - accuracy: 0.8500 - auc_3: 0.9664 - precision_3: 0.8663 - recall_3: 0.8169 - val_loss: 0.1837 - val_accuracy: 0.9167 - val_auc_3: 0.9664 - val_precision_3: 0.8663 - val_recall_3: 0.8170\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 190us/step - loss: 0.2365 - accuracy: 0.8900 - auc_3: 0.9665 - precision_3: 0.8663 - recall_3: 0.8171 - val_loss: 0.2069 - val_accuracy: 0.9167 - val_auc_3: 0.9665 - val_precision_3: 0.8663 - val_recall_3: 0.8171\n",
      "Epoch 152/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2032 - accuracy: 0.9100 - auc_3: 0.9665 - precision_3: 0.8664 - recall_3: 0.8172 - val_loss: 0.2200 - val_accuracy: 0.9167 - val_auc_3: 0.9665 - val_precision_3: 0.8664 - val_recall_3: 0.8172\n",
      "Epoch 153/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.5201 - accuracy: 0.8000 - auc_3: 0.9665 - precision_3: 0.8663 - recall_3: 0.8172 - val_loss: 0.2291 - val_accuracy: 0.9167 - val_auc_3: 0.9665 - val_precision_3: 0.8663 - val_recall_3: 0.8172\n",
      "Epoch 154/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.1432 - accuracy: 0.9800 - auc_3: 0.9665 - precision_3: 0.8664 - recall_3: 0.8174 - val_loss: 0.2341 - val_accuracy: 0.9167 - val_auc_3: 0.9666 - val_precision_3: 0.8665 - val_recall_3: 0.8175\n",
      "Epoch 155/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2247 - accuracy: 0.9100 - auc_3: 0.9666 - precision_3: 0.8665 - recall_3: 0.8175 - val_loss: 0.2337 - val_accuracy: 0.9167 - val_auc_3: 0.9666 - val_precision_3: 0.8666 - val_recall_3: 0.8176\n",
      "Epoch 156/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2051 - accuracy: 0.9700 - auc_3: 0.9666 - precision_3: 0.8667 - recall_3: 0.8177 - val_loss: 0.2384 - val_accuracy: 0.9167 - val_auc_3: 0.9666 - val_precision_3: 0.8667 - val_recall_3: 0.8178\n",
      "Epoch 157/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2521 - accuracy: 0.9000 - auc_3: 0.9667 - precision_3: 0.8667 - recall_3: 0.8179 - val_loss: 0.2291 - val_accuracy: 0.9167 - val_auc_3: 0.9667 - val_precision_3: 0.8668 - val_recall_3: 0.8180\n",
      "Epoch 158/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2908 - accuracy: 0.8800 - auc_3: 0.9667 - precision_3: 0.8668 - recall_3: 0.8180 - val_loss: 0.2228 - val_accuracy: 0.9167 - val_auc_3: 0.9667 - val_precision_3: 0.8668 - val_recall_3: 0.8180\n",
      "Epoch 159/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2797 - accuracy: 0.9200 - auc_3: 0.9667 - precision_3: 0.8669 - recall_3: 0.8181 - val_loss: 0.1970 - val_accuracy: 0.9167 - val_auc_3: 0.9667 - val_precision_3: 0.8669 - val_recall_3: 0.8181\n",
      "Epoch 160/500\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.3347 - accuracy: 0.8100 - auc_3: 0.9667 - precision_3: 0.8669 - recall_3: 0.8181 - val_loss: 0.1709 - val_accuracy: 0.9167 - val_auc_3: 0.9667 - val_precision_3: 0.8669 - val_recall_3: 0.8181\n",
      "Epoch 161/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3314 - accuracy: 0.8800 - auc_3: 0.9667 - precision_3: 0.8669 - recall_3: 0.8182 - val_loss: 0.1606 - val_accuracy: 0.9167 - val_auc_3: 0.9668 - val_precision_3: 0.8669 - val_recall_3: 0.8182\n",
      "Epoch 162/500\n",
      "100/100 [==============================] - 0s 169us/step - loss: 0.2231 - accuracy: 0.9100 - auc_3: 0.9668 - precision_3: 0.8669 - recall_3: 0.8183 - val_loss: 0.1584 - val_accuracy: 0.9167 - val_auc_3: 0.9668 - val_precision_3: 0.8670 - val_recall_3: 0.8184\n",
      "Epoch 163/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2893 - accuracy: 0.8900 - auc_3: 0.9668 - precision_3: 0.8670 - recall_3: 0.8184 - val_loss: 0.1649 - val_accuracy: 0.9167 - val_auc_3: 0.9668 - val_precision_3: 0.8670 - val_recall_3: 0.8185\n",
      "Epoch 164/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2947 - accuracy: 0.8700 - auc_3: 0.9668 - precision_3: 0.8670 - recall_3: 0.8185 - val_loss: 0.2044 - val_accuracy: 0.9167 - val_auc_3: 0.9668 - val_precision_3: 0.8671 - val_recall_3: 0.8186\n",
      "Epoch 165/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.3081 - accuracy: 0.8700 - auc_3: 0.9668 - precision_3: 0.8670 - recall_3: 0.8186 - val_loss: 0.2141 - val_accuracy: 0.9167 - val_auc_3: 0.9669 - val_precision_3: 0.8671 - val_recall_3: 0.8186\n",
      "Epoch 166/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2403 - accuracy: 0.9000 - auc_3: 0.9669 - precision_3: 0.8671 - recall_3: 0.8187 - val_loss: 0.2166 - val_accuracy: 0.9167 - val_auc_3: 0.9669 - val_precision_3: 0.8671 - val_recall_3: 0.8188\n",
      "Epoch 167/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.4089 - accuracy: 0.8300 - auc_3: 0.9669 - precision_3: 0.8671 - recall_3: 0.8188 - val_loss: 0.1981 - val_accuracy: 0.9167 - val_auc_3: 0.9669 - val_precision_3: 0.8671 - val_recall_3: 0.8188\n",
      "Epoch 168/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2716 - accuracy: 0.8900 - auc_3: 0.9669 - precision_3: 0.8671 - recall_3: 0.8188 - val_loss: 0.1570 - val_accuracy: 0.9167 - val_auc_3: 0.9669 - val_precision_3: 0.8671 - val_recall_3: 0.8189\n",
      "Epoch 169/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2890 - accuracy: 0.9100 - auc_3: 0.9669 - precision_3: 0.8672 - recall_3: 0.8189 - val_loss: 0.1448 - val_accuracy: 0.9167 - val_auc_3: 0.9669 - val_precision_3: 0.8672 - val_recall_3: 0.8190\n",
      "Epoch 170/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2459 - accuracy: 0.9000 - auc_3: 0.9670 - precision_3: 0.8672 - recall_3: 0.8191 - val_loss: 0.1502 - val_accuracy: 0.9167 - val_auc_3: 0.9670 - val_precision_3: 0.8673 - val_recall_3: 0.8191\n",
      "Epoch 171/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2061 - accuracy: 0.9300 - auc_3: 0.9670 - precision_3: 0.8673 - recall_3: 0.8192 - val_loss: 0.1633 - val_accuracy: 0.9167 - val_auc_3: 0.9670 - val_precision_3: 0.8674 - val_recall_3: 0.8193\n",
      "Epoch 172/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2712 - accuracy: 0.8800 - auc_3: 0.9671 - precision_3: 0.8674 - recall_3: 0.8193 - val_loss: 0.1786 - val_accuracy: 0.9167 - val_auc_3: 0.9671 - val_precision_3: 0.8674 - val_recall_3: 0.8193\n",
      "Epoch 173/500\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.3107 - accuracy: 0.8900 - auc_3: 0.9671 - precision_3: 0.8674 - recall_3: 0.8194 - val_loss: 0.2039 - val_accuracy: 0.9167 - val_auc_3: 0.9671 - val_precision_3: 0.8674 - val_recall_3: 0.8194\n",
      "Epoch 174/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3482 - accuracy: 0.8100 - auc_3: 0.9671 - precision_3: 0.8674 - recall_3: 0.8194 - val_loss: 0.2265 - val_accuracy: 0.9167 - val_auc_3: 0.9671 - val_precision_3: 0.8674 - val_recall_3: 0.8194\n",
      "Epoch 175/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2781 - accuracy: 0.8700 - auc_3: 0.9671 - precision_3: 0.8674 - recall_3: 0.8195 - val_loss: 0.2273 - val_accuracy: 0.9167 - val_auc_3: 0.9671 - val_precision_3: 0.8674 - val_recall_3: 0.8195\n",
      "Epoch 176/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2405 - accuracy: 0.9200 - auc_3: 0.9671 - precision_3: 0.8674 - recall_3: 0.8196 - val_loss: 0.2298 - val_accuracy: 0.9167 - val_auc_3: 0.9671 - val_precision_3: 0.8675 - val_recall_3: 0.8197\n",
      "Epoch 177/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.3489 - accuracy: 0.8800 - auc_3: 0.9672 - precision_3: 0.8675 - recall_3: 0.8197 - val_loss: 0.2235 - val_accuracy: 0.9167 - val_auc_3: 0.9672 - val_precision_3: 0.8675 - val_recall_3: 0.8198\n",
      "Epoch 178/500\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.2891 - accuracy: 0.9200 - auc_3: 0.9672 - precision_3: 0.8676 - recall_3: 0.8199 - val_loss: 0.2265 - val_accuracy: 0.9167 - val_auc_3: 0.9672 - val_precision_3: 0.8676 - val_recall_3: 0.8199\n",
      "Epoch 179/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2428 - accuracy: 0.9000 - auc_3: 0.9672 - precision_3: 0.8676 - recall_3: 0.8200 - val_loss: 0.2441 - val_accuracy: 0.9167 - val_auc_3: 0.9672 - val_precision_3: 0.8677 - val_recall_3: 0.8200\n",
      "Epoch 180/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2558 - accuracy: 0.9200 - auc_3: 0.9672 - precision_3: 0.8677 - recall_3: 0.8201 - val_loss: 0.2445 - val_accuracy: 0.9167 - val_auc_3: 0.9673 - val_precision_3: 0.8678 - val_recall_3: 0.8202\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 249us/step - loss: 0.3114 - accuracy: 0.8600 - auc_3: 0.9673 - precision_3: 0.8678 - recall_3: 0.8201 - val_loss: 0.2496 - val_accuracy: 0.9167 - val_auc_3: 0.9673 - val_precision_3: 0.8678 - val_recall_3: 0.8202\n",
      "Epoch 182/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2276 - accuracy: 0.9400 - auc_3: 0.9673 - precision_3: 0.8679 - recall_3: 0.8203 - val_loss: 0.2461 - val_accuracy: 0.9167 - val_auc_3: 0.9673 - val_precision_3: 0.8679 - val_recall_3: 0.8204\n",
      "Epoch 183/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2791 - accuracy: 0.8500 - auc_3: 0.9673 - precision_3: 0.8679 - recall_3: 0.8204 - val_loss: 0.2436 - val_accuracy: 0.9167 - val_auc_3: 0.9673 - val_precision_3: 0.8679 - val_recall_3: 0.8204\n",
      "Epoch 184/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3412 - accuracy: 0.8500 - auc_3: 0.9673 - precision_3: 0.8679 - recall_3: 0.8204 - val_loss: 0.2560 - val_accuracy: 0.9167 - val_auc_3: 0.9673 - val_precision_3: 0.8679 - val_recall_3: 0.8205\n",
      "Epoch 185/500\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.3018 - accuracy: 0.8500 - auc_3: 0.9673 - precision_3: 0.8679 - recall_3: 0.8205 - val_loss: 0.2765 - val_accuracy: 0.9167 - val_auc_3: 0.9673 - val_precision_3: 0.8679 - val_recall_3: 0.8205\n",
      "Epoch 186/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.1958 - accuracy: 0.9200 - auc_3: 0.9674 - precision_3: 0.8679 - recall_3: 0.8206 - val_loss: 0.3013 - val_accuracy: 0.9167 - val_auc_3: 0.9674 - val_precision_3: 0.8680 - val_recall_3: 0.8207\n",
      "Epoch 187/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.1740 - accuracy: 0.9300 - auc_3: 0.9674 - precision_3: 0.8680 - recall_3: 0.8207 - val_loss: 0.2981 - val_accuracy: 0.9167 - val_auc_3: 0.9674 - val_precision_3: 0.8681 - val_recall_3: 0.8208\n",
      "Epoch 188/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2202 - accuracy: 0.9400 - auc_3: 0.9675 - precision_3: 0.8681 - recall_3: 0.8209 - val_loss: 0.2845 - val_accuracy: 0.9167 - val_auc_3: 0.9675 - val_precision_3: 0.8682 - val_recall_3: 0.8210\n",
      "Epoch 189/500\n",
      "100/100 [==============================] - 0s 261us/step - loss: 0.1734 - accuracy: 0.9600 - auc_3: 0.9675 - precision_3: 0.8683 - recall_3: 0.8211 - val_loss: 0.2721 - val_accuracy: 0.9167 - val_auc_3: 0.9675 - val_precision_3: 0.8683 - val_recall_3: 0.8212\n",
      "Epoch 190/500\n",
      "100/100 [==============================] - 0s 449us/step - loss: 0.1904 - accuracy: 0.9200 - auc_3: 0.9676 - precision_3: 0.8684 - recall_3: 0.8213 - val_loss: 0.2656 - val_accuracy: 0.9167 - val_auc_3: 0.9676 - val_precision_3: 0.8684 - val_recall_3: 0.8213\n",
      "Epoch 191/500\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.2299 - accuracy: 0.9100 - auc_3: 0.9676 - precision_3: 0.8684 - recall_3: 0.8214 - val_loss: 0.2750 - val_accuracy: 0.9167 - val_auc_3: 0.9676 - val_precision_3: 0.8685 - val_recall_3: 0.8215\n",
      "Epoch 192/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3033 - accuracy: 0.8700 - auc_3: 0.9676 - precision_3: 0.8685 - recall_3: 0.8215 - val_loss: 0.2746 - val_accuracy: 0.9167 - val_auc_3: 0.9676 - val_precision_3: 0.8685 - val_recall_3: 0.8215\n",
      "Epoch 193/500\n",
      "100/100 [==============================] - 0s 210us/step - loss: 0.2427 - accuracy: 0.9000 - auc_3: 0.9676 - precision_3: 0.8685 - recall_3: 0.8216 - val_loss: 0.2663 - val_accuracy: 0.9167 - val_auc_3: 0.9677 - val_precision_3: 0.8686 - val_recall_3: 0.8216\n",
      "Epoch 194/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2329 - accuracy: 0.9100 - auc_3: 0.9677 - precision_3: 0.8686 - recall_3: 0.8217 - val_loss: 0.2608 - val_accuracy: 0.9167 - val_auc_3: 0.9677 - val_precision_3: 0.8686 - val_recall_3: 0.8218\n",
      "Epoch 195/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3672 - accuracy: 0.8500 - auc_3: 0.9677 - precision_3: 0.8686 - recall_3: 0.8218 - val_loss: 0.2638 - val_accuracy: 0.9167 - val_auc_3: 0.9677 - val_precision_3: 0.8686 - val_recall_3: 0.8218\n",
      "Epoch 196/500\n",
      "100/100 [==============================] - 0s 253us/step - loss: 0.2232 - accuracy: 0.8600 - auc_3: 0.9677 - precision_3: 0.8686 - recall_3: 0.8218 - val_loss: 0.2769 - val_accuracy: 0.9167 - val_auc_3: 0.9677 - val_precision_3: 0.8686 - val_recall_3: 0.8219\n",
      "Epoch 197/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2533 - accuracy: 0.9000 - auc_3: 0.9677 - precision_3: 0.8686 - recall_3: 0.8219 - val_loss: 0.2897 - val_accuracy: 0.9167 - val_auc_3: 0.9678 - val_precision_3: 0.8687 - val_recall_3: 0.8220\n",
      "Epoch 198/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.2652 - accuracy: 0.9100 - auc_3: 0.9678 - precision_3: 0.8687 - recall_3: 0.8221 - val_loss: 0.2929 - val_accuracy: 0.9167 - val_auc_3: 0.9678 - val_precision_3: 0.8687 - val_recall_3: 0.8221\n",
      "Epoch 199/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.3043 - accuracy: 0.8700 - auc_3: 0.9678 - precision_3: 0.8688 - recall_3: 0.8221 - val_loss: 0.2822 - val_accuracy: 0.9167 - val_auc_3: 0.9678 - val_precision_3: 0.8687 - val_recall_3: 0.8222\n",
      "Epoch 200/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2299 - accuracy: 0.9200 - auc_3: 0.9678 - precision_3: 0.8688 - recall_3: 0.8223 - val_loss: 0.2668 - val_accuracy: 0.9167 - val_auc_3: 0.9678 - val_precision_3: 0.8689 - val_recall_3: 0.8223\n",
      "Epoch 201/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.1852 - accuracy: 0.9500 - auc_3: 0.9679 - precision_3: 0.8689 - recall_3: 0.8224 - val_loss: 0.2565 - val_accuracy: 0.9167 - val_auc_3: 0.9679 - val_precision_3: 0.8690 - val_recall_3: 0.8225\n",
      "Epoch 202/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2568 - accuracy: 0.9200 - auc_3: 0.9679 - precision_3: 0.8690 - recall_3: 0.8226 - val_loss: 0.2610 - val_accuracy: 0.9167 - val_auc_3: 0.9679 - val_precision_3: 0.8691 - val_recall_3: 0.8226\n",
      "Epoch 203/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2708 - accuracy: 0.9100 - auc_3: 0.9679 - precision_3: 0.8691 - recall_3: 0.8227 - val_loss: 0.2811 - val_accuracy: 0.9167 - val_auc_3: 0.9679 - val_precision_3: 0.8691 - val_recall_3: 0.8227\n",
      "Epoch 204/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2279 - accuracy: 0.9400 - auc_3: 0.9680 - precision_3: 0.8692 - recall_3: 0.8228 - val_loss: 0.3048 - val_accuracy: 0.9167 - val_auc_3: 0.9680 - val_precision_3: 0.8692 - val_recall_3: 0.8229\n",
      "Epoch 205/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3363 - accuracy: 0.8800 - auc_3: 0.9680 - precision_3: 0.8692 - recall_3: 0.8229 - val_loss: 0.3492 - val_accuracy: 0.9167 - val_auc_3: 0.9680 - val_precision_3: 0.8693 - val_recall_3: 0.8230\n",
      "Epoch 206/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8500 - auc_3: 0.9680 - precision_3: 0.8693 - recall_3: 0.823 - 0s 238us/step - loss: 0.1962 - accuracy: 0.9500 - auc_3: 0.9680 - precision_3: 0.8693 - recall_3: 0.8230 - val_loss: 0.3880 - val_accuracy: 0.9167 - val_auc_3: 0.9680 - val_precision_3: 0.8694 - val_recall_3: 0.8231\n",
      "Epoch 207/500\n",
      "100/100 [==============================] - 0s 314us/step - loss: 0.4219 - accuracy: 0.8300 - auc_3: 0.9680 - precision_3: 0.8693 - recall_3: 0.8231 - val_loss: 0.4265 - val_accuracy: 0.9167 - val_auc_3: 0.9680 - val_precision_3: 0.8693 - val_recall_3: 0.8232\n",
      "Epoch 208/500\n",
      "100/100 [==============================] - 0s 284us/step - loss: 0.2204 - accuracy: 0.9100 - auc_3: 0.9680 - precision_3: 0.8694 - recall_3: 0.8232 - val_loss: 0.4371 - val_accuracy: 0.9167 - val_auc_3: 0.9680 - val_precision_3: 0.8694 - val_recall_3: 0.8233\n",
      "Epoch 209/500\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.2183 - accuracy: 0.9400 - auc_3: 0.9681 - precision_3: 0.8695 - recall_3: 0.8233 - val_loss: 0.4497 - val_accuracy: 0.9167 - val_auc_3: 0.9681 - val_precision_3: 0.8695 - val_recall_3: 0.8234\n",
      "Epoch 210/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.1928 - accuracy: 0.9300 - auc_3: 0.9681 - precision_3: 0.8696 - recall_3: 0.8235 - val_loss: 0.4542 - val_accuracy: 0.9167 - val_auc_3: 0.9681 - val_precision_3: 0.8696 - val_recall_3: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2541 - accuracy: 0.9200 - auc_3: 0.9681 - precision_3: 0.8697 - recall_3: 0.8236 - val_loss: 0.4433 - val_accuracy: 0.9167 - val_auc_3: 0.9681 - val_precision_3: 0.8697 - val_recall_3: 0.8237\n",
      "Epoch 212/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2098 - accuracy: 0.9500 - auc_3: 0.9682 - precision_3: 0.8698 - recall_3: 0.8238 - val_loss: 0.4231 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8698 - val_recall_3: 0.8238\n",
      "Epoch 213/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.4235 - accuracy: 0.8000 - auc_3: 0.9682 - precision_3: 0.8698 - recall_3: 0.8238 - val_loss: 0.4314 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8697 - val_recall_3: 0.8238\n",
      "Epoch 214/500\n",
      "100/100 [==============================] - 0s 234us/step - loss: 0.3303 - accuracy: 0.8800 - auc_3: 0.9681 - precision_3: 0.8697 - recall_3: 0.8238 - val_loss: 0.4299 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8698 - val_recall_3: 0.8239\n",
      "Epoch 215/500\n",
      "100/100 [==============================] - 0s 214us/step - loss: 0.3020 - accuracy: 0.8700 - auc_3: 0.9682 - precision_3: 0.8698 - recall_3: 0.8239 - val_loss: 0.4214 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8698 - val_recall_3: 0.8240\n",
      "Epoch 216/500\n",
      "100/100 [==============================] - 0s 311us/step - loss: 0.2039 - accuracy: 0.9100 - auc_3: 0.9682 - precision_3: 0.8698 - recall_3: 0.8240 - val_loss: 0.3877 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8699 - val_recall_3: 0.8241\n",
      "Epoch 217/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.1783 - accuracy: 0.9500 - auc_3: 0.9682 - precision_3: 0.8699 - recall_3: 0.8241 - val_loss: 0.3506 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8700 - val_recall_3: 0.8242\n",
      "Epoch 218/500\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.2576 - accuracy: 0.8900 - auc_3: 0.9683 - precision_3: 0.8700 - recall_3: 0.8243 - val_loss: 0.3283 - val_accuracy: 0.9167 - val_auc_3: 0.9683 - val_precision_3: 0.8700 - val_recall_3: 0.8243\n",
      "Epoch 219/500\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.4419 - accuracy: 0.8200 - auc_3: 0.9683 - precision_3: 0.8700 - recall_3: 0.8243 - val_loss: 0.3270 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8700 - val_recall_3: 0.8243\n",
      "Epoch 220/500\n",
      "100/100 [==============================] - 0s 287us/step - loss: 0.4174 - accuracy: 0.8600 - auc_3: 0.9683 - precision_3: 0.8700 - recall_3: 0.8243 - val_loss: 0.3030 - val_accuracy: 0.9167 - val_auc_3: 0.9682 - val_precision_3: 0.8700 - val_recall_3: 0.8243\n",
      "Epoch 221/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3124 - accuracy: 0.8400 - auc_3: 0.9682 - precision_3: 0.8699 - recall_3: 0.8243 - val_loss: 0.2851 - val_accuracy: 0.9167 - val_auc_3: 0.9683 - val_precision_3: 0.8700 - val_recall_3: 0.8244\n",
      "Epoch 222/500\n",
      "100/100 [==============================] - 0s 275us/step - loss: 0.2135 - accuracy: 0.9200 - auc_3: 0.9683 - precision_3: 0.8700 - recall_3: 0.8244 - val_loss: 0.2747 - val_accuracy: 0.9167 - val_auc_3: 0.9683 - val_precision_3: 0.8701 - val_recall_3: 0.8244\n",
      "Epoch 223/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.3564 - accuracy: 0.8800 - auc_3: 0.9683 - precision_3: 0.8701 - recall_3: 0.8245 - val_loss: 0.2602 - val_accuracy: 0.9167 - val_auc_3: 0.9683 - val_precision_3: 0.8701 - val_recall_3: 0.8245\n",
      "Epoch 224/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2231 - accuracy: 0.8900 - auc_3: 0.9683 - precision_3: 0.8701 - recall_3: 0.8246 - val_loss: 0.2492 - val_accuracy: 0.9167 - val_auc_3: 0.9683 - val_precision_3: 0.8701 - val_recall_3: 0.8246\n",
      "Epoch 225/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3596 - accuracy: 0.8800 - auc_3: 0.9683 - precision_3: 0.8701 - recall_3: 0.8247 - val_loss: 0.2474 - val_accuracy: 0.9167 - val_auc_3: 0.9683 - val_precision_3: 0.8702 - val_recall_3: 0.8247\n",
      "Epoch 226/500\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.2128 - accuracy: 0.9100 - auc_3: 0.9683 - precision_3: 0.8702 - recall_3: 0.8248 - val_loss: 0.2583 - val_accuracy: 0.9167 - val_auc_3: 0.9684 - val_precision_3: 0.8702 - val_recall_3: 0.8248\n",
      "Epoch 227/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2569 - accuracy: 0.8800 - auc_3: 0.9684 - precision_3: 0.8702 - recall_3: 0.8248 - val_loss: 0.2590 - val_accuracy: 0.9167 - val_auc_3: 0.9684 - val_precision_3: 0.8702 - val_recall_3: 0.8249\n",
      "Epoch 228/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2272 - accuracy: 0.8900 - auc_3: 0.9684 - precision_3: 0.8703 - recall_3: 0.8249 - val_loss: 0.2501 - val_accuracy: 0.9167 - val_auc_3: 0.9684 - val_precision_3: 0.8703 - val_recall_3: 0.8250\n",
      "Epoch 229/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3394 - accuracy: 0.8300 - auc_3: 0.9684 - precision_3: 0.8703 - recall_3: 0.8250 - val_loss: 0.2466 - val_accuracy: 0.9167 - val_auc_3: 0.9684 - val_precision_3: 0.8702 - val_recall_3: 0.8250\n",
      "Epoch 230/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2929 - accuracy: 0.8300 - auc_3: 0.9684 - precision_3: 0.8702 - recall_3: 0.8249 - val_loss: 0.2330 - val_accuracy: 0.9167 - val_auc_3: 0.9684 - val_precision_3: 0.8702 - val_recall_3: 0.8250\n",
      "Epoch 231/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.3119 - accuracy: 0.8800 - auc_3: 0.9684 - precision_3: 0.8702 - recall_3: 0.8250 - val_loss: 0.2040 - val_accuracy: 0.9167 - val_auc_3: 0.9684 - val_precision_3: 0.8702 - val_recall_3: 0.8250\n",
      "Epoch 232/500\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.3201 - accuracy: 0.8700 - auc_3: 0.9684 - precision_3: 0.8702 - recall_3: 0.8250 - val_loss: 0.2070 - val_accuracy: 0.9167 - val_auc_3: 0.9685 - val_precision_3: 0.8702 - val_recall_3: 0.8251\n",
      "Epoch 233/500\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.1904 - accuracy: 0.9300 - auc_3: 0.9685 - precision_3: 0.8703 - recall_3: 0.8251 - val_loss: 0.2101 - val_accuracy: 0.9167 - val_auc_3: 0.9685 - val_precision_3: 0.8703 - val_recall_3: 0.8252\n",
      "Epoch 234/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3085 - accuracy: 0.8800 - auc_3: 0.9685 - precision_3: 0.8703 - recall_3: 0.8252 - val_loss: 0.2040 - val_accuracy: 0.9167 - val_auc_3: 0.9685 - val_precision_3: 0.8703 - val_recall_3: 0.8253\n",
      "Epoch 235/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2386 - accuracy: 0.9200 - auc_3: 0.9685 - precision_3: 0.8704 - recall_3: 0.8254 - val_loss: 0.1984 - val_accuracy: 0.9167 - val_auc_3: 0.9685 - val_precision_3: 0.8704 - val_recall_3: 0.8254\n",
      "Epoch 236/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2553 - accuracy: 0.8800 - auc_3: 0.9685 - precision_3: 0.8704 - recall_3: 0.8254 - val_loss: 0.1985 - val_accuracy: 0.9167 - val_auc_3: 0.9686 - val_precision_3: 0.8704 - val_recall_3: 0.8255\n",
      "Epoch 237/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2443 - accuracy: 0.8800 - auc_3: 0.9686 - precision_3: 0.8704 - recall_3: 0.8255 - val_loss: 0.2074 - val_accuracy: 0.9167 - val_auc_3: 0.9686 - val_precision_3: 0.8705 - val_recall_3: 0.8256\n",
      "Epoch 238/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2742 - accuracy: 0.8500 - auc_3: 0.9686 - precision_3: 0.8705 - recall_3: 0.8256 - val_loss: 0.2156 - val_accuracy: 0.9167 - val_auc_3: 0.9686 - val_precision_3: 0.8705 - val_recall_3: 0.8256\n",
      "Epoch 239/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.1735 - accuracy: 0.9700 - auc_3: 0.9686 - precision_3: 0.8705 - recall_3: 0.8257 - val_loss: 0.2144 - val_accuracy: 0.9167 - val_auc_3: 0.9687 - val_precision_3: 0.8706 - val_recall_3: 0.8257\n",
      "Epoch 240/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2784 - accuracy: 0.8900 - auc_3: 0.9687 - precision_3: 0.8706 - recall_3: 0.8258 - val_loss: 0.1949 - val_accuracy: 0.9167 - val_auc_3: 0.9687 - val_precision_3: 0.8706 - val_recall_3: 0.8258\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 234us/step - loss: 0.3305 - accuracy: 0.8700 - auc_3: 0.9687 - precision_3: 0.8706 - recall_3: 0.8259 - val_loss: 0.1815 - val_accuracy: 0.9167 - val_auc_3: 0.9687 - val_precision_3: 0.8706 - val_recall_3: 0.8259\n",
      "Epoch 242/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2447 - accuracy: 0.8800 - auc_3: 0.9687 - precision_3: 0.8706 - recall_3: 0.8259 - val_loss: 0.1752 - val_accuracy: 0.9167 - val_auc_3: 0.9687 - val_precision_3: 0.8706 - val_recall_3: 0.8260\n",
      "Epoch 243/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.1780 - accuracy: 0.9700 - auc_3: 0.9687 - precision_3: 0.8707 - recall_3: 0.8260 - val_loss: 0.1702 - val_accuracy: 0.9167 - val_auc_3: 0.9688 - val_precision_3: 0.8708 - val_recall_3: 0.8261\n",
      "Epoch 244/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.2146 - accuracy: 0.9300 - auc_3: 0.9688 - precision_3: 0.8708 - recall_3: 0.8262 - val_loss: 0.1665 - val_accuracy: 0.9167 - val_auc_3: 0.9688 - val_precision_3: 0.8709 - val_recall_3: 0.8263\n",
      "Epoch 245/500\n",
      "100/100 [==============================] - 0s 312us/step - loss: 0.2683 - accuracy: 0.8900 - auc_3: 0.9688 - precision_3: 0.8709 - recall_3: 0.8263 - val_loss: 0.1657 - val_accuracy: 0.9167 - val_auc_3: 0.9688 - val_precision_3: 0.8709 - val_recall_3: 0.8263\n",
      "Epoch 246/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2557 - accuracy: 0.9200 - auc_3: 0.9688 - precision_3: 0.8709 - recall_3: 0.8264 - val_loss: 0.1644 - val_accuracy: 0.9167 - val_auc_3: 0.9689 - val_precision_3: 0.8710 - val_recall_3: 0.8265\n",
      "Epoch 247/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2030 - accuracy: 0.9400 - auc_3: 0.9689 - precision_3: 0.8711 - recall_3: 0.8265 - val_loss: 0.1637 - val_accuracy: 0.9167 - val_auc_3: 0.9689 - val_precision_3: 0.8711 - val_recall_3: 0.8266\n",
      "Epoch 248/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2897 - accuracy: 0.8800 - auc_3: 0.9689 - precision_3: 0.8711 - recall_3: 0.8266 - val_loss: 0.1934 - val_accuracy: 0.9167 - val_auc_3: 0.9689 - val_precision_3: 0.8711 - val_recall_3: 0.8267\n",
      "Epoch 249/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3335 - accuracy: 0.8900 - auc_3: 0.9689 - precision_3: 0.8711 - recall_3: 0.8267 - val_loss: 0.2435 - val_accuracy: 0.9167 - val_auc_3: 0.9689 - val_precision_3: 0.8712 - val_recall_3: 0.8268\n",
      "Epoch 250/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2331 - accuracy: 0.8900 - auc_3: 0.9689 - precision_3: 0.8712 - recall_3: 0.8268 - val_loss: 0.2738 - val_accuracy: 0.9167 - val_auc_3: 0.9690 - val_precision_3: 0.8712 - val_recall_3: 0.8268\n",
      "Epoch 251/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.1781 - accuracy: 0.9500 - auc_3: 0.9690 - precision_3: 0.8713 - recall_3: 0.8269 - val_loss: 0.2843 - val_accuracy: 0.9167 - val_auc_3: 0.9690 - val_precision_3: 0.8713 - val_recall_3: 0.8270\n",
      "Epoch 252/500\n",
      "100/100 [==============================] - 0s 292us/step - loss: 0.2865 - accuracy: 0.8800 - auc_3: 0.9690 - precision_3: 0.8713 - recall_3: 0.8270 - val_loss: 0.2841 - val_accuracy: 0.9167 - val_auc_3: 0.9690 - val_precision_3: 0.8713 - val_recall_3: 0.8271\n",
      "Epoch 253/500\n",
      "100/100 [==============================] - 0s 255us/step - loss: 0.2070 - accuracy: 0.9100 - auc_3: 0.9690 - precision_3: 0.8714 - recall_3: 0.8271 - val_loss: 0.2638 - val_accuracy: 0.9167 - val_auc_3: 0.9690 - val_precision_3: 0.8714 - val_recall_3: 0.8272\n",
      "Epoch 254/500\n",
      "100/100 [==============================] - 0s 201us/step - loss: 0.2122 - accuracy: 0.8900 - auc_3: 0.9691 - precision_3: 0.8715 - recall_3: 0.8272 - val_loss: 0.2628 - val_accuracy: 0.9167 - val_auc_3: 0.9691 - val_precision_3: 0.8715 - val_recall_3: 0.8273\n",
      "Epoch 255/500\n",
      "100/100 [==============================] - 0s 258us/step - loss: 0.2181 - accuracy: 0.9200 - auc_3: 0.9691 - precision_3: 0.8715 - recall_3: 0.8273 - val_loss: 0.2726 - val_accuracy: 0.9167 - val_auc_3: 0.9691 - val_precision_3: 0.8715 - val_recall_3: 0.8274\n",
      "Epoch 256/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.1571 - accuracy: 0.9500 - auc_3: 0.9691 - precision_3: 0.8716 - recall_3: 0.8275 - val_loss: 0.2785 - val_accuracy: 0.9167 - val_auc_3: 0.9692 - val_precision_3: 0.8716 - val_recall_3: 0.8275\n",
      "Epoch 257/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2916 - accuracy: 0.8600 - auc_3: 0.9692 - precision_3: 0.8716 - recall_3: 0.8276 - val_loss: 0.2825 - val_accuracy: 0.9167 - val_auc_3: 0.9692 - val_precision_3: 0.8716 - val_recall_3: 0.8276\n",
      "Epoch 258/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2504 - accuracy: 0.8800 - auc_3: 0.9692 - precision_3: 0.8717 - recall_3: 0.8276 - val_loss: 0.2818 - val_accuracy: 0.9167 - val_auc_3: 0.9692 - val_precision_3: 0.8717 - val_recall_3: 0.8276\n",
      "Epoch 259/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2010 - accuracy: 0.9100 - auc_3: 0.9692 - precision_3: 0.8717 - recall_3: 0.8277 - val_loss: 0.2795 - val_accuracy: 0.9167 - val_auc_3: 0.9692 - val_precision_3: 0.8717 - val_recall_3: 0.8277\n",
      "Epoch 260/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2396 - accuracy: 0.8900 - auc_3: 0.9692 - precision_3: 0.8717 - recall_3: 0.8278 - val_loss: 0.2690 - val_accuracy: 0.9167 - val_auc_3: 0.9693 - val_precision_3: 0.8718 - val_recall_3: 0.8278\n",
      "Epoch 261/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2098 - accuracy: 0.9400 - auc_3: 0.9693 - precision_3: 0.8718 - recall_3: 0.8279 - val_loss: 0.2472 - val_accuracy: 0.9167 - val_auc_3: 0.9693 - val_precision_3: 0.8718 - val_recall_3: 0.8280\n",
      "Epoch 262/500\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.2526 - accuracy: 0.8900 - auc_3: 0.9693 - precision_3: 0.8719 - recall_3: 0.8280 - val_loss: 0.2459 - val_accuracy: 0.9167 - val_auc_3: 0.9693 - val_precision_3: 0.8719 - val_recall_3: 0.8280\n",
      "Epoch 263/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.4006 - accuracy: 0.8400 - auc_3: 0.9693 - precision_3: 0.8719 - recall_3: 0.8280 - val_loss: 0.2410 - val_accuracy: 0.9167 - val_auc_3: 0.9693 - val_precision_3: 0.8718 - val_recall_3: 0.8280\n",
      "Epoch 264/500\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.3125 - accuracy: 0.8500 - auc_3: 0.9693 - precision_3: 0.8719 - recall_3: 0.8281 - val_loss: 0.2454 - val_accuracy: 0.9167 - val_auc_3: 0.9693 - val_precision_3: 0.8718 - val_recall_3: 0.8281\n",
      "Epoch 265/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2405 - accuracy: 0.8900 - auc_3: 0.9693 - precision_3: 0.8719 - recall_3: 0.8281 - val_loss: 0.2348 - val_accuracy: 0.9167 - val_auc_3: 0.9693 - val_precision_3: 0.8719 - val_recall_3: 0.8281\n",
      "Epoch 266/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2473 - accuracy: 0.9000 - auc_3: 0.9693 - precision_3: 0.8719 - recall_3: 0.8282 - val_loss: 0.2402 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8719 - val_recall_3: 0.8282\n",
      "Epoch 267/500\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.2992 - accuracy: 0.8500 - auc_3: 0.9694 - precision_3: 0.8719 - recall_3: 0.8283 - val_loss: 0.2387 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8719 - val_recall_3: 0.8283\n",
      "Epoch 268/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.3118 - accuracy: 0.8800 - auc_3: 0.9694 - precision_3: 0.8719 - recall_3: 0.8283 - val_loss: 0.2588 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8719 - val_recall_3: 0.8283\n",
      "Epoch 269/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9500 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.828 - 0s 249us/step - loss: 0.2813 - accuracy: 0.8700 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8284 - val_loss: 0.2674 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8719 - val_recall_3: 0.8284\n",
      "Epoch 270/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2203 - accuracy: 0.9200 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8284 - val_loss: 0.2918 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8720 - val_recall_3: 0.8285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3334 - accuracy: 0.8600 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8285 - val_loss: 0.3137 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8720 - val_recall_3: 0.8286\n",
      "Epoch 272/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2506 - accuracy: 0.8800 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8286 - val_loss: 0.3196 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8720 - val_recall_3: 0.8286\n",
      "Epoch 273/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.5527 - accuracy: 0.8500 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8286 - val_loss: 0.3184 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8720 - val_recall_3: 0.8286\n",
      "Epoch 274/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2403 - accuracy: 0.8900 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8287 - val_loss: 0.3227 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8720 - val_recall_3: 0.8287\n",
      "Epoch 275/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2454 - accuracy: 0.9000 - auc_3: 0.9694 - precision_3: 0.8720 - recall_3: 0.8288 - val_loss: 0.3111 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8721 - val_recall_3: 0.8288\n",
      "Epoch 276/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.3001 - accuracy: 0.8500 - auc_3: 0.9694 - precision_3: 0.8721 - recall_3: 0.8288 - val_loss: 0.2950 - val_accuracy: 0.9167 - val_auc_3: 0.9694 - val_precision_3: 0.8721 - val_recall_3: 0.8288\n",
      "Epoch 277/500\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.2301 - accuracy: 0.8900 - auc_3: 0.9695 - precision_3: 0.8721 - recall_3: 0.8289 - val_loss: 0.2839 - val_accuracy: 0.9167 - val_auc_3: 0.9695 - val_precision_3: 0.8721 - val_recall_3: 0.8289\n",
      "Epoch 278/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2512 - accuracy: 0.9000 - auc_3: 0.9695 - precision_3: 0.8721 - recall_3: 0.8290 - val_loss: 0.2812 - val_accuracy: 0.9167 - val_auc_3: 0.9695 - val_precision_3: 0.8722 - val_recall_3: 0.8290\n",
      "Epoch 279/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.3848 - accuracy: 0.8200 - auc_3: 0.9695 - precision_3: 0.8721 - recall_3: 0.8290 - val_loss: 0.2904 - val_accuracy: 0.9167 - val_auc_3: 0.9695 - val_precision_3: 0.8721 - val_recall_3: 0.8290\n",
      "Epoch 280/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2957 - accuracy: 0.8800 - auc_3: 0.9695 - precision_3: 0.8721 - recall_3: 0.8290 - val_loss: 0.3009 - val_accuracy: 0.9167 - val_auc_3: 0.9695 - val_precision_3: 0.8721 - val_recall_3: 0.8290\n",
      "Epoch 281/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2590 - accuracy: 0.9300 - auc_3: 0.9695 - precision_3: 0.8722 - recall_3: 0.8291 - val_loss: 0.3017 - val_accuracy: 0.9167 - val_auc_3: 0.9695 - val_precision_3: 0.8722 - val_recall_3: 0.8292\n",
      "Epoch 282/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2291 - accuracy: 0.9500 - auc_3: 0.9695 - precision_3: 0.8723 - recall_3: 0.8292 - val_loss: 0.2843 - val_accuracy: 0.9167 - val_auc_3: 0.9695 - val_precision_3: 0.8723 - val_recall_3: 0.8293\n",
      "Epoch 283/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.3259 - accuracy: 0.8900 - auc_3: 0.9695 - precision_3: 0.8723 - recall_3: 0.8293 - val_loss: 0.2800 - val_accuracy: 0.9167 - val_auc_3: 0.9696 - val_precision_3: 0.8724 - val_recall_3: 0.8294\n",
      "Epoch 284/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2093 - accuracy: 0.9200 - auc_3: 0.9696 - precision_3: 0.8724 - recall_3: 0.8294 - val_loss: 0.2676 - val_accuracy: 0.9167 - val_auc_3: 0.9696 - val_precision_3: 0.8724 - val_recall_3: 0.8295\n",
      "Epoch 285/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.4118 - accuracy: 0.8500 - auc_3: 0.9696 - precision_3: 0.8724 - recall_3: 0.8295 - val_loss: 0.2717 - val_accuracy: 0.9167 - val_auc_3: 0.9696 - val_precision_3: 0.8724 - val_recall_3: 0.8295\n",
      "Epoch 286/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2213 - accuracy: 0.9100 - auc_3: 0.9696 - precision_3: 0.8724 - recall_3: 0.8296 - val_loss: 0.2588 - val_accuracy: 0.9167 - val_auc_3: 0.9696 - val_precision_3: 0.8725 - val_recall_3: 0.8296\n",
      "Epoch 287/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.1899 - accuracy: 0.9500 - auc_3: 0.9696 - precision_3: 0.8725 - recall_3: 0.8297 - val_loss: 0.2429 - val_accuracy: 0.9167 - val_auc_3: 0.9696 - val_precision_3: 0.8725 - val_recall_3: 0.8297\n",
      "Epoch 288/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.4187 - accuracy: 0.7900 - auc_3: 0.9696 - precision_3: 0.8725 - recall_3: 0.8297 - val_loss: 0.2367 - val_accuracy: 0.9167 - val_auc_3: 0.9696 - val_precision_3: 0.8725 - val_recall_3: 0.8297\n",
      "Epoch 289/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2097 - accuracy: 0.9200 - auc_3: 0.9696 - precision_3: 0.8725 - recall_3: 0.8298 - val_loss: 0.2368 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8726 - val_recall_3: 0.8298\n",
      "Epoch 290/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.1559 - accuracy: 0.9700 - auc_3: 0.9697 - precision_3: 0.8726 - recall_3: 0.8299 - val_loss: 0.2382 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8727 - val_recall_3: 0.8300\n",
      "Epoch 291/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2431 - accuracy: 0.9400 - auc_3: 0.9697 - precision_3: 0.8727 - recall_3: 0.8300 - val_loss: 0.2529 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8728 - val_recall_3: 0.8301\n",
      "Epoch 292/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.3457 - accuracy: 0.8300 - auc_3: 0.9697 - precision_3: 0.8727 - recall_3: 0.8301 - val_loss: 0.2748 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8727 - val_recall_3: 0.8301\n",
      "Epoch 293/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2427 - accuracy: 0.9200 - auc_3: 0.9697 - precision_3: 0.8728 - recall_3: 0.8302 - val_loss: 0.3038 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8728 - val_recall_3: 0.8302\n",
      "Epoch 294/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.4672 - accuracy: 0.8400 - auc_3: 0.9697 - precision_3: 0.8728 - recall_3: 0.8302 - val_loss: 0.3068 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8728 - val_recall_3: 0.8303\n",
      "Epoch 295/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2400 - accuracy: 0.9000 - auc_3: 0.9697 - precision_3: 0.8728 - recall_3: 0.8303 - val_loss: 0.3318 - val_accuracy: 0.9167 - val_auc_3: 0.9697 - val_precision_3: 0.8728 - val_recall_3: 0.8303\n",
      "Epoch 296/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2379 - accuracy: 0.9200 - auc_3: 0.9698 - precision_3: 0.8729 - recall_3: 0.8304 - val_loss: 0.3314 - val_accuracy: 0.9167 - val_auc_3: 0.9698 - val_precision_3: 0.8729 - val_recall_3: 0.8304\n",
      "Epoch 297/500\n",
      "100/100 [==============================] - 0s 160us/step - loss: 0.2262 - accuracy: 0.9100 - auc_3: 0.9698 - precision_3: 0.8729 - recall_3: 0.8305 - val_loss: 0.3194 - val_accuracy: 0.9167 - val_auc_3: 0.9698 - val_precision_3: 0.8729 - val_recall_3: 0.8305\n",
      "Epoch 298/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2394 - accuracy: 0.9000 - auc_3: 0.9698 - precision_3: 0.8730 - recall_3: 0.8306 - val_loss: 0.3081 - val_accuracy: 0.9167 - val_auc_3: 0.9698 - val_precision_3: 0.8730 - val_recall_3: 0.8306\n",
      "Epoch 299/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2530 - accuracy: 0.8700 - auc_3: 0.9698 - precision_3: 0.8730 - recall_3: 0.8306 - val_loss: 0.2797 - val_accuracy: 0.9167 - val_auc_3: 0.9698 - val_precision_3: 0.8730 - val_recall_3: 0.8307\n",
      "Epoch 300/500\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.2355 - accuracy: 0.9000 - auc_3: 0.9699 - precision_3: 0.8730 - recall_3: 0.8307 - val_loss: 0.2541 - val_accuracy: 0.9167 - val_auc_3: 0.9699 - val_precision_3: 0.8730 - val_recall_3: 0.8307\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 219us/step - loss: 0.2544 - accuracy: 0.8600 - auc_3: 0.9699 - precision_3: 0.8730 - recall_3: 0.8308 - val_loss: 0.2033 - val_accuracy: 0.9167 - val_auc_3: 0.9699 - val_precision_3: 0.8730 - val_recall_3: 0.8308\n",
      "Epoch 302/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2807 - accuracy: 0.8600 - auc_3: 0.9699 - precision_3: 0.8730 - recall_3: 0.8308 - val_loss: 0.1750 - val_accuracy: 0.9167 - val_auc_3: 0.9699 - val_precision_3: 0.8730 - val_recall_3: 0.8308\n",
      "Epoch 303/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3010 - accuracy: 0.9000 - auc_3: 0.9699 - precision_3: 0.8731 - recall_3: 0.8309 - val_loss: 0.1654 - val_accuracy: 0.9167 - val_auc_3: 0.9699 - val_precision_3: 0.8731 - val_recall_3: 0.8309\n",
      "Epoch 304/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2346 - accuracy: 0.9100 - auc_3: 0.9699 - precision_3: 0.8731 - recall_3: 0.8310 - val_loss: 0.1756 - val_accuracy: 0.9167 - val_auc_3: 0.9699 - val_precision_3: 0.8732 - val_recall_3: 0.8310\n",
      "Epoch 305/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2739 - accuracy: 0.8800 - auc_3: 0.9700 - precision_3: 0.8732 - recall_3: 0.8310 - val_loss: 0.1757 - val_accuracy: 0.9167 - val_auc_3: 0.9700 - val_precision_3: 0.8732 - val_recall_3: 0.8311\n",
      "Epoch 306/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2761 - accuracy: 0.8800 - auc_3: 0.9700 - precision_3: 0.8732 - recall_3: 0.8311 - val_loss: 0.1728 - val_accuracy: 0.9167 - val_auc_3: 0.9700 - val_precision_3: 0.8732 - val_recall_3: 0.8311\n",
      "Epoch 307/500\n",
      "100/100 [==============================] - 0s 179us/step - loss: 0.3289 - accuracy: 0.8400 - auc_3: 0.9700 - precision_3: 0.8731 - recall_3: 0.8311 - val_loss: 0.1665 - val_accuracy: 0.9167 - val_auc_3: 0.9700 - val_precision_3: 0.8732 - val_recall_3: 0.8311\n",
      "Epoch 308/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2366 - accuracy: 0.9100 - auc_3: 0.9700 - precision_3: 0.8732 - recall_3: 0.8312 - val_loss: 0.1722 - val_accuracy: 0.9167 - val_auc_3: 0.9700 - val_precision_3: 0.8732 - val_recall_3: 0.8312\n",
      "Epoch 309/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2658 - accuracy: 0.8600 - auc_3: 0.9700 - precision_3: 0.8732 - recall_3: 0.8312 - val_loss: 0.1789 - val_accuracy: 0.9167 - val_auc_3: 0.9700 - val_precision_3: 0.8732 - val_recall_3: 0.8313\n",
      "Epoch 310/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2593 - accuracy: 0.9100 - auc_3: 0.9700 - precision_3: 0.8732 - recall_3: 0.8313 - val_loss: 0.1790 - val_accuracy: 0.9167 - val_auc_3: 0.9700 - val_precision_3: 0.8733 - val_recall_3: 0.8314\n",
      "Epoch 311/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2269 - accuracy: 0.9400 - auc_3: 0.9701 - precision_3: 0.8733 - recall_3: 0.8314 - val_loss: 0.1928 - val_accuracy: 0.9167 - val_auc_3: 0.9701 - val_precision_3: 0.8734 - val_recall_3: 0.8315\n",
      "Epoch 312/500\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.8800 - auc_3: 0.9701 - precision_3: 0.8734 - recall_3: 0.8315 - val_loss: 0.1959 - val_accuracy: 0.9167 - val_auc_3: 0.9701 - val_precision_3: 0.8734 - val_recall_3: 0.8315\n",
      "Epoch 313/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.1944 - accuracy: 0.9400 - auc_3: 0.9701 - precision_3: 0.8734 - recall_3: 0.8316 - val_loss: 0.1860 - val_accuracy: 0.9167 - val_auc_3: 0.9701 - val_precision_3: 0.8735 - val_recall_3: 0.8317\n",
      "Epoch 314/500\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.2773 - accuracy: 0.8700 - auc_3: 0.9701 - precision_3: 0.8734 - recall_3: 0.8317 - val_loss: 0.1758 - val_accuracy: 0.9167 - val_auc_3: 0.9701 - val_precision_3: 0.8735 - val_recall_3: 0.8317\n",
      "Epoch 315/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3428 - accuracy: 0.8700 - auc_3: 0.9702 - precision_3: 0.8735 - recall_3: 0.8318 - val_loss: 0.1713 - val_accuracy: 0.9167 - val_auc_3: 0.9701 - val_precision_3: 0.8735 - val_recall_3: 0.8318\n",
      "Epoch 316/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2985 - accuracy: 0.8700 - auc_3: 0.9701 - precision_3: 0.8734 - recall_3: 0.8318 - val_loss: 0.1832 - val_accuracy: 0.9167 - val_auc_3: 0.9702 - val_precision_3: 0.8735 - val_recall_3: 0.8318\n",
      "Epoch 317/500\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.3213 - accuracy: 0.9000 - auc_3: 0.9702 - precision_3: 0.8735 - recall_3: 0.8318 - val_loss: 0.1832 - val_accuracy: 0.9167 - val_auc_3: 0.9702 - val_precision_3: 0.8735 - val_recall_3: 0.8319\n",
      "Epoch 318/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3032 - accuracy: 0.8800 - auc_3: 0.9702 - precision_3: 0.8735 - recall_3: 0.8319 - val_loss: 0.1908 - val_accuracy: 0.9167 - val_auc_3: 0.9702 - val_precision_3: 0.8735 - val_recall_3: 0.8319\n",
      "Epoch 319/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2106 - accuracy: 0.9100 - auc_3: 0.9702 - precision_3: 0.8735 - recall_3: 0.8320 - val_loss: 0.2085 - val_accuracy: 0.9167 - val_auc_3: 0.9702 - val_precision_3: 0.8736 - val_recall_3: 0.8320\n",
      "Epoch 320/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2908 - accuracy: 0.8500 - auc_3: 0.9702 - precision_3: 0.8735 - recall_3: 0.8320 - val_loss: 0.2276 - val_accuracy: 0.9167 - val_auc_3: 0.9702 - val_precision_3: 0.8735 - val_recall_3: 0.8320\n",
      "Epoch 321/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.1862 - accuracy: 0.9200 - auc_3: 0.9702 - precision_3: 0.8736 - recall_3: 0.8321 - val_loss: 0.2405 - val_accuracy: 0.9167 - val_auc_3: 0.9702 - val_precision_3: 0.8736 - val_recall_3: 0.8322\n",
      "Epoch 322/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2596 - accuracy: 0.9000 - auc_3: 0.9703 - precision_3: 0.8736 - recall_3: 0.8322 - val_loss: 0.2297 - val_accuracy: 0.9167 - val_auc_3: 0.9703 - val_precision_3: 0.8736 - val_recall_3: 0.8322\n",
      "Epoch 323/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2494 - accuracy: 0.9100 - auc_3: 0.9703 - precision_3: 0.8737 - recall_3: 0.8323 - val_loss: 0.2081 - val_accuracy: 0.9167 - val_auc_3: 0.9703 - val_precision_3: 0.8737 - val_recall_3: 0.8323\n",
      "Epoch 324/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2415 - accuracy: 0.9000 - auc_3: 0.9703 - precision_3: 0.8737 - recall_3: 0.8323 - val_loss: 0.2169 - val_accuracy: 0.9167 - val_auc_3: 0.9703 - val_precision_3: 0.8737 - val_recall_3: 0.8324\n",
      "Epoch 325/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2632 - accuracy: 0.9000 - auc_3: 0.9703 - precision_3: 0.8738 - recall_3: 0.8324 - val_loss: 0.2290 - val_accuracy: 0.9167 - val_auc_3: 0.9703 - val_precision_3: 0.8738 - val_recall_3: 0.8325\n",
      "Epoch 326/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3820 - accuracy: 0.8200 - auc_3: 0.9703 - precision_3: 0.8737 - recall_3: 0.8324 - val_loss: 0.2605 - val_accuracy: 0.9167 - val_auc_3: 0.9703 - val_precision_3: 0.8737 - val_recall_3: 0.8324\n",
      "Epoch 327/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2199 - accuracy: 0.9000 - auc_3: 0.9703 - precision_3: 0.8737 - recall_3: 0.8325 - val_loss: 0.2868 - val_accuracy: 0.9167 - val_auc_3: 0.9703 - val_precision_3: 0.8738 - val_recall_3: 0.8325\n",
      "Epoch 328/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.1914 - accuracy: 0.9100 - auc_3: 0.9704 - precision_3: 0.8738 - recall_3: 0.8326 - val_loss: 0.2995 - val_accuracy: 0.9167 - val_auc_3: 0.9704 - val_precision_3: 0.8738 - val_recall_3: 0.8326\n",
      "Epoch 329/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2480 - accuracy: 0.9100 - auc_3: 0.9704 - precision_3: 0.8738 - recall_3: 0.8327 - val_loss: 0.3201 - val_accuracy: 0.9167 - val_auc_3: 0.9704 - val_precision_3: 0.8739 - val_recall_3: 0.8327\n",
      "Epoch 330/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.3898 - accuracy: 0.8200 - auc_3: 0.9704 - precision_3: 0.8738 - recall_3: 0.8327 - val_loss: 0.3877 - val_accuracy: 0.9167 - val_auc_3: 0.9704 - val_precision_3: 0.8738 - val_recall_3: 0.8327\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 249us/step - loss: 0.1825 - accuracy: 0.9400 - auc_3: 0.9704 - precision_3: 0.8739 - recall_3: 0.8328 - val_loss: 0.4401 - val_accuracy: 0.9167 - val_auc_3: 0.9704 - val_precision_3: 0.8739 - val_recall_3: 0.8328\n",
      "Epoch 332/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2183 - accuracy: 0.9100 - auc_3: 0.9704 - precision_3: 0.8740 - recall_3: 0.8329 - val_loss: 0.4534 - val_accuracy: 0.9167 - val_auc_3: 0.9704 - val_precision_3: 0.8740 - val_recall_3: 0.8329\n",
      "Epoch 333/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.1841 - accuracy: 0.9200 - auc_3: 0.9705 - precision_3: 0.8740 - recall_3: 0.8330 - val_loss: 0.4222 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8741 - val_recall_3: 0.8330\n",
      "Epoch 334/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2956 - accuracy: 0.9200 - auc_3: 0.9705 - precision_3: 0.8741 - recall_3: 0.8331 - val_loss: 0.3893 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8741 - val_recall_3: 0.8331\n",
      "Epoch 335/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2986 - accuracy: 0.8900 - auc_3: 0.9705 - precision_3: 0.8741 - recall_3: 0.8331 - val_loss: 0.3729 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8741 - val_recall_3: 0.8332\n",
      "Epoch 336/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2913 - accuracy: 0.8700 - auc_3: 0.9705 - precision_3: 0.8741 - recall_3: 0.8332 - val_loss: 0.3514 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8741 - val_recall_3: 0.8332\n",
      "Epoch 337/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2040 - accuracy: 0.9200 - auc_3: 0.9705 - precision_3: 0.8742 - recall_3: 0.8333 - val_loss: 0.3216 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8742 - val_recall_3: 0.8333\n",
      "Epoch 338/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2201 - accuracy: 0.9000 - auc_3: 0.9705 - precision_3: 0.8742 - recall_3: 0.8334 - val_loss: 0.2854 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8743 - val_recall_3: 0.8334\n",
      "Epoch 339/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.3789 - accuracy: 0.8400 - auc_3: 0.9705 - precision_3: 0.8742 - recall_3: 0.8334 - val_loss: 0.2589 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8742 - val_recall_3: 0.8334\n",
      "Epoch 340/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2743 - accuracy: 0.9000 - auc_3: 0.9705 - precision_3: 0.8743 - recall_3: 0.8335 - val_loss: 0.2517 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8743 - val_recall_3: 0.8335\n",
      "Epoch 341/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2403 - accuracy: 0.9100 - auc_3: 0.9706 - precision_3: 0.8743 - recall_3: 0.8335 - val_loss: 0.2381 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8743 - val_recall_3: 0.8336\n",
      "Epoch 342/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.5084 - accuracy: 0.8400 - auc_3: 0.9706 - precision_3: 0.8743 - recall_3: 0.8336 - val_loss: 0.2145 - val_accuracy: 0.9167 - val_auc_3: 0.9705 - val_precision_3: 0.8743 - val_recall_3: 0.8336\n",
      "Epoch 343/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2734 - accuracy: 0.8800 - auc_3: 0.9706 - precision_3: 0.8743 - recall_3: 0.8336 - val_loss: 0.2302 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8743 - val_recall_3: 0.8337\n",
      "Epoch 344/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.2908 - accuracy: 0.8700 - auc_3: 0.9706 - precision_3: 0.8743 - recall_3: 0.8337 - val_loss: 0.2265 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8743 - val_recall_3: 0.8337\n",
      "Epoch 345/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2503 - accuracy: 0.9300 - auc_3: 0.9706 - precision_3: 0.8744 - recall_3: 0.8338 - val_loss: 0.2308 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8744 - val_recall_3: 0.8338\n",
      "Epoch 346/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2877 - accuracy: 0.8800 - auc_3: 0.9706 - precision_3: 0.8744 - recall_3: 0.8338 - val_loss: 0.2264 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8744 - val_recall_3: 0.8339\n",
      "Epoch 347/500\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.3524 - accuracy: 0.8300 - auc_3: 0.9706 - precision_3: 0.8744 - recall_3: 0.8338 - val_loss: 0.2427 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8744 - val_recall_3: 0.8339\n",
      "Epoch 348/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2374 - accuracy: 0.9000 - auc_3: 0.9706 - precision_3: 0.8744 - recall_3: 0.8339 - val_loss: 0.2418 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8744 - val_recall_3: 0.8339\n",
      "Epoch 349/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3205 - accuracy: 0.8800 - auc_3: 0.9706 - precision_3: 0.8744 - recall_3: 0.8340 - val_loss: 0.2451 - val_accuracy: 0.9167 - val_auc_3: 0.9706 - val_precision_3: 0.8744 - val_recall_3: 0.8340\n",
      "Epoch 350/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2038 - accuracy: 0.9100 - auc_3: 0.9706 - precision_3: 0.8745 - recall_3: 0.8340 - val_loss: 0.2396 - val_accuracy: 0.9167 - val_auc_3: 0.9707 - val_precision_3: 0.8745 - val_recall_3: 0.8341\n",
      "Epoch 351/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.1915 - accuracy: 0.9200 - auc_3: 0.9707 - precision_3: 0.8746 - recall_3: 0.8342 - val_loss: 0.2354 - val_accuracy: 0.9167 - val_auc_3: 0.9707 - val_precision_3: 0.8746 - val_recall_3: 0.8342\n",
      "Epoch 352/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2808 - accuracy: 0.8600 - auc_3: 0.9707 - precision_3: 0.8746 - recall_3: 0.8342 - val_loss: 0.2235 - val_accuracy: 0.9167 - val_auc_3: 0.9707 - val_precision_3: 0.8746 - val_recall_3: 0.8342\n",
      "Epoch 353/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.1817 - accuracy: 0.9500 - auc_3: 0.9707 - precision_3: 0.8746 - recall_3: 0.8343 - val_loss: 0.2179 - val_accuracy: 0.9167 - val_auc_3: 0.9707 - val_precision_3: 0.8747 - val_recall_3: 0.8344\n",
      "Epoch 354/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.3089 - accuracy: 0.8500 - auc_3: 0.9707 - precision_3: 0.8747 - recall_3: 0.8343 - val_loss: 0.2469 - val_accuracy: 0.9167 - val_auc_3: 0.9707 - val_precision_3: 0.8747 - val_recall_3: 0.8344\n",
      "Epoch 355/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2866 - accuracy: 0.8400 - auc_3: 0.9708 - precision_3: 0.8747 - recall_3: 0.8344 - val_loss: 0.2606 - val_accuracy: 0.9167 - val_auc_3: 0.9708 - val_precision_3: 0.8747 - val_recall_3: 0.8344\n",
      "Epoch 356/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2224 - accuracy: 0.9000 - auc_3: 0.9708 - precision_3: 0.8747 - recall_3: 0.8344 - val_loss: 0.2837 - val_accuracy: 0.9167 - val_auc_3: 0.9708 - val_precision_3: 0.8747 - val_recall_3: 0.8345\n",
      "Epoch 357/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2496 - accuracy: 0.9100 - auc_3: 0.9708 - precision_3: 0.8747 - recall_3: 0.8345 - val_loss: 0.3124 - val_accuracy: 0.9167 - val_auc_3: 0.9708 - val_precision_3: 0.8748 - val_recall_3: 0.8345\n",
      "Epoch 358/500\n",
      "100/100 [==============================] - 0s 509us/step - loss: 0.2480 - accuracy: 0.8800 - auc_3: 0.9708 - precision_3: 0.8748 - recall_3: 0.8346 - val_loss: 0.3212 - val_accuracy: 0.9167 - val_auc_3: 0.9708 - val_precision_3: 0.8748 - val_recall_3: 0.8346\n",
      "Epoch 359/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2335 - accuracy: 0.9100 - auc_3: 0.9708 - precision_3: 0.8748 - recall_3: 0.8346 - val_loss: 0.3092 - val_accuracy: 0.9167 - val_auc_3: 0.9708 - val_precision_3: 0.8748 - val_recall_3: 0.8347\n",
      "Epoch 360/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2390 - accuracy: 0.9100 - auc_3: 0.9708 - precision_3: 0.8748 - recall_3: 0.8347 - val_loss: 0.2856 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8749 - val_recall_3: 0.8347\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 359us/step - loss: 0.2177 - accuracy: 0.9500 - auc_3: 0.9709 - precision_3: 0.8749 - recall_3: 0.8348 - val_loss: 0.2726 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8750 - val_recall_3: 0.8348\n",
      "Epoch 362/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.2380 - accuracy: 0.8800 - auc_3: 0.9709 - precision_3: 0.8749 - recall_3: 0.8349 - val_loss: 0.2573 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8750 - val_recall_3: 0.8349\n",
      "Epoch 363/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.3834 - accuracy: 0.8600 - auc_3: 0.9709 - precision_3: 0.8749 - recall_3: 0.8349 - val_loss: 0.2584 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8750 - val_recall_3: 0.8349\n",
      "Epoch 364/500\n",
      "100/100 [==============================] - 0s 549us/step - loss: 0.3245 - accuracy: 0.8900 - auc_3: 0.9709 - precision_3: 0.8750 - recall_3: 0.8350 - val_loss: 0.2221 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8750 - val_recall_3: 0.8350\n",
      "Epoch 365/500\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.2160 - accuracy: 0.8900 - auc_3: 0.9709 - precision_3: 0.8750 - recall_3: 0.8350 - val_loss: 0.2084 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8750 - val_recall_3: 0.8351\n",
      "Epoch 366/500\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.3162 - accuracy: 0.9100 - auc_3: 0.9709 - precision_3: 0.8750 - recall_3: 0.8351 - val_loss: 0.2133 - val_accuracy: 0.9167 - val_auc_3: 0.9709 - val_precision_3: 0.8751 - val_recall_3: 0.8351\n",
      "Epoch 367/500\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.2159 - accuracy: 0.8800 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8352 - val_loss: 0.2307 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8751 - val_recall_3: 0.8352\n",
      "Epoch 368/500\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.2807 - accuracy: 0.8700 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8352 - val_loss: 0.2561 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8751 - val_recall_3: 0.8352\n",
      "Epoch 369/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.4442 - accuracy: 0.8200 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8352 - val_loss: 0.2692 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8750 - val_recall_3: 0.8352\n",
      "Epoch 370/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2154 - accuracy: 0.9100 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8353 - val_loss: 0.2802 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8751 - val_recall_3: 0.8353\n",
      "Epoch 371/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2216 - accuracy: 0.9100 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8354 - val_loss: 0.2787 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8751 - val_recall_3: 0.8354\n",
      "Epoch 372/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.2935 - accuracy: 0.8900 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8354 - val_loss: 0.2946 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8751 - val_recall_3: 0.8355\n",
      "Epoch 373/500\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.4066 - accuracy: 0.8300 - auc_3: 0.9710 - precision_3: 0.8751 - recall_3: 0.8354 - val_loss: 0.2839 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8751 - val_recall_3: 0.8355\n",
      "Epoch 374/500\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.2268 - accuracy: 0.9300 - auc_3: 0.9710 - precision_3: 0.8752 - recall_3: 0.8355 - val_loss: 0.2745 - val_accuracy: 0.9167 - val_auc_3: 0.9710 - val_precision_3: 0.8752 - val_recall_3: 0.8355\n",
      "Epoch 375/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.1842 - accuracy: 0.9500 - auc_3: 0.9710 - precision_3: 0.8752 - recall_3: 0.8356 - val_loss: 0.2606 - val_accuracy: 0.9167 - val_auc_3: 0.9711 - val_precision_3: 0.8753 - val_recall_3: 0.8357\n",
      "Epoch 376/500\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.1865 - accuracy: 0.9300 - auc_3: 0.9711 - precision_3: 0.8753 - recall_3: 0.8357 - val_loss: 0.2363 - val_accuracy: 0.9167 - val_auc_3: 0.9711 - val_precision_3: 0.8753 - val_recall_3: 0.8358\n",
      "Epoch 377/500\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.2288 - accuracy: 0.9000 - auc_3: 0.9711 - precision_3: 0.8754 - recall_3: 0.8358 - val_loss: 0.2329 - val_accuracy: 0.9167 - val_auc_3: 0.9711 - val_precision_3: 0.8754 - val_recall_3: 0.8359\n",
      "Epoch 378/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.2222 - accuracy: 0.9200 - auc_3: 0.9711 - precision_3: 0.8754 - recall_3: 0.8359 - val_loss: 0.2352 - val_accuracy: 0.9167 - val_auc_3: 0.9711 - val_precision_3: 0.8754 - val_recall_3: 0.8359\n",
      "Epoch 379/500\n",
      "100/100 [==============================] - 0s 509us/step - loss: 0.2371 - accuracy: 0.9200 - auc_3: 0.9712 - precision_3: 0.8755 - recall_3: 0.8360 - val_loss: 0.2336 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8755 - val_recall_3: 0.8360\n",
      "Epoch 380/500\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.2791 - accuracy: 0.8700 - auc_3: 0.9712 - precision_3: 0.8755 - recall_3: 0.8360 - val_loss: 0.2465 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8755 - val_recall_3: 0.8361\n",
      "Epoch 381/500\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.3558 - accuracy: 0.8400 - auc_3: 0.9712 - precision_3: 0.8755 - recall_3: 0.8361 - val_loss: 0.2397 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8755 - val_recall_3: 0.8361\n",
      "Epoch 382/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.3065 - accuracy: 0.8900 - auc_3: 0.9712 - precision_3: 0.8755 - recall_3: 0.8361 - val_loss: 0.2619 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8755 - val_recall_3: 0.8361\n",
      "Epoch 383/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.3817 - accuracy: 0.8500 - auc_3: 0.9712 - precision_3: 0.8755 - recall_3: 0.8361 - val_loss: 0.2950 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8755 - val_recall_3: 0.8361\n",
      "Epoch 384/500\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.2392 - accuracy: 0.9200 - auc_3: 0.9712 - precision_3: 0.8755 - recall_3: 0.8361 - val_loss: 0.3131 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8756 - val_recall_3: 0.8362\n",
      "Epoch 385/500\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.2012 - accuracy: 0.9000 - auc_3: 0.9712 - precision_3: 0.8756 - recall_3: 0.8362 - val_loss: 0.3206 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8756 - val_recall_3: 0.8363\n",
      "Epoch 386/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2869 - accuracy: 0.8600 - auc_3: 0.9712 - precision_3: 0.8756 - recall_3: 0.8363 - val_loss: 0.3492 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8756 - val_recall_3: 0.8363\n",
      "Epoch 387/500\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.2765 - accuracy: 0.8900 - auc_3: 0.9712 - precision_3: 0.8756 - recall_3: 0.8363 - val_loss: 0.3703 - val_accuracy: 0.9167 - val_auc_3: 0.9712 - val_precision_3: 0.8757 - val_recall_3: 0.8364\n",
      "Epoch 388/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.1861 - accuracy: 0.9400 - auc_3: 0.9712 - precision_3: 0.8757 - recall_3: 0.8364 - val_loss: 0.3578 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8365\n",
      "Epoch 389/500\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.2453 - accuracy: 0.8800 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8365 - val_loss: 0.3453 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8365\n",
      "Epoch 390/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2392 - accuracy: 0.9000 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8366 - val_loss: 0.3035 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8366\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 249us/step - loss: 0.3145 - accuracy: 0.8700 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8366 - val_loss: 0.2650 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8366\n",
      "Epoch 392/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.3125 - accuracy: 0.8700 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8367 - val_loss: 0.2057 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8367\n",
      "Epoch 393/500\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.3509 - accuracy: 0.8300 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8366 - val_loss: 0.1692 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8367\n",
      "Epoch 394/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.3999 - accuracy: 0.8200 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8366 - val_loss: 0.1546 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8366\n",
      "Epoch 395/500\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.3763 - accuracy: 0.8600 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8367 - val_loss: 0.1481 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8367\n",
      "Epoch 396/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3411 - accuracy: 0.9100 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8367 - val_loss: 0.1705 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8367\n",
      "Epoch 397/500\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.3008 - accuracy: 0.8700 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8368 - val_loss: 0.1927 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8368\n",
      "Epoch 398/500\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.3350 - accuracy: 0.8400 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8368 - val_loss: 0.1952 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8368\n",
      "Epoch 399/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.3004 - accuracy: 0.8900 - auc_3: 0.9713 - precision_3: 0.8757 - recall_3: 0.8368 - val_loss: 0.2051 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8757 - val_recall_3: 0.8368\n",
      "Epoch 400/500\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.1783 - accuracy: 0.9300 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8369 - val_loss: 0.2148 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8369\n",
      "Epoch 401/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3276 - accuracy: 0.8600 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8370 - val_loss: 0.2110 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8370\n",
      "Epoch 402/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2264 - accuracy: 0.8900 - auc_3: 0.9713 - precision_3: 0.8758 - recall_3: 0.8370 - val_loss: 0.2039 - val_accuracy: 0.9167 - val_auc_3: 0.9713 - val_precision_3: 0.8758 - val_recall_3: 0.8370\n",
      "Epoch 403/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2096 - accuracy: 0.9300 - auc_3: 0.9714 - precision_3: 0.8759 - recall_3: 0.8371 - val_loss: 0.2032 - val_accuracy: 0.9167 - val_auc_3: 0.9714 - val_precision_3: 0.8759 - val_recall_3: 0.8371\n",
      "Epoch 404/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2412 - accuracy: 0.9000 - auc_3: 0.9714 - precision_3: 0.8759 - recall_3: 0.8372 - val_loss: 0.2257 - val_accuracy: 0.9167 - val_auc_3: 0.9714 - val_precision_3: 0.8759 - val_recall_3: 0.8372\n",
      "Epoch 405/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.1805 - accuracy: 0.9300 - auc_3: 0.9714 - precision_3: 0.8760 - recall_3: 0.8372 - val_loss: 0.2475 - val_accuracy: 0.9167 - val_auc_3: 0.9714 - val_precision_3: 0.8760 - val_recall_3: 0.8373\n",
      "Epoch 406/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2169 - accuracy: 0.9000 - auc_3: 0.9714 - precision_3: 0.8760 - recall_3: 0.8373 - val_loss: 0.2668 - val_accuracy: 0.9167 - val_auc_3: 0.9714 - val_precision_3: 0.8760 - val_recall_3: 0.8373\n",
      "Epoch 407/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.1734 - accuracy: 0.9400 - auc_3: 0.9715 - precision_3: 0.8761 - recall_3: 0.8374 - val_loss: 0.2721 - val_accuracy: 0.9167 - val_auc_3: 0.9715 - val_precision_3: 0.8761 - val_recall_3: 0.8374\n",
      "Epoch 408/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2234 - accuracy: 0.8800 - auc_3: 0.9715 - precision_3: 0.8761 - recall_3: 0.8375 - val_loss: 0.2839 - val_accuracy: 0.9167 - val_auc_3: 0.9715 - val_precision_3: 0.8761 - val_recall_3: 0.8375\n",
      "Epoch 409/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2289 - accuracy: 0.9200 - auc_3: 0.9715 - precision_3: 0.8762 - recall_3: 0.8375 - val_loss: 0.3061 - val_accuracy: 0.9167 - val_auc_3: 0.9715 - val_precision_3: 0.8762 - val_recall_3: 0.8376\n",
      "Epoch 410/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2256 - accuracy: 0.9400 - auc_3: 0.9715 - precision_3: 0.8762 - recall_3: 0.8376 - val_loss: 0.3077 - val_accuracy: 0.9167 - val_auc_3: 0.9715 - val_precision_3: 0.8762 - val_recall_3: 0.8376\n",
      "Epoch 411/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.3321 - accuracy: 0.8600 - auc_3: 0.9715 - precision_3: 0.8762 - recall_3: 0.8377 - val_loss: 0.3299 - val_accuracy: 0.9167 - val_auc_3: 0.9715 - val_precision_3: 0.8762 - val_recall_3: 0.8377\n",
      "Epoch 412/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2616 - accuracy: 0.8900 - auc_3: 0.9715 - precision_3: 0.8763 - recall_3: 0.8377 - val_loss: 0.3504 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8763 - val_recall_3: 0.8377\n",
      "Epoch 413/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2414 - accuracy: 0.9300 - auc_3: 0.9716 - precision_3: 0.8763 - recall_3: 0.8378 - val_loss: 0.3576 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8763 - val_recall_3: 0.8378\n",
      "Epoch 414/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2446 - accuracy: 0.9000 - auc_3: 0.9716 - precision_3: 0.8763 - recall_3: 0.8378 - val_loss: 0.3278 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8764 - val_recall_3: 0.8379\n",
      "Epoch 415/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.3268 - accuracy: 0.8600 - auc_3: 0.9716 - precision_3: 0.8764 - recall_3: 0.8379 - val_loss: 0.2974 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8764 - val_recall_3: 0.8379\n",
      "Epoch 416/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.2704 - accuracy: 0.8900 - auc_3: 0.9716 - precision_3: 0.8764 - recall_3: 0.8379 - val_loss: 0.2689 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8764 - val_recall_3: 0.8380\n",
      "Epoch 417/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2585 - accuracy: 0.9000 - auc_3: 0.9716 - precision_3: 0.8764 - recall_3: 0.8380 - val_loss: 0.2558 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8764 - val_recall_3: 0.8380\n",
      "Epoch 418/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2965 - accuracy: 0.8800 - auc_3: 0.9716 - precision_3: 0.8764 - recall_3: 0.8381 - val_loss: 0.2479 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8764 - val_recall_3: 0.8381\n",
      "Epoch 419/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2213 - accuracy: 0.9300 - auc_3: 0.9716 - precision_3: 0.8765 - recall_3: 0.8381 - val_loss: 0.2515 - val_accuracy: 0.9167 - val_auc_3: 0.9716 - val_precision_3: 0.8765 - val_recall_3: 0.8382\n",
      "Epoch 420/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.2533 - accuracy: 0.9200 - auc_3: 0.9716 - precision_3: 0.8765 - recall_3: 0.8382 - val_loss: 0.2558 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8765 - val_recall_3: 0.8383\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 190us/step - loss: 0.1668 - accuracy: 0.9400 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8383 - val_loss: 0.2498 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8766 - val_recall_3: 0.8384\n",
      "Epoch 422/500\n",
      "100/100 [==============================] - 0s 150us/step - loss: 0.1650 - accuracy: 0.9300 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8384 - val_loss: 0.2466 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8766 - val_recall_3: 0.8385\n",
      "Epoch 423/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2969 - accuracy: 0.8500 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8385 - val_loss: 0.2405 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8766 - val_recall_3: 0.8385\n",
      "Epoch 424/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2077 - accuracy: 0.9000 - auc_3: 0.9717 - precision_3: 0.8767 - recall_3: 0.8385 - val_loss: 0.2258 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8767 - val_recall_3: 0.8385\n",
      "Epoch 425/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.4395 - accuracy: 0.8000 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8385 - val_loss: 0.2092 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8766 - val_recall_3: 0.8385\n",
      "Epoch 426/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2508 - accuracy: 0.8900 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8385 - val_loss: 0.2343 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8766 - val_recall_3: 0.8386\n",
      "Epoch 427/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.4002 - accuracy: 0.8300 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8385 - val_loss: 0.2716 - val_accuracy: 0.9167 - val_auc_3: 0.9717 - val_precision_3: 0.8766 - val_recall_3: 0.8385\n",
      "Epoch 428/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.1457 - accuracy: 0.9400 - auc_3: 0.9717 - precision_3: 0.8766 - recall_3: 0.8386 - val_loss: 0.3191 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8767 - val_recall_3: 0.8387\n",
      "Epoch 429/500\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.2319 - accuracy: 0.9200 - auc_3: 0.9718 - precision_3: 0.8767 - recall_3: 0.8387 - val_loss: 0.3414 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8767 - val_recall_3: 0.8387\n",
      "Epoch 430/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2951 - accuracy: 0.8500 - auc_3: 0.9718 - precision_3: 0.8767 - recall_3: 0.8387 - val_loss: 0.3592 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8767 - val_recall_3: 0.8388\n",
      "Epoch 431/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.3367 - accuracy: 0.8400 - auc_3: 0.9718 - precision_3: 0.8767 - recall_3: 0.8388 - val_loss: 0.3663 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8767 - val_recall_3: 0.8388\n",
      "Epoch 432/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2094 - accuracy: 0.9100 - auc_3: 0.9718 - precision_3: 0.8767 - recall_3: 0.8388 - val_loss: 0.3499 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8767 - val_recall_3: 0.8388\n",
      "Epoch 433/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.1619 - accuracy: 0.9400 - auc_3: 0.9718 - precision_3: 0.8768 - recall_3: 0.8389 - val_loss: 0.3261 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8768 - val_recall_3: 0.8389\n",
      "Epoch 434/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3257 - accuracy: 0.8800 - auc_3: 0.9718 - precision_3: 0.8768 - recall_3: 0.8390 - val_loss: 0.3233 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8768 - val_recall_3: 0.8390\n",
      "Epoch 435/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2994 - accuracy: 0.8700 - auc_3: 0.9718 - precision_3: 0.8768 - recall_3: 0.8390 - val_loss: 0.3112 - val_accuracy: 0.9167 - val_auc_3: 0.9718 - val_precision_3: 0.8768 - val_recall_3: 0.8390\n",
      "Epoch 436/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2421 - accuracy: 0.8900 - auc_3: 0.9719 - precision_3: 0.8768 - recall_3: 0.8390 - val_loss: 0.3182 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8768 - val_recall_3: 0.8391\n",
      "Epoch 437/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2800 - accuracy: 0.8700 - auc_3: 0.9719 - precision_3: 0.8768 - recall_3: 0.8391 - val_loss: 0.3148 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8768 - val_recall_3: 0.8391\n",
      "Epoch 438/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.3333 - accuracy: 0.8600 - auc_3: 0.9719 - precision_3: 0.8768 - recall_3: 0.8391 - val_loss: 0.2941 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8768 - val_recall_3: 0.8391\n",
      "Epoch 439/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2790 - accuracy: 0.8800 - auc_3: 0.9719 - precision_3: 0.8768 - recall_3: 0.8392 - val_loss: 0.2931 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8769 - val_recall_3: 0.8392\n",
      "Epoch 440/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2420 - accuracy: 0.9000 - auc_3: 0.9719 - precision_3: 0.8769 - recall_3: 0.8392 - val_loss: 0.2946 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8769 - val_recall_3: 0.8392\n",
      "Epoch 441/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3177 - accuracy: 0.9000 - auc_3: 0.9719 - precision_3: 0.8769 - recall_3: 0.8393 - val_loss: 0.2858 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8769 - val_recall_3: 0.8393\n",
      "Epoch 442/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.3067 - accuracy: 0.8800 - auc_3: 0.9719 - precision_3: 0.8769 - recall_3: 0.8393 - val_loss: 0.2668 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8769 - val_recall_3: 0.8393\n",
      "Epoch 443/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.1889 - accuracy: 0.9200 - auc_3: 0.9719 - precision_3: 0.8769 - recall_3: 0.8394 - val_loss: 0.2611 - val_accuracy: 0.9167 - val_auc_3: 0.9719 - val_precision_3: 0.8770 - val_recall_3: 0.8394\n",
      "Epoch 444/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.1995 - accuracy: 0.9200 - auc_3: 0.9719 - precision_3: 0.8770 - recall_3: 0.8394 - val_loss: 0.2552 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8770 - val_recall_3: 0.8395\n",
      "Epoch 445/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2544 - accuracy: 0.9000 - auc_3: 0.9720 - precision_3: 0.8771 - recall_3: 0.8395 - val_loss: 0.2484 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8770 - val_recall_3: 0.8396\n",
      "Epoch 446/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.3569 - accuracy: 0.8300 - auc_3: 0.9720 - precision_3: 0.8770 - recall_3: 0.8395 - val_loss: 0.2409 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8770 - val_recall_3: 0.8395\n",
      "Epoch 447/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2744 - accuracy: 0.9200 - auc_3: 0.9720 - precision_3: 0.8771 - recall_3: 0.8396 - val_loss: 0.2366 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8771 - val_recall_3: 0.8396\n",
      "Epoch 448/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2004 - accuracy: 0.9200 - auc_3: 0.9720 - precision_3: 0.8771 - recall_3: 0.8397 - val_loss: 0.2251 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8771 - val_recall_3: 0.8397\n",
      "Epoch 449/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.1744 - accuracy: 0.9300 - auc_3: 0.9720 - precision_3: 0.8771 - recall_3: 0.8397 - val_loss: 0.2208 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8772 - val_recall_3: 0.8398\n",
      "Epoch 450/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2369 - accuracy: 0.8900 - auc_3: 0.9720 - precision_3: 0.8772 - recall_3: 0.8398 - val_loss: 0.2207 - val_accuracy: 0.9167 - val_auc_3: 0.9720 - val_precision_3: 0.8772 - val_recall_3: 0.8398\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 229us/step - loss: 0.2121 - accuracy: 0.9200 - auc_3: 0.9721 - precision_3: 0.8772 - recall_3: 0.8399 - val_loss: 0.2299 - val_accuracy: 0.9167 - val_auc_3: 0.9721 - val_precision_3: 0.8772 - val_recall_3: 0.8399\n",
      "Epoch 452/500\n",
      "100/100 [==============================] - 0s 232us/step - loss: 0.2325 - accuracy: 0.9200 - auc_3: 0.9721 - precision_3: 0.8773 - recall_3: 0.8400 - val_loss: 0.2419 - val_accuracy: 0.9167 - val_auc_3: 0.9721 - val_precision_3: 0.8773 - val_recall_3: 0.8400\n",
      "Epoch 453/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.2143 - accuracy: 0.9100 - auc_3: 0.9721 - precision_3: 0.8773 - recall_3: 0.8400 - val_loss: 0.2497 - val_accuracy: 0.9167 - val_auc_3: 0.9721 - val_precision_3: 0.8773 - val_recall_3: 0.8401\n",
      "Epoch 454/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.2710 - accuracy: 0.8400 - auc_3: 0.9721 - precision_3: 0.8773 - recall_3: 0.8401 - val_loss: 0.2681 - val_accuracy: 0.9167 - val_auc_3: 0.9721 - val_precision_3: 0.8773 - val_recall_3: 0.8401\n",
      "Epoch 455/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.1993 - accuracy: 0.9200 - auc_3: 0.9721 - precision_3: 0.8773 - recall_3: 0.8401 - val_loss: 0.2936 - val_accuracy: 0.9167 - val_auc_3: 0.9721 - val_precision_3: 0.8774 - val_recall_3: 0.8402\n",
      "Epoch 456/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2282 - accuracy: 0.8900 - auc_3: 0.9722 - precision_3: 0.8774 - recall_3: 0.8402 - val_loss: 0.3247 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8774 - val_recall_3: 0.8402\n",
      "Epoch 457/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.2604 - accuracy: 0.9200 - auc_3: 0.9722 - precision_3: 0.8774 - recall_3: 0.8402 - val_loss: 0.3479 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8774 - val_recall_3: 0.8403\n",
      "Epoch 458/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.1764 - accuracy: 0.9500 - auc_3: 0.9722 - precision_3: 0.8775 - recall_3: 0.8403 - val_loss: 0.3644 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8775 - val_recall_3: 0.8404\n",
      "Epoch 459/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.2057 - accuracy: 0.9300 - auc_3: 0.9722 - precision_3: 0.8775 - recall_3: 0.8404 - val_loss: 0.3671 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8776 - val_recall_3: 0.8404\n",
      "Epoch 460/500\n",
      "100/100 [==============================] - 0s 160us/step - loss: 0.2605 - accuracy: 0.8900 - auc_3: 0.9722 - precision_3: 0.8776 - recall_3: 0.8405 - val_loss: 0.3831 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8776 - val_recall_3: 0.8405\n",
      "Epoch 461/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.3182 - accuracy: 0.8700 - auc_3: 0.9722 - precision_3: 0.8776 - recall_3: 0.8405 - val_loss: 0.4083 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8776 - val_recall_3: 0.8405\n",
      "Epoch 462/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2650 - accuracy: 0.8500 - auc_3: 0.9722 - precision_3: 0.8775 - recall_3: 0.8405 - val_loss: 0.4284 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8775 - val_recall_3: 0.8405\n",
      "Epoch 463/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2576 - accuracy: 0.9000 - auc_3: 0.9722 - precision_3: 0.8776 - recall_3: 0.8405 - val_loss: 0.4134 - val_accuracy: 0.9167 - val_auc_3: 0.9722 - val_precision_3: 0.8776 - val_recall_3: 0.8406\n",
      "Epoch 464/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.1828 - accuracy: 0.9100 - auc_3: 0.9723 - precision_3: 0.8776 - recall_3: 0.8406 - val_loss: 0.3999 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8776 - val_recall_3: 0.8407\n",
      "Epoch 465/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2685 - accuracy: 0.9000 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8407 - val_loss: 0.3828 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8777 - val_recall_3: 0.8407\n",
      "Epoch 466/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2617 - accuracy: 0.8700 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8407 - val_loss: 0.2958 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8777 - val_recall_3: 0.8407\n",
      "Epoch 467/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2622 - accuracy: 0.9000 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8408 - val_loss: 0.2721 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8777 - val_recall_3: 0.8408\n",
      "Epoch 468/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2455 - accuracy: 0.9000 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8408 - val_loss: 0.2694 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8777 - val_recall_3: 0.8409\n",
      "Epoch 469/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2450 - accuracy: 0.8900 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8409 - val_loss: 0.2961 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8777 - val_recall_3: 0.8409\n",
      "Epoch 470/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.2356 - accuracy: 0.8800 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8409 - val_loss: 0.2903 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8778 - val_recall_3: 0.8410\n",
      "Epoch 471/500\n",
      "100/100 [==============================] - 0s 160us/step - loss: 0.2848 - accuracy: 0.8700 - auc_3: 0.9723 - precision_3: 0.8777 - recall_3: 0.8410 - val_loss: 0.2872 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8778 - val_recall_3: 0.8410\n",
      "Epoch 472/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3559 - accuracy: 0.8600 - auc_3: 0.9724 - precision_3: 0.8778 - recall_3: 0.8410 - val_loss: 0.2803 - val_accuracy: 0.9167 - val_auc_3: 0.9723 - val_precision_3: 0.8777 - val_recall_3: 0.8410\n",
      "Epoch 473/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.2745 - accuracy: 0.8700 - auc_3: 0.9724 - precision_3: 0.8778 - recall_3: 0.8410 - val_loss: 0.2772 - val_accuracy: 0.9167 - val_auc_3: 0.9724 - val_precision_3: 0.8778 - val_recall_3: 0.8410\n",
      "Epoch 474/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2806 - accuracy: 0.9000 - auc_3: 0.9724 - precision_3: 0.8778 - recall_3: 0.8411 - val_loss: 0.2912 - val_accuracy: 0.9167 - val_auc_3: 0.9724 - val_precision_3: 0.8778 - val_recall_3: 0.8411\n",
      "Epoch 475/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.3276 - accuracy: 0.8800 - auc_3: 0.9724 - precision_3: 0.8778 - recall_3: 0.8411 - val_loss: 0.2933 - val_accuracy: 0.9167 - val_auc_3: 0.9724 - val_precision_3: 0.8778 - val_recall_3: 0.8411\n",
      "Epoch 476/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.1817 - accuracy: 0.9300 - auc_3: 0.9724 - precision_3: 0.8778 - recall_3: 0.8412 - val_loss: 0.3009 - val_accuracy: 0.9167 - val_auc_3: 0.9724 - val_precision_3: 0.8778 - val_recall_3: 0.8412\n",
      "Epoch 477/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2006 - accuracy: 0.9000 - auc_3: 0.9724 - precision_3: 0.8778 - recall_3: 0.8412 - val_loss: 0.2887 - val_accuracy: 0.9167 - val_auc_3: 0.9724 - val_precision_3: 0.8779 - val_recall_3: 0.8413\n",
      "Epoch 478/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.1928 - accuracy: 0.9100 - auc_3: 0.9724 - precision_3: 0.8779 - recall_3: 0.8413 - val_loss: 0.2835 - val_accuracy: 0.9167 - val_auc_3: 0.9724 - val_precision_3: 0.8779 - val_recall_3: 0.8413\n",
      "Epoch 479/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.1722 - accuracy: 0.9600 - auc_3: 0.9724 - precision_3: 0.8780 - recall_3: 0.8414 - val_loss: 0.2746 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8780 - val_recall_3: 0.8415\n",
      "Epoch 480/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2650 - accuracy: 0.8800 - auc_3: 0.9725 - precision_3: 0.8780 - recall_3: 0.8415 - val_loss: 0.2489 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8780 - val_recall_3: 0.8415\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 170us/step - loss: 0.2884 - accuracy: 0.9000 - auc_3: 0.9725 - precision_3: 0.8780 - recall_3: 0.8415 - val_loss: 0.2464 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8780 - val_recall_3: 0.8415\n",
      "Epoch 482/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2417 - accuracy: 0.9000 - auc_3: 0.9725 - precision_3: 0.8780 - recall_3: 0.8416 - val_loss: 0.2614 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8780 - val_recall_3: 0.8416\n",
      "Epoch 483/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.2338 - accuracy: 0.8900 - auc_3: 0.9725 - precision_3: 0.8780 - recall_3: 0.8416 - val_loss: 0.2607 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8781 - val_recall_3: 0.8417\n",
      "Epoch 484/500\n",
      "100/100 [==============================] - 0s 190us/step - loss: 0.3041 - accuracy: 0.8800 - auc_3: 0.9725 - precision_3: 0.8781 - recall_3: 0.8417 - val_loss: 0.2456 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8781 - val_recall_3: 0.8417\n",
      "Epoch 485/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2371 - accuracy: 0.8900 - auc_3: 0.9725 - precision_3: 0.8781 - recall_3: 0.8417 - val_loss: 0.2436 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8781 - val_recall_3: 0.8417\n",
      "Epoch 486/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.2732 - accuracy: 0.9000 - auc_3: 0.9725 - precision_3: 0.8781 - recall_3: 0.8418 - val_loss: 0.2442 - val_accuracy: 0.9167 - val_auc_3: 0.9725 - val_precision_3: 0.8781 - val_recall_3: 0.8418\n",
      "Epoch 487/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.2393 - accuracy: 0.9100 - auc_3: 0.9725 - precision_3: 0.8781 - recall_3: 0.8418 - val_loss: 0.2448 - val_accuracy: 0.9167 - val_auc_3: 0.9726 - val_precision_3: 0.8781 - val_recall_3: 0.8419\n",
      "Epoch 488/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.2863 - accuracy: 0.8500 - auc_3: 0.9726 - precision_3: 0.8781 - recall_3: 0.8419 - val_loss: 0.2297 - val_accuracy: 0.9167 - val_auc_3: 0.9726 - val_precision_3: 0.8781 - val_recall_3: 0.8419\n",
      "Epoch 489/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.1936 - accuracy: 0.9300 - auc_3: 0.9726 - precision_3: 0.8782 - recall_3: 0.8419 - val_loss: 0.2286 - val_accuracy: 0.9167 - val_auc_3: 0.9726 - val_precision_3: 0.8782 - val_recall_3: 0.8420\n",
      "Epoch 490/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 0.1929 - accuracy: 0.9100 - auc_3: 0.9726 - precision_3: 0.8782 - recall_3: 0.8420 - val_loss: 0.2155 - val_accuracy: 0.9167 - val_auc_3: 0.9726 - val_precision_3: 0.8782 - val_recall_3: 0.8420\n",
      "Epoch 491/500\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.1611 - accuracy: 0.9300 - auc_3: 0.9726 - precision_3: 0.8782 - recall_3: 0.8421 - val_loss: 0.2065 - val_accuracy: 0.9167 - val_auc_3: 0.9726 - val_precision_3: 0.8783 - val_recall_3: 0.8421\n",
      "Epoch 492/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2772 - accuracy: 0.8500 - auc_3: 0.9726 - precision_3: 0.8782 - recall_3: 0.8421 - val_loss: 0.1957 - val_accuracy: 0.9167 - val_auc_3: 0.9726 - val_precision_3: 0.8782 - val_recall_3: 0.8421\n",
      "Epoch 493/500\n",
      "100/100 [==============================] - 0s 189us/step - loss: 0.2171 - accuracy: 0.8800 - auc_3: 0.9727 - precision_3: 0.8782 - recall_3: 0.8422 - val_loss: 0.2008 - val_accuracy: 0.9167 - val_auc_3: 0.9727 - val_precision_3: 0.8783 - val_recall_3: 0.8422\n",
      "Epoch 494/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.3192 - accuracy: 0.8800 - auc_3: 0.9727 - precision_3: 0.8783 - recall_3: 0.8422 - val_loss: 0.1922 - val_accuracy: 0.9167 - val_auc_3: 0.9727 - val_precision_3: 0.8783 - val_recall_3: 0.8422\n",
      "Epoch 495/500\n",
      "100/100 [==============================] - 0s 180us/step - loss: 0.1798 - accuracy: 0.9300 - auc_3: 0.9727 - precision_3: 0.8783 - recall_3: 0.8422 - val_loss: 0.1879 - val_accuracy: 0.9167 - val_auc_3: 0.9727 - val_precision_3: 0.8783 - val_recall_3: 0.8423\n",
      "Epoch 496/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 0.1902 - accuracy: 0.9500 - auc_3: 0.9727 - precision_3: 0.8784 - recall_3: 0.8423 - val_loss: 0.1830 - val_accuracy: 0.9167 - val_auc_3: 0.9727 - val_precision_3: 0.8784 - val_recall_3: 0.8424\n",
      "Epoch 497/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.3305 - accuracy: 0.8400 - auc_3: 0.9727 - precision_3: 0.8784 - recall_3: 0.8424 - val_loss: 0.1776 - val_accuracy: 0.9167 - val_auc_3: 0.9727 - val_precision_3: 0.8784 - val_recall_3: 0.8424\n",
      "Epoch 498/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 0.1827 - accuracy: 0.8900 - auc_3: 0.9727 - precision_3: 0.8784 - recall_3: 0.8424 - val_loss: 0.1744 - val_accuracy: 0.9167 - val_auc_3: 0.9727 - val_precision_3: 0.8784 - val_recall_3: 0.8424\n",
      "Epoch 499/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2681 - accuracy: 0.9100 - auc_3: 0.9727 - precision_3: 0.8784 - recall_3: 0.8424 - val_loss: 0.1766 - val_accuracy: 0.9167 - val_auc_3: 0.9728 - val_precision_3: 0.8784 - val_recall_3: 0.8425\n",
      "Epoch 500/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 0.2532 - accuracy: 0.8900 - auc_3: 0.9728 - precision_3: 0.8784 - recall_3: 0.8425 - val_loss: 0.1788 - val_accuracy: 0.9167 - val_auc_3: 0.9728 - val_precision_3: 0.8784 - val_recall_3: 0.8425\n"
     ]
    }
   ],
   "source": [
    "keras_do_bn_reg_model = model.fit(X_train, y_train, epochs=500,\n",
    "                                  batch_size=20, validation_split=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 89us/step\n",
      "112/112 [==============================] - 0s 71us/step\n",
      "[('loss', 0.09553925480161395), ('accuracy', 0.9732142686843872), ('auc_3', 0.9728368520736694), ('precision_3', 0.878604531288147), ('recall_3', 0.8427282571792603)]\n",
      "Training Metrics: \n",
      " loss 0.09553925480161395 \n",
      " accuracy 0.9732142686843872 \n",
      " auc_3 0.9728368520736694 \n",
      " precision_3 0.8427282571792603 \n",
      " recall_3 0.8427282571792603 \n",
      "\n",
      "38/38 [==============================] - 0s 131us/step\n",
      "[('loss', 0.177237973401421), ('accuracy', 0.9473684430122375), ('auc_3', 0.9728591442108154), ('precision_3', 0.8786613941192627), ('recall_3', 0.8428055047988892)]\n",
      "Testing Metrics: \n",
      " loss 0.177237973401421 \n",
      " accuracy 0.9473684430122375 \n",
      " auc_3 0.9728591442108154 \n",
      " precision_3 0.8428055047988892 \n",
      " recall_3 0.8428055047988892 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# Returns the loss value and the metrics values for the model in test mode\n",
    "#     That is the evaluate() method is runs the model in test mode\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "scores_train = model.evaluate(X_train, y_train)\n",
    "print(list(zip(model.metrics_names, scores_train)))\n",
    "print(\"Training Metrics: \\n\", model.metrics_names[0], scores_train[0], \"\\n\",\n",
    "      model.metrics_names[1], scores_train[1], \"\\n\",\n",
    "      model.metrics_names[2], scores_train[2], \"\\n\",\n",
    "      model.metrics_names[3], scores_train[4], \"\\n\",\n",
    "      model.metrics_names[4], scores_train[4], \"\\n\")\n",
    "\n",
    "scores_test = model.evaluate(X_test, y_test)\n",
    "print(list(zip(model.metrics_names, scores_test)))\n",
    "print(\"Testing Metrics: \\n\", model.metrics_names[0], scores_test[0], \"\\n\",\n",
    "      model.metrics_names[1], scores_test[1], \"\\n\",\n",
    "      model.metrics_names[2], scores_test[2], \"\\n\",\n",
    "      model.metrics_names[3], scores_test[4], \"\\n\",\n",
    "      model.metrics_names[4], scores_test[4], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "HL1 (Dense)                  (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "HL2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "OL (Dense)                   (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 117\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# In Batch Normalization layer 12 parameters are trainable\n",
    "# and 12 are not trainable. Trainable parameters are gamma and beta\n",
    "# Non-trainable parameters are running weighted mean and standard deviation\n",
    "\n",
    "# First Batch-norm layer\n",
    "# So, 6 neurons 4 params(moving_mean, moving_variance, gamma, beta)  ==> 2 non-trainable per neuron  ==> 12 non-trainable params\n",
    "\n",
    "# Second Batch-norm layer\n",
    "# So, 6 neurons 4 params(moving_mean, moving_variance, gamma, beta)  ==> 2 non-trainable per neuron  ==> 12 non-trainable params\n",
    "\n",
    "# So, total non-trainable: 12+12 = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_viz(model, title=\"Shallow Neural Network\", view=True) # doesnot gives propee output.. gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
