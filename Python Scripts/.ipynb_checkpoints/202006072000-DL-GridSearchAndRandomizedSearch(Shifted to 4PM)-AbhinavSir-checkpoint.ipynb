{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare data\n",
    "# MTCars dataset\n",
    "cars = pd.read_csv(\"C:/Users/Admin/Documents/Datasets/mtcars.csv\")\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mazda RX4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda RX4 Wag</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datsun 710</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet 4 Drive</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet Sportabout</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "Unnamed: 0                                                                   \n",
       "Mazda RX4          21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "Mazda RX4 Wag      21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "Datsun 710         22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "Hornet 4 Drive     21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "                   carb  \n",
       "Unnamed: 0               \n",
       "Mazda RX4             4  \n",
       "Mazda RX4 Wag         4  \n",
       "Datsun 710            1  \n",
       "Hornet 4 Drive        1  \n",
       "Hornet Sportabout     2  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.set_index(keys=\"Unnamed: 0\", inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32 entries, Mazda RX4 to Volvo 142E\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mpg     32 non-null     float64\n",
      " 1   cyl     32 non-null     int64  \n",
      " 2   disp    32 non-null     float64\n",
      " 3   hp      32 non-null     int64  \n",
      " 4   drat    32 non-null     float64\n",
      " 5   wt      32 non-null     float64\n",
      " 6   qsec    32 non-null     float64\n",
      " 7   vs      32 non-null     int64  \n",
      " 8   am      32 non-null     int64  \n",
      " 9   gear    32 non-null     int64  \n",
      " 10  carb    32 non-null     int64  \n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"cyl\"] = cars.cyl.astype(\"category\")\n",
    "cars.am = cars.am.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cars.mpg\n",
    "X = cars.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    disp   hp  drat     wt   qsec  vs am  gear  carb\n",
      "Unnamed: 0                                                          \n",
      "Mazda RX4          160.0  110  3.90  2.620  16.46   0  1     4     4\n",
      "Mazda RX4 Wag      160.0  110  3.90  2.875  17.02   0  1     4     4\n",
      "Datsun 710         108.0   93  3.85  2.320  18.61   1  1     4     1\n",
      "Hornet 4 Drive     258.0  110  3.08  3.215  19.44   1  0     3     1\n",
      "Hornet Sportabout  360.0  175  3.15  3.440  17.02   0  0     3     2\n",
      "Unnamed: 0\n",
      "Mazda RX4            21.0\n",
      "Mazda RX4 Wag        21.0\n",
      "Datsun 710           22.8\n",
      "Hornet 4 Drive       21.4\n",
      "Hornet Sportabout    18.7\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# sgd,relu,[70,70],learning_rate_init = 0.1 diverges\n",
    "nnreg = MLPRegressor(solver = 'sgd', activation = 'relu',\n",
    "                    hidden_layer_sizes = (70,70),\n",
    "                    learning_rate = 'constant',\n",
    "                    learning_rate_init = 0.1,\n",
    "                    random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploding Gradients  --  i.e. exploding weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTCars Data Set\n",
      "R2 of NN Regressor on training set: -937283129859776747020063658796785751143880932448852019326924160802154251135483904.000\n",
      "R2 of NN Regressor on test set: -1637087874532681635186041853869110326974828491300848341267745891938720763510521856.000\n",
      "MSE: 34372450490676426127650992791180280702336581082949979099529732077916628836197335040.000\n",
      "R-square: -1637087874532681635186041853869110326974828491300848341267745891938720763510521856.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MTCars Data Set\")\n",
    "print(\"R2 of NN Regressor on training set: {:.3f}\".format(nnreg.score(X_train, y_train)))\n",
    "print(\"R2 of NN Regressor on test set: {:.3f}\".format(nnreg.score(X_test, y_test)))\n",
    "print(\"MSE: {:.3f}\".format(mean_squared_error(y_test, nnreg.predict(X_test))))\n",
    "print(\"R-square: {:.3f}\".format(r2_score(y_test, nnreg.predict(X_test))))\n",
    "nnreg.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights Matrix:\n",
      " [array([[-1.57111202e+16, -9.86327158e+15, -1.98186393e+16,\n",
      "        -3.24311888e+15, -5.05750970e+01,  8.04115894e-02,\n",
      "        -3.43996851e-02, -6.58893006e+02, -1.52587282e+16,\n",
      "        -6.42428439e-02, -7.75589450e+00,  1.59258408e-02,\n",
      "         3.75037155e-02, -2.39263742e+16, -2.36429501e-01,\n",
      "        -2.27559485e-01, -2.64438368e-01, -4.85345503e+15,\n",
      "        -1.70694011e+16, -2.41398269e+02, -1.93108906e+02,\n",
      "        -1.93966364e+16, -2.12311905e-02, -4.44763051e+02,\n",
      "        -2.10393411e-01,  7.71194360e-02, -1.96570844e-01,\n",
      "        -4.76343246e+15, -1.16781746e+16, -4.70352703e-02,\n",
      "        -2.28666015e+01, -8.63375680e+01, -1.08951519e+02,\n",
      "        -1.14747934e+01, -2.65225760e-01, -9.76694016e+01,\n",
      "        -3.82884745e+01, -3.22130620e+02, -1.31206606e+16,\n",
      "        -2.93412813e+02, -7.74341937e-02, -5.76663241e+15,\n",
      "        -1.32137431e+16, -2.42387908e-01, -2.19634555e+02,\n",
      "        -6.37822203e+01, -1.21096437e+15, -2.04522482e-01,\n",
      "        -1.18761077e+01, -1.77141064e+01, -6.99377241e+01,\n",
      "        -2.16030758e+00, -5.97744642e+01, -2.19338592e-01,\n",
      "        -1.60456664e-01, -1.86674016e-01,  8.43878039e-02,\n",
      "        -1.35976798e-01, -2.96367052e+15, -1.40863424e-01,\n",
      "        -1.87963703e-01, -2.14747213e-01,  8.61632488e-02,\n",
      "        -1.99420548e-01, -1.67232893e-01, -7.23539658e-02,\n",
      "        -1.69573815e+16, -2.22063290e-01, -2.01957045e+16,\n",
      "        -2.22616035e-01],\n",
      "       [-9.86459235e+15, -6.19288455e+15, -1.24435938e+16,\n",
      "        -2.03626765e+15, -3.30758603e+01, -2.53983120e-01,\n",
      "        -1.19708993e-01, -3.87830011e+02, -9.58054751e+15,\n",
      "        -2.10143572e-01, -7.02104120e+00, -4.72551547e-02,\n",
      "        -2.40226229e-01, -1.50227307e+16,  3.67083269e-02,\n",
      "        -1.29308877e-01,  1.28134912e-02, -3.04735466e+15,\n",
      "        -1.07174206e+16, -1.47048640e+02, -1.16582983e+02,\n",
      "        -1.21786294e+16, -2.02939779e-01, -2.92095716e+02,\n",
      "        -1.16071790e-01, -1.74613530e-01,  4.76828190e-02,\n",
      "        -2.99083190e+15, -7.33241362e+15, -2.72994044e-01,\n",
      "        -2.53795122e+01, -4.53105161e+01, -7.25088262e+01,\n",
      "        -1.92940150e+01, -1.38478234e-01, -5.90792942e+01,\n",
      "         9.87034671e-01, -2.09626403e+02, -8.23811205e+15,\n",
      "        -1.88382481e+02, -2.91425902e-02, -3.62071433e+15,\n",
      "        -8.29655604e+15, -1.11645469e-01, -1.51391041e+02,\n",
      "        -3.08851765e+01, -7.60332154e+14,  4.47946852e-02,\n",
      "        -7.92244007e+00, -1.90467798e+01, -4.88569368e+01,\n",
      "        -1.94329750e+00, -4.62350458e+01,  7.93622205e-02,\n",
      "        -4.19683594e-02,  5.86401142e-02, -2.65003421e-01,\n",
      "        -1.09364827e-01, -1.86080949e+15, -1.15701675e-01,\n",
      "         6.50458611e-02, -3.92601309e-02, -2.00913589e-01,\n",
      "        -1.11179529e-01,  3.85621431e-02,  5.00857986e-02,\n",
      "        -1.06470865e+16,  8.44387835e-02, -1.26803429e+16,\n",
      "        -3.77996925e-02],\n",
      "       [-1.98561238e+14, -1.24654601e+14, -2.50473137e+14,\n",
      "        -4.09873830e+13, -1.23483008e+00,  1.12376056e-01,\n",
      "        -2.20340566e-01, -1.23892740e+01, -1.92843790e+14,\n",
      "         2.74946534e-01, -5.24916500e-01,  2.02897847e-01,\n",
      "        -1.86021759e-01, -3.02387763e+14, -2.07336900e-01,\n",
      "         1.91809623e-01,  1.69383160e-01, -6.13392317e+13,\n",
      "        -2.15727547e+14, -4.65500474e+00, -3.34745704e+00,\n",
      "        -2.45139754e+14,  1.22389062e-01, -8.94006967e+00,\n",
      "         2.62090356e-01,  1.96106009e-01, -2.69125640e-01,\n",
      "        -6.02015029e+13, -1.47591819e+14, -1.80985915e-01,\n",
      "        -8.75710578e-01, -1.39145651e+00, -2.08795330e+00,\n",
      "        -1.04811108e+00,  1.61875614e-01, -2.05695827e+00,\n",
      "         3.63186743e-01, -6.38620465e+00, -1.65822334e+14,\n",
      "        -6.45963921e+00, -1.84808525e-01, -7.28802058e+13,\n",
      "        -1.66998735e+14, -1.44464053e-01, -4.64696346e+00,\n",
      "        -7.55058774e-01, -1.53044838e+13,  4.95551462e-02,\n",
      "        -2.90520665e-01, -6.90830678e-01, -1.56873046e+00,\n",
      "        -2.86135936e-01, -1.61448741e+00,  2.44922084e-01,\n",
      "         1.32031785e-01, -5.25876163e-03, -1.50239256e-01,\n",
      "        -1.35389875e-01, -3.74556417e+13, -3.61471979e-02,\n",
      "        -1.03731343e-01,  1.08217471e-01, -6.73787907e-02,\n",
      "        -1.76590933e-01, -2.61979994e-01, -2.38516443e-01,\n",
      "        -2.14311814e+14, -2.55206344e-02, -2.55238585e+14,\n",
      "         2.18630954e-01],\n",
      "       [-2.00276781e+14, -1.25731601e+14, -2.52637192e+14,\n",
      "        -4.13415087e+13, -1.16816593e+00,  1.42409024e-01,\n",
      "        -9.92000750e-02, -1.01190567e+01, -1.94509935e+14,\n",
      "         1.82462005e-01, -1.06215325e-01,  2.05391642e-01,\n",
      "        -1.24815488e-01, -3.05000354e+14, -1.73266164e-01,\n",
      "         2.49562481e-01,  1.03336797e-01, -6.18691947e+13,\n",
      "        -2.17591405e+14, -3.44554055e+00, -2.93971229e+00,\n",
      "        -2.47257729e+14,  1.00315791e-02, -7.18327338e+00,\n",
      "        -1.61231976e-01, -4.15106616e-02, -6.93529825e-02,\n",
      "        -6.07216360e+13, -1.48866993e+14,  4.78324114e-02,\n",
      "        -2.52972814e-01, -1.36551379e+00, -1.57176778e+00,\n",
      "        -5.71357667e-01,  1.19525259e-01, -1.53917554e+00,\n",
      "        -1.39792298e-01, -5.18076558e+00, -1.67255018e+14,\n",
      "        -4.65208787e+00, -7.95810673e-02, -7.35098813e+13,\n",
      "        -1.68441582e+14,  1.37054446e-01, -3.31292759e+00,\n",
      "        -1.04634486e+00, -1.54367126e+13,  4.65601718e-02,\n",
      "         9.92123793e-04, -4.42063947e-01, -1.27841035e+00,\n",
      "        -2.75184998e-01, -1.23704107e+00,  2.36741115e-01,\n",
      "         9.36518910e-02,  1.57166032e-01, -1.20302518e-01,\n",
      "         4.76261767e-02, -3.77792535e+13, -7.92155235e-03,\n",
      "         2.63178152e-01,  2.07516154e-01, -8.92009666e-02,\n",
      "         2.54400873e-01, -1.47876417e-01,  2.47648379e-01,\n",
      "        -2.16163440e+14,  1.64909708e-01, -2.57443813e+14,\n",
      "         2.06294069e-01],\n",
      "       [-1.01937674e+15, -6.39953712e+14, -1.28588285e+15,\n",
      "        -2.10421659e+14, -6.69331644e+00, -1.93932106e-01,\n",
      "         2.65567035e-01, -6.40432784e+01, -9.90024422e+14,\n",
      "         7.68722362e-02, -1.68666604e+00, -2.00127515e-01,\n",
      "         1.77539713e-01, -1.55240296e+15,  6.23861620e-03,\n",
      "        -1.51946541e-01, -2.21653660e-01, -3.14904293e+14,\n",
      "        -1.10750540e+15, -2.22117951e+01, -1.71537779e+01,\n",
      "        -1.25850225e+15, -9.19643928e-02, -4.54589457e+01,\n",
      "        -5.11253311e-02, -1.47582913e-01, -2.02559602e-01,\n",
      "        -3.09063403e+14, -7.57709155e+14, -2.69283618e-01,\n",
      "        -3.86793799e+00, -6.51228277e+00, -9.95880119e+00,\n",
      "        -3.49599366e+00,  9.48265653e-02, -9.73200008e+00,\n",
      "         9.33474481e-01, -3.26090544e+01, -8.51301255e+14,\n",
      "        -3.07857726e+01, -1.26587001e-01, -3.74153524e+14,\n",
      "        -8.57340677e+14, -1.09351699e-01, -2.38150183e+01,\n",
      "        -4.55147116e+00, -7.85703949e+13,  1.07821712e-01,\n",
      "        -2.22789483e+00, -2.70881940e+00, -7.72905659e+00,\n",
      "        -4.36135568e-01, -6.90038489e+00,  1.08577796e-01,\n",
      "         1.53606882e-01,  1.52897074e-01, -1.32597632e-01,\n",
      "        -6.95496612e-02, -1.92290350e+14, -1.25212399e-01,\n",
      "        -7.11812935e-02, -1.66972788e-01, -2.21259935e-02,\n",
      "        -2.50993326e-01,  1.65236712e-01, -2.33166396e-01,\n",
      "        -1.10023729e+15, -1.06479327e-01, -1.31034778e+15,\n",
      "         2.53223138e-01],\n",
      "       [-1.81281741e+13, -1.13806719e+13, -2.28676084e+13,\n",
      "        -3.74205168e+12, -2.33801186e-01,  9.99770297e-02,\n",
      "        -1.22581034e-01, -2.40532876e+00, -1.76061845e+13,\n",
      "         2.51554424e-01, -2.67639188e-01,  2.22661430e-01,\n",
      "         2.41442646e-02, -2.76072916e+13,  2.10567489e-01,\n",
      "        -2.28160078e-02,  1.23553141e-01, -5.60012760e+12,\n",
      "        -1.96954177e+13, -6.49012895e-01, -4.18675256e-01,\n",
      "        -2.23806830e+13,  1.41527155e-01, -1.48194919e+00,\n",
      "        -1.43291478e-01, -1.87098795e-01,  1.63360324e-01,\n",
      "        -5.49625564e+12, -1.34747860e+13,  5.01472005e-02,\n",
      "         3.42524430e-02, -2.03893357e-01, -2.53634810e-02,\n",
      "        -8.76104397e-02,  1.76795304e-01, -1.10413691e-01,\n",
      "         2.84096176e-01, -1.28903860e+00, -1.51391892e+13,\n",
      "        -1.19833658e+00, -2.41016898e-01, -6.65379140e+12,\n",
      "        -1.52465917e+13,  1.92377366e-01, -1.08012474e+00,\n",
      "         1.23471513e-01, -1.39726338e+12, -7.89780098e-02,\n",
      "        -3.84899934e-01, -2.86205459e-01, -3.39153435e-01,\n",
      "         2.06701879e-01, -4.21466122e-01,  2.45434194e-01,\n",
      "         2.03648793e-01, -2.52640387e-02, -9.55162429e-02,\n",
      "        -1.47301827e-01, -3.41961200e+12, -2.57352497e-01,\n",
      "        -2.66980521e-01, -3.92452376e-02, -2.38062040e-01,\n",
      "        -1.36721208e-01, -1.53686078e-01, -1.36032140e-01,\n",
      "        -1.95661646e+13, -2.68948089e-01, -2.33026826e+13,\n",
      "         6.53020590e-02],\n",
      "       [-1.64650721e+13, -1.03365945e+13, -2.07697046e+13,\n",
      "        -3.39875106e+12, -1.22230240e-01, -5.34334440e-03,\n",
      "         2.69745072e-01, -1.66171682e+00, -1.59909706e+13,\n",
      "        -1.16627140e-01, -2.05742631e-01,  8.95666769e-02,\n",
      "        -1.39960842e-01, -2.50745633e+13,  9.53983234e-03,\n",
      "        -4.18394201e-02,  3.01419538e-02, -5.08636470e+12,\n",
      "        -1.78885348e+13, -5.62560119e-01, -4.66788265e-01,\n",
      "        -2.03274504e+13,  2.34226482e-01, -1.50894255e+00,\n",
      "        -1.47366388e-01, -8.34906769e-02,  1.73598199e-01,\n",
      "        -4.99202209e+12, -1.22385918e+13,  2.23192968e-01,\n",
      "        -3.39558693e-01,  2.27093196e-01, -3.84746549e-01,\n",
      "        -4.09649593e-01,  2.48548865e-01, -3.77909908e-01,\n",
      "         3.70280494e-01, -1.13405263e+00, -1.37503005e+13,\n",
      "        -6.25386522e-01, -1.25424601e-01, -6.04336404e+12,\n",
      "        -1.38478498e+13,  1.37123142e-01, -8.63179889e-01,\n",
      "        -2.15625870e-01, -1.26907665e+12, -1.07769983e-01,\n",
      "         1.26125765e-01, -2.95054053e-01, -2.22365778e-01,\n",
      "         2.14028052e-01, -1.73093229e-01,  2.02436714e-01,\n",
      "         2.42627753e-01,  1.38212575e-01,  1.09998597e-01,\n",
      "         2.57925794e-01, -3.10589240e+12, -2.65541562e-02,\n",
      "        -2.36521149e-01, -1.14204480e-01, -1.91609586e-01,\n",
      "        -4.54785434e-02, -2.03220065e-01,  5.73859899e-02,\n",
      "        -1.77711396e+13,  2.17922483e-01, -2.11648646e+13,\n",
      "         2.58412720e-02],\n",
      "       [-2.03796582e+14, -1.27941294e+14, -2.57077211e+14,\n",
      "        -4.20680726e+13, -1.23887156e+00, -1.25856784e-01,\n",
      "        -2.45575828e-02, -1.23051248e+01, -1.97928386e+14,\n",
      "         3.23333983e-03, -4.25034346e-01, -6.99786179e-02,\n",
      "         1.37628099e-02, -3.10360638e+14, -9.17646985e-02,\n",
      "         2.33781061e-01,  1.99696956e-01, -6.29565261e+13,\n",
      "        -2.21415504e+14, -4.52729250e+00, -3.62646060e+00,\n",
      "        -2.51603206e+14,  1.32333123e-01, -9.19991898e+00,\n",
      "         6.74538966e-02,  1.16035686e-01, -1.62635454e-01,\n",
      "        -6.17887995e+13, -1.51483283e+14,  2.09020566e-01,\n",
      "        -1.02511028e+00, -1.27901302e+00, -2.25611054e+00,\n",
      "        -7.05128052e-01, -2.71236588e-01, -1.95554485e+00,\n",
      "         5.04751050e-01, -6.39875201e+00, -1.70194472e+14,\n",
      "        -6.29992700e+00, -2.62181461e-01, -7.48017942e+13,\n",
      "        -1.71401889e+14, -1.21769803e-01, -5.07275685e+00,\n",
      "        -1.03695043e+00, -1.57080079e+13,  1.07625806e-01,\n",
      "        -2.92346385e-01, -4.40779624e-01, -1.87186945e+00,\n",
      "        -3.85029552e-02, -1.40924600e+00,  4.89100823e-02,\n",
      "         2.55062361e-01, -2.66282962e-01,  1.08294051e-01,\n",
      "         1.72888393e-01, -3.84432119e+13, -9.15125940e-02,\n",
      "         1.60300641e-01, -2.21985218e-01, -3.19478723e-02,\n",
      "         1.09970315e-02,  1.06901800e-01, -2.25489074e-01,\n",
      "        -2.19962444e+14, -4.94385535e-02, -2.61968307e+14,\n",
      "         2.13278869e-01],\n",
      "       [-1.83405938e+14, -1.15140267e+14, -2.31355631e+14,\n",
      "        -3.78589975e+13, -7.09246453e-01,  2.32783022e-01,\n",
      "         2.28076056e-02, -6.91302102e+00, -1.78124877e+14,\n",
      "         2.58102632e-01,  1.89791864e-01, -2.55721478e-01,\n",
      "        -1.79253977e-01, -2.79307844e+14,  2.49204798e-01,\n",
      "        -1.10216869e-01, -1.87138027e-01, -5.66574797e+13,\n",
      "        -1.99262018e+14, -2.54524211e+00, -2.35703598e+00,\n",
      "        -2.26429322e+14, -3.29244716e-02, -6.06885183e+00,\n",
      "         1.08283421e-01, -1.39224723e-01, -2.53747370e-01,\n",
      "        -5.56065887e+13, -1.36326789e+14,  2.24727746e-01,\n",
      "        -4.92750816e-01, -5.70473315e-01, -1.26024514e+00,\n",
      "        -6.07429790e-01, -1.07782133e-01, -8.15237376e-01,\n",
      "         2.55389897e-01, -4.22393075e+00, -1.53165850e+14,\n",
      "        -3.36427729e+00, -1.79316600e-01, -6.73175824e+13,\n",
      "        -1.54252461e+14, -2.40744256e-01, -3.08560412e+00,\n",
      "        -5.07284934e-01, -1.41363603e+13, -1.44177194e-01,\n",
      "        -6.14546729e-02, -5.07371725e-01, -1.00030511e+00,\n",
      "        -1.19484738e-01, -7.72074325e-01, -2.02035005e-01,\n",
      "        -2.22227164e-01, -8.63168481e-02,  5.01707548e-02,\n",
      "         8.77323480e-02, -3.45968184e+13,  2.75184078e-01,\n",
      "        -8.16312552e-02,  1.22031395e-01,  7.58306343e-02,\n",
      "         1.72544033e-01,  2.62478463e-01,  2.14840248e-01,\n",
      "        -1.97954342e+14,  1.09267433e-01, -2.35757354e+14,\n",
      "        -1.94183042e-01]]), array([[ 3.55144988e+12, -1.21926545e+02,  1.23836190e+12, ...,\n",
      "        -5.10326482e-02,  1.92998403e-01, -1.62345348e+01],\n",
      "       [ 1.80097174e+13, -7.61083538e+01,  6.27984303e+12, ...,\n",
      "        -1.86582452e-01, -8.57500701e-02, -1.01156681e+01],\n",
      "       [ 1.19524572e+13, -1.53147673e+02,  4.16772531e+12, ...,\n",
      "        -6.85326152e-02, -1.34405267e-01, -2.07036222e+01],\n",
      "       ...,\n",
      "       [ 2.00171653e-01, -3.22654232e-02,  1.52908693e-01, ...,\n",
      "        -1.89878590e-01, -4.22085579e-02,  1.49244864e-01],\n",
      "       [ 5.36167741e+12, -1.56073859e+02,  1.86957362e+12, ...,\n",
      "         1.18054557e-01, -5.79496681e-03, -2.08778728e+01],\n",
      "       [ 4.62533156e-02,  1.45039581e-02,  7.24872849e-02, ...,\n",
      "         1.84742263e-01, -9.97064275e-02, -8.23505253e-02]]), array([[ 5.73450783e+29],\n",
      "       [ 3.91473369e+01],\n",
      "       [ 1.99957658e+29],\n",
      "       [-4.00554307e+15],\n",
      "       [-4.42280463e+66],\n",
      "       [ 4.26955640e+02],\n",
      "       [ 8.98178168e+02],\n",
      "       [-8.58653677e+63],\n",
      "       [ 3.43891829e+02],\n",
      "       [-1.09872573e+13],\n",
      "       [-5.02076452e+65],\n",
      "       [ 5.09302251e+20],\n",
      "       [-2.55445658e-01],\n",
      "       [ 3.90277174e+02],\n",
      "       [ 4.98416202e+24],\n",
      "       [-4.97158799e+15],\n",
      "       [ 1.74200914e+02],\n",
      "       [ 6.27745555e+20],\n",
      "       [-1.62718873e+16],\n",
      "       [ 1.13234178e-01],\n",
      "       [-2.59549107e+16],\n",
      "       [ 2.02179540e+02],\n",
      "       [ 1.41904597e-01],\n",
      "       [ 5.85056743e+20],\n",
      "       [ 5.74043355e+02],\n",
      "       [-2.43289539e+16],\n",
      "       [ 1.60087965e-01],\n",
      "       [-3.33933458e+15],\n",
      "       [ 9.16585309e+00],\n",
      "       [-2.61724370e-01],\n",
      "       [ 5.83221990e+20],\n",
      "       [ 1.06800315e+01],\n",
      "       [-4.48956316e-02],\n",
      "       [ 2.73079528e+02],\n",
      "       [ 9.11149495e+00],\n",
      "       [-7.72808272e+15],\n",
      "       [ 7.00869367e+01],\n",
      "       [-2.80932714e-01],\n",
      "       [-2.56201367e+16],\n",
      "       [ 6.96263540e+29],\n",
      "       [-1.92096285e-01],\n",
      "       [ 1.48308339e-01],\n",
      "       [ 1.62885722e+01],\n",
      "       [-2.29193467e+63],\n",
      "       [ 6.79180929e+19],\n",
      "       [-3.98634367e-02],\n",
      "       [ 1.95964780e+02],\n",
      "       [ 1.96360923e+01],\n",
      "       [ 1.59314014e+02],\n",
      "       [-2.74144634e+16],\n",
      "       [ 1.69769854e+02],\n",
      "       [ 1.97236315e-01],\n",
      "       [ 2.96343717e+02],\n",
      "       [-1.44655229e+15],\n",
      "       [-8.10394531e+15],\n",
      "       [ 8.62099750e+20],\n",
      "       [ 2.87918046e+02],\n",
      "       [ 1.07941727e+30],\n",
      "       [-2.38109884e-01],\n",
      "       [ 6.44179255e+29],\n",
      "       [-1.17346805e+16],\n",
      "       [-4.80133138e+63],\n",
      "       [ 5.87981780e+29],\n",
      "       [ 3.84411969e+02],\n",
      "       [-2.09747746e+16],\n",
      "       [-2.48646880e-01],\n",
      "       [-3.78405735e+15],\n",
      "       [ 6.33682566e+20],\n",
      "       [-1.01511214e+64],\n",
      "       [ 3.51050619e+02]])]\n",
      "\n",
      "Biases:\n",
      " [array([-5.82488201e+13, -3.65679802e+13, -7.34774059e+13, -1.20238306e+13,\n",
      "       -1.96926155e-01,  2.52848021e-01, -2.10924630e-01, -3.64564569e+00,\n",
      "       -5.65715813e+13,  1.35258082e-01,  1.07606617e-01,  2.40221165e-01,\n",
      "        2.66454032e-01, -8.87067917e+13, -6.59566447e-02, -1.94120199e-01,\n",
      "        1.01931841e-01, -1.79941357e+13, -6.32846328e+13, -1.44370732e+00,\n",
      "       -9.49905121e-01, -7.19128342e+13, -1.42448140e-01, -2.64478503e+00,\n",
      "        1.98193138e-01, -2.43325951e-01, -1.61931189e-02, -1.76603779e+13,\n",
      "       -4.32967148e+13,  2.64544797e-01, -2.69482270e-01, -1.44366324e-01,\n",
      "       -7.50457350e-01, -3.06022919e-01, -5.30273493e-02, -5.71568601e-01,\n",
      "        1.51326516e-01, -1.85897645e+00, -4.86447174e+13, -1.58938286e+00,\n",
      "       -5.55801840e-02, -2.13797317e+13, -4.89898196e+13, -2.36983395e-01,\n",
      "       -1.11184301e+00, -1.60464803e-01, -4.48963822e+12,  2.03511553e-02,\n",
      "       -3.20740557e-01, -2.02851101e-01, -4.63412557e-01, -1.28545728e-01,\n",
      "       -6.30798179e-01,  1.30769379e-01, -2.15078321e-01,  5.85947312e-02,\n",
      "        1.12009065e-01,  7.42912902e-02, -1.09877786e+13, -2.18653430e-01,\n",
      "        2.02374554e-01, -2.59500105e-01,  1.92454112e-02, -5.27788355e-02,\n",
      "        1.33296180e-02, -7.43540143e-02, -6.28693214e+13, -2.65049002e-01,\n",
      "       -7.48753712e+13,  1.88931153e-01]), array([-1.83490936e+34, -3.51914556e+00, -2.60900114e+34, -7.66494276e+10,\n",
      "       -5.39354385e+63, -2.87043156e+00, -9.62080160e-01, -1.35207909e+63,\n",
      "       -2.82775713e-01, -2.14588653e+07, -4.50257489e+63, -3.32112826e+20,\n",
      "       -1.35960291e-01, -1.97109087e+00, -4.69595021e+34, -6.47316729e+11,\n",
      "       -3.13496189e-01, -3.92098351e+20, -1.05954053e+11, -1.54234990e-01,\n",
      "       -3.88333233e+11, -3.96852462e+00, -1.92324208e-01, -1.26359051e+21,\n",
      "       -1.53595141e+00, -1.79660988e+11, -2.15464536e-02, -4.59214176e+09,\n",
      "       -5.52654759e-01, -9.27031041e-02, -6.90664875e+20, -1.75389266e-01,\n",
      "       -2.18023810e-02, -2.43196342e-01, -9.45698820e-01, -3.69151873e+11,\n",
      "       -3.20639308e-01, -1.86097063e-01, -4.99544082e+11, -7.70447787e+34,\n",
      "       -1.73154117e-01, -1.21028196e-01, -5.06412725e-01, -5.79842478e+63,\n",
      "       -1.42321512e+21, -6.46102648e-03, -3.80396323e+00, -1.20998449e+00,\n",
      "       -2.25163978e+00, -1.44678712e+11, -1.66064094e+00, -1.84502896e-01,\n",
      "       -6.90776567e-01, -1.89147549e+09, -3.13801502e+10, -1.41997052e+21,\n",
      "       -2.95729195e+00, -6.08691568e+34, -6.66752516e-03, -5.93102994e+34,\n",
      "       -3.27706952e+10, -5.67247980e+63, -6.78613961e+33, -7.22902959e-01,\n",
      "       -3.40973618e+11, -1.55981775e-01, -1.42922328e+11, -1.10902901e+21,\n",
      "       -7.12265534e+63, -4.73165955e-01]), array([1.85398087e+41])]\n"
     ]
    }
   ],
   "source": [
    "# EXPLODING GRADIENTS\n",
    "print(\"\\nWeights Matrix:\\n\", nnreg.coefs_)\n",
    "print(\"\\nBiases:\\n\", nnreg.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=229, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(70, 70), learning_rate='constant',\n",
       "             learning_rate_init=1, max_fun=15000, max_iter=6000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=0, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Effect of Regularization\n",
    "# lbfgs, logistic\n",
    "# nnreg = MLPRegressor(solver = 'lbfgs', activation = 'logistic',\n",
    "#                     hidden_layer_sizes = [7,7],\n",
    "#                     learning_rate = 'constant',\n",
    "#                     learning_rate_init = 0.01,\n",
    "#                     max_iter = 2000,\n",
    "#                     power_t = 0.9,\n",
    "#                     alpha = 10,\n",
    "#                     random_state=0).fit(X_train, y_train)\n",
    "\n",
    "nnreg = MLPRegressor(solver=\"lbfgs\",\n",
    "                     activation=\"relu\",\n",
    "                     hidden_layer_sizes=(70, 70),\n",
    "                     learning_rate=\"constant\",\n",
    "                     learning_rate_init=1,\n",
    "                     max_iter=6000,\n",
    "                     alpha=229,#weights will shrink a lot bcoz of dis high regularization value\n",
    "                     random_state=0\n",
    "                    )\n",
    "nnreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTCars Data Set\n",
      "R2 of NN Regressor on training set: 0.853\n",
      "R2 of NN Regressor on test set: 0.800\n",
      "MSE: 4.190\n",
      "R-square: 0.800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MTCars Data Set\")\n",
    "print(\"R2 of NN Regressor on training set: {:.3f}\".format(nnreg.score(X_train, y_train)))\n",
    "print(\"R2 of NN Regressor on test set: {:.3f}\".format(nnreg.score(X_test, y_test)))\n",
    "print(\"MSE: {:.3f}\".format(mean_squared_error(y_test, nnreg.predict(X_test))))\n",
    "print(\"R-square: {:.3f}\".format(r2_score(y_test, nnreg.predict(X_test))))\n",
    "nnreg.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation function at Output layer:  identity\n",
      "Number of Layers:  4\n",
      "Number of Outputs:  1\n",
      "Number of iterations for convergence:  1301\n",
      "\n",
      "Weights matrix:\n",
      " [array([[ 7.60119468e-02,  4.53248627e-03, -2.57551069e-03,\n",
      "         1.79783273e-03, -8.55075744e-06, -1.94425510e-02,\n",
      "         5.10159148e-02,  7.27891777e-02, -1.29608054e-04,\n",
      "        -9.68255037e-03, -1.49854292e-02, -1.89671140e-02,\n",
      "        -1.89938202e-02,  1.82712246e-03,  1.56644458e-02,\n",
      "         8.81850444e-03, -7.16299168e-03, -2.79057706e-02,\n",
      "        -7.76582336e-02,  1.06857004e-05, -3.85841466e-02,\n",
      "        -7.49408793e-02,  3.08668078e-02, -1.11438169e-05,\n",
      "        -1.43676036e-02,  4.56753558e-02,  3.19441373e-04,\n",
      "         1.95763418e-02, -5.46883605e-02, -2.04303362e-02,\n",
      "         7.90166093e-04, -1.28813365e-02,  1.67145899e-01,\n",
      "         1.75124484e-01,  4.72684009e-03,  2.24326246e-03,\n",
      "        -8.17266199e-03, -5.30399426e-06, -8.75226827e-04,\n",
      "        -6.15225510e-03,  1.45239682e-02,  1.09801237e-03,\n",
      "         1.22170735e-05, -3.75408882e-05,  1.75197773e-03,\n",
      "        -1.36968141e-02, -1.51672292e-02, -1.29540599e-03,\n",
      "         5.67540656e-02,  6.19260408e-03,  1.57042155e-01,\n",
      "         1.19776299e-05,  9.62265816e-06,  3.83026172e-03,\n",
      "        -3.67737495e-05, -4.18839957e-03, -9.09261381e-03,\n",
      "        -5.73230768e-03, -4.40226150e-02,  4.12434296e-02,\n",
      "        -1.56853985e-02,  3.96269981e-05, -1.55925419e-03,\n",
      "         6.70870715e-04, -1.50385090e-04,  1.23471812e-02,\n",
      "        -1.10759951e-03,  4.62410923e-02, -4.60717928e-04,\n",
      "        -1.38051683e-02],\n",
      "       [ 4.96435530e-02,  2.96918983e-03, -5.43702860e-04,\n",
      "         1.16019129e-03, -1.45804859e-05, -6.82961592e-03,\n",
      "         3.33413377e-02,  4.76863196e-02, -1.17002911e-04,\n",
      "        -3.00244107e-03, -4.83026905e-03, -6.10865870e-03,\n",
      "        -6.50235266e-03,  1.22431261e-03,  1.01967796e-02,\n",
      "         5.84161412e-03, -2.37921413e-03, -9.53480507e-03,\n",
      "        -2.73844472e-02,  2.66240564e-05, -1.32188631e-02,\n",
      "        -2.55472521e-02,  2.01716160e-02, -1.05663289e-05,\n",
      "        -5.15351793e-03,  2.98459498e-02,  2.11853127e-04,\n",
      "         1.29114968e-02, -1.89380341e-02, -7.00562041e-03,\n",
      "         4.98583743e-04, -4.44689597e-03,  1.09113620e-01,\n",
      "         1.14468096e-01,  3.10283259e-03,  1.50110150e-03,\n",
      "        -1.68794519e-03,  1.52342206e-06, -1.32969743e-04,\n",
      "        -1.72031977e-03,  9.53221162e-03,  7.25298459e-04,\n",
      "         1.75175225e-05, -1.25164478e-05,  1.24296162e-03,\n",
      "        -4.51494934e-03, -5.33110958e-03, -4.34965964e-04,\n",
      "         3.74469272e-02,  4.05529590e-03,  1.02759601e-01,\n",
      "         2.74000469e-06,  1.18603510e-05,  2.72301648e-03,\n",
      "        -5.92494326e-05, -1.25836007e-03, -3.15852125e-03,\n",
      "        -1.90095367e-03, -1.49957726e-02,  2.69510035e-02,\n",
      "        -5.20198612e-03,  3.20331055e-05, -4.17049400e-04,\n",
      "         4.33785710e-04, -8.24927508e-05,  8.29647412e-03,\n",
      "        -5.02162867e-04,  3.02923191e-02, -1.86272649e-04,\n",
      "        -4.38745433e-03],\n",
      "       [-3.69539900e-04, -1.88502562e-05,  5.21357712e-05,\n",
      "        -1.30787649e-05,  1.12814655e-05,  1.39428472e-04,\n",
      "        -2.34666322e-04, -3.21327108e-04,  2.69431638e-06,\n",
      "         1.26442298e-04,  1.51302258e-04,  1.94434777e-04,\n",
      "         1.64067795e-04, -4.85574503e-06, -7.23408142e-05,\n",
      "        -5.38484928e-05,  6.44586809e-05,  2.64654132e-04,\n",
      "         6.55285724e-04,  7.24385500e-06,  3.33807035e-04,\n",
      "         6.91667892e-04, -1.40840409e-04,  4.37824313e-07,\n",
      "         8.27783694e-05, -2.13424068e-04, -1.76169516e-06,\n",
      "        -8.91958684e-05,  4.90435127e-04,  1.42395198e-04,\n",
      "        -8.60307490e-07,  9.64796034e-05, -8.30262720e-04,\n",
      "        -8.53664621e-04, -2.45412762e-05, -1.03742714e-05,\n",
      "         1.52216691e-04,  1.16058302e-07,  5.84099239e-05,\n",
      "         8.46718075e-05, -6.57953457e-05, -1.35891611e-06,\n",
      "        -1.69313716e-05,  7.69140247e-07, -8.22023591e-06,\n",
      "         1.29953944e-04,  1.03766186e-04,  6.97966731e-06,\n",
      "        -2.76505064e-04, -2.97880583e-05, -7.81552487e-04,\n",
      "         2.91968990e-06,  6.82744849e-06, -7.39601155e-05,\n",
      "        -7.67267240e-07,  4.70107420e-05,  7.12872170e-05,\n",
      "         5.69632008e-05,  3.71949089e-04, -1.92994237e-04,\n",
      "         1.53105625e-04,  1.23913057e-05,  1.60847014e-05,\n",
      "        -3.61261899e-06, -1.66621234e-07, -5.10869436e-05,\n",
      "         2.10254539e-05, -2.08464329e-04,  2.10309042e-06,\n",
      "         1.37010754e-04],\n",
      "       [ 2.11080226e-03,  1.25566133e-04, -4.56026137e-05,\n",
      "         5.01615074e-05, -1.73594877e-06, -3.66930483e-04,\n",
      "         1.41501252e-03,  2.02092059e-03, -4.98035458e-06,\n",
      "        -1.97673008e-04, -2.88044762e-04, -3.61086767e-04,\n",
      "        -3.63150913e-04,  5.24513902e-05,  4.32554907e-04,\n",
      "         2.46170779e-04, -1.35452577e-04, -5.39433747e-04,\n",
      "        -1.48662030e-03,  3.30538491e-07, -7.34521575e-04,\n",
      "        -1.44980059e-03,  8.55919373e-04, -7.82440079e-07,\n",
      "        -2.74321811e-04,  1.26682104e-03,  8.86336379e-06,\n",
      "         5.45280987e-04, -1.04829861e-03, -3.94618382e-04,\n",
      "         2.17106316e-05, -2.47026509e-04,  4.63903453e-03,\n",
      "         4.85842449e-03,  1.31639787e-04,  6.31981093e-05,\n",
      "        -1.48633618e-04, -3.70655185e-07, -2.59112817e-05,\n",
      "        -1.12846593e-04,  4.03981316e-04,  3.08287570e-05,\n",
      "         8.95231077e-07, -2.46121105e-07,  5.33492821e-05,\n",
      "        -2.63131540e-04, -2.93931668e-04, -2.47222491e-05,\n",
      "         1.58858975e-03,  1.71612649e-04,  4.36694237e-03,\n",
      "        -3.37395856e-07, -7.41106948e-08,  1.28308723e-04,\n",
      "        -1.40205580e-06, -7.98086194e-05, -1.73542153e-04,\n",
      "        -1.09792847e-04, -8.36231578e-04,  1.14318706e-03,\n",
      "        -2.99826806e-04,  9.99668283e-07, -2.85395706e-05,\n",
      "         1.92652435e-05, -3.14036134e-06,  3.50285804e-04,\n",
      "        -2.27832709e-05,  1.28406684e-03, -9.05743849e-06,\n",
      "        -2.61851928e-04],\n",
      "       [ 5.50606328e-04,  4.66227567e-05,  1.52240387e-04,\n",
      "        -4.40994291e-06,  4.17629413e-05,  1.25441200e-04,\n",
      "         4.19454898e-04,  6.51104973e-04,  7.59982903e-06,\n",
      "         2.72910006e-04,  2.55688406e-04,  3.36525848e-04,\n",
      "         2.27735270e-04,  3.24236882e-05,  1.25877098e-04,\n",
      "         2.14341570e-05,  9.49747612e-05,  4.17250778e-04,\n",
      "         9.08425921e-04,  2.92912993e-05,  4.51015191e-04,\n",
      "         1.02458587e-03,  2.56835321e-04, -1.81920932e-06,\n",
      "         1.71596563e-05,  3.55360919e-04,  2.69193866e-06,\n",
      "         1.61948794e-04,  7.04046859e-04,  1.07898952e-04,\n",
      "         1.89430476e-05,  9.31938117e-05,  1.13720435e-03,\n",
      "         1.25613974e-03,  2.58285545e-05,  1.92066126e-05,\n",
      "         4.09267786e-04, -1.49668451e-06,  2.30829189e-04,\n",
      "         1.92408219e-04,  1.25244436e-04,  2.31370344e-05,\n",
      "        -6.61888673e-05,  1.32604865e-06,  1.68831253e-05,\n",
      "         2.01509964e-04,  6.80575901e-05, -1.34630167e-06,\n",
      "         4.17938440e-04,  4.51259232e-05,  1.07956622e-03,\n",
      "         1.37624305e-05,  2.58780748e-05, -1.80189445e-04,\n",
      "        -4.65785868e-06,  8.96622662e-05,  8.19654691e-05,\n",
      "         9.71366563e-05,  4.96778465e-04,  3.24880051e-04,\n",
      "         2.55247289e-04,  4.47680565e-05,  2.88878945e-05,\n",
      "         5.95322062e-06, -1.00525255e-06,  1.31505520e-04,\n",
      "         6.25894300e-05,  3.96889161e-04, -4.75721017e-07,\n",
      "         2.29427185e-04],\n",
      "       [-3.41263522e-04, -1.97940043e-05,  1.92209599e-05,\n",
      "        -9.31798871e-06,  3.20666440e-06,  8.74623188e-05,\n",
      "        -2.25330811e-04, -3.18349013e-04,  1.39729482e-06,\n",
      "         5.94177159e-05,  7.96026370e-05,  1.05020747e-04,\n",
      "         9.26108237e-05, -7.42508177e-06, -6.86298374e-05,\n",
      "        -4.21648885e-05,  3.73919720e-05,  1.47240228e-04,\n",
      "         3.80580775e-04,  1.75518557e-06,  1.88146413e-04,\n",
      "         3.78904574e-04, -1.35798060e-04, -1.86596896e-07,\n",
      "         5.98598673e-05, -2.03289570e-04, -1.19729757e-06,\n",
      "        -8.63125686e-05,  2.68792449e-04,  9.63944819e-05,\n",
      "        -2.30672237e-06,  5.80214159e-05, -7.53084055e-04,\n",
      "        -7.84794579e-04, -2.16059303e-05, -9.79563037e-06,\n",
      "         5.95937072e-05, -3.96055270e-07,  2.22252916e-05,\n",
      "         3.62693983e-05, -6.42767831e-05, -3.94197914e-06,\n",
      "        -5.20684675e-06,  1.60051484e-07, -9.14323826e-06,\n",
      "         6.92798513e-05,  5.89897214e-05,  4.70861530e-06,\n",
      "        -2.57869916e-04, -2.79374951e-05, -7.10087149e-04,\n",
      "         1.38394900e-06,  1.06173274e-06, -3.54283191e-05,\n",
      "         3.33501767e-08,  2.46405526e-05,  4.13941114e-05,\n",
      "         3.13001876e-05,  2.15888512e-04, -1.82592028e-04,\n",
      "         8.44499074e-05,  2.46191764e-06,  6.61006078e-06,\n",
      "        -3.30375959e-06,  2.36266657e-07, -5.43929825e-05,\n",
      "         7.65216756e-06, -2.03651948e-04,  1.72730985e-06,\n",
      "         7.59801507e-05],\n",
      "       [-1.03333341e-03, -5.98803988e-05,  4.68312537e-05,\n",
      "        -2.64824944e-05,  3.98423104e-06,  2.40439432e-04,\n",
      "        -6.88516210e-04, -9.78339378e-04,  3.29520717e-06,\n",
      "         1.52962630e-04,  2.05598469e-04,  2.60063385e-04,\n",
      "         2.49597852e-04, -2.38340981e-05, -2.11346056e-04,\n",
      "        -1.23990238e-04,  9.42297315e-05,  3.74329468e-04,\n",
      "         1.00627844e-03,  2.61867049e-06,  5.01905846e-04,\n",
      "         1.00232113e-03, -4.16604165e-04, -1.76187990e-08,\n",
      "         1.68934658e-04, -6.18718212e-04, -4.06971609e-06,\n",
      "        -2.64003941e-04,  7.22515285e-04,  2.52541031e-04,\n",
      "        -9.53416277e-06,  1.60885789e-04, -2.27981803e-03,\n",
      "        -2.38283158e-03, -6.47453200e-05, -3.06369071e-05,\n",
      "         1.46029891e-04, -2.91391891e-07,  3.53606154e-05,\n",
      "         9.56695036e-05, -1.96172292e-04, -1.35195546e-05,\n",
      "        -8.31510001e-06,  7.55189649e-07, -2.49242565e-05,\n",
      "         1.86164668e-04,  1.93171896e-04,  1.55555144e-05,\n",
      "        -7.74908017e-04, -8.41974025e-05, -2.14223060e-03,\n",
      "         1.30867305e-06,  2.92081723e-06, -8.14695751e-05,\n",
      "         4.74426691e-07,  5.97791494e-05,  1.17129224e-04,\n",
      "         7.82923294e-05,  5.68483488e-04, -5.58242712e-04,\n",
      "         2.12041339e-04,  4.33325646e-06,  2.23677847e-05,\n",
      "        -9.10507335e-06,  9.49463793e-07, -1.65982894e-04,\n",
      "         1.90177636e-05, -6.22313009e-04,  5.53735331e-06,\n",
      "         1.87207494e-04],\n",
      "       [-1.44173714e-03, -8.19048094e-05,  9.62238542e-05,\n",
      "        -3.88922733e-05,  1.04740703e-05,  4.00653143e-04,\n",
      "        -9.55271782e-04, -1.34828872e-03,  5.82469448e-06,\n",
      "         2.86997916e-04,  3.73609633e-04,  4.77553078e-04,\n",
      "         4.29992708e-04, -2.99998705e-05, -2.93923694e-04,\n",
      "        -1.77958926e-04,  1.67616433e-04,  6.61687451e-04,\n",
      "         1.71126255e-03,  7.46159819e-06,  8.68057509e-04,\n",
      "         1.74872439e-03, -5.77295906e-04,  3.05553195e-07,\n",
      "         2.72109672e-04, -8.60558710e-04, -6.12000561e-06,\n",
      "        -3.66291108e-04,  1.24140437e-03,  4.32605936e-04,\n",
      "        -1.13372493e-05,  2.71385829e-04, -3.19157989e-03,\n",
      "        -3.32546809e-03, -9.24053309e-05, -4.20130966e-05,\n",
      "         3.02805273e-04,  1.03000605e-07,  8.82350995e-05,\n",
      "         1.85823422e-04, -2.71038064e-04, -1.68590080e-05,\n",
      "        -1.83391608e-05,  8.40737889e-07, -3.36309802e-05,\n",
      "         3.27550121e-04,  3.08243053e-04,  2.53147654e-05,\n",
      "        -1.07839164e-03, -1.16907781e-04, -2.99533533e-03,\n",
      "         3.19238712e-06,  7.31093544e-06, -1.46656882e-04,\n",
      "        -4.31273645e-07,  1.12206266e-04,  1.96443609e-04,\n",
      "         1.41322148e-04,  9.84743505e-04, -7.76494652e-04,\n",
      "         3.82413421e-04,  1.17229527e-05,  4.01089116e-05,\n",
      "        -1.21227302e-05,  1.37614441e-06, -2.25243483e-04,\n",
      "         3.72187114e-05, -8.60310823e-04,  7.82120723e-06,\n",
      "         3.43252665e-04],\n",
      "       [ 2.11120116e-03,  1.25181128e-04, -2.56191313e-05,\n",
      "         5.13321976e-05, -4.55698905e-06, -2.53044599e-04,\n",
      "         1.41118730e-03,  2.01612203e-03, -5.70172770e-06,\n",
      "        -1.34163411e-04, -1.87024351e-04, -2.32983098e-04,\n",
      "        -2.49173942e-04,  5.24316178e-05,  4.30912941e-04,\n",
      "         2.48242755e-04, -9.11832272e-05, -3.75396806e-04,\n",
      "        -1.07072516e-03, -1.31357489e-07, -4.99122218e-04,\n",
      "        -9.98999081e-04,  8.53701040e-04, -1.70577467e-07,\n",
      "        -1.93363617e-04,  1.26492422e-03,  8.66744722e-06,\n",
      "         5.46101979e-04, -7.30956491e-04, -2.66886225e-04,\n",
      "         2.04095755e-05, -1.67003552e-04,  4.63942404e-03,\n",
      "         4.85686433e-03,  1.32079593e-04,  6.44837748e-05,\n",
      "        -6.91734086e-05,  1.47042771e-07, -3.24666391e-05,\n",
      "        -5.94559820e-05,  4.03589257e-04,  2.96402677e-05,\n",
      "         4.80380918e-06,  5.29018269e-07,  5.60121123e-05,\n",
      "        -1.73894485e-04, -1.99413330e-04, -1.57164764e-05,\n",
      "         1.59868877e-03,  1.71765392e-04,  4.37355619e-03,\n",
      "        -1.42170607e-06,  1.17938540e-07,  1.41844463e-04,\n",
      "        -2.39581283e-06, -4.99825424e-05, -1.19245068e-04,\n",
      "        -7.40716866e-05, -5.70305236e-04,  1.13962864e-03,\n",
      "        -2.02993780e-04, -4.52261412e-08, -1.47342607e-05,\n",
      "         1.93959287e-05, -3.02812270e-06,  3.54215158e-04,\n",
      "        -2.01695669e-05,  1.28209632e-03, -7.95660437e-06,\n",
      "        -1.69290509e-04]]), array([[ 8.20211851e-08,  6.16874665e-03, -9.84641976e-04, ...,\n",
      "        -6.21348961e-03, -9.24230428e-03,  1.18772304e-02],\n",
      "       [ 1.58232856e-07,  3.64968838e-04, -5.97831884e-05, ...,\n",
      "        -3.76098506e-04, -5.57477850e-04,  6.98027067e-04],\n",
      "       [ 4.26150328e-08, -1.97303386e-04,  3.12218187e-05, ...,\n",
      "         1.93718559e-04,  2.88295015e-04, -3.89678605e-04],\n",
      "       ...,\n",
      "       [ 2.67614038e-07,  3.73482757e-03, -5.99741237e-04, ...,\n",
      "        -3.78380237e-03, -5.62481319e-03,  7.21125017e-03],\n",
      "       [-1.32237026e-08, -3.36617594e-05,  5.65110418e-06, ...,\n",
      "         4.20392564e-05,  5.44289858e-05, -5.46065561e-05],\n",
      "       [ 1.26047975e-07, -1.07202074e-03,  1.74328257e-04, ...,\n",
      "         1.11506368e-03,  1.62933092e-03, -2.09218698e-03]]), array([[-7.19936622e-07],\n",
      "       [-2.90605322e-02],\n",
      "       [ 4.85143866e-03],\n",
      "       [ 3.23899590e-02],\n",
      "       [ 1.16101738e-01],\n",
      "       [ 1.25652017e-06],\n",
      "       [ 4.15322812e-02],\n",
      "       [ 1.84785177e-02],\n",
      "       [ 2.80214117e-02],\n",
      "       [ 2.76078609e-02],\n",
      "       [ 5.79927914e-02],\n",
      "       [ 2.65027663e-02],\n",
      "       [-3.44527343e-07],\n",
      "       [ 4.09365636e-02],\n",
      "       [ 4.42046046e-02],\n",
      "       [ 5.24221564e-06],\n",
      "       [-2.61260317e-06],\n",
      "       [ 3.04730709e-02],\n",
      "       [ 7.48202912e-02],\n",
      "       [ 2.17960494e-08],\n",
      "       [-1.75027998e-01],\n",
      "       [-1.44274392e-02],\n",
      "       [-2.96662519e-06],\n",
      "       [ 3.21559277e-02],\n",
      "       [-2.23538906e-02],\n",
      "       [ 7.61623523e-02],\n",
      "       [-1.61889351e-03],\n",
      "       [-1.58584517e-01],\n",
      "       [ 3.34469781e-02],\n",
      "       [-5.75100936e-07],\n",
      "       [ 1.63664474e-02],\n",
      "       [-4.84772033e-02],\n",
      "       [ 2.64315652e-07],\n",
      "       [ 1.03158139e-01],\n",
      "       [ 1.90247989e-02],\n",
      "       [ 6.32478884e-02],\n",
      "       [ 1.60926872e-02],\n",
      "       [-3.77319246e-07],\n",
      "       [ 2.33168429e-01],\n",
      "       [ 1.57086598e-02],\n",
      "       [ 6.52141179e-07],\n",
      "       [ 2.61200662e-07],\n",
      "       [ 3.17150932e-02],\n",
      "       [ 4.02421227e-02],\n",
      "       [ 2.95988899e-03],\n",
      "       [-4.61345440e-04],\n",
      "       [-7.62776472e-03],\n",
      "       [ 4.50988511e-02],\n",
      "       [ 4.17985675e-02],\n",
      "       [-7.83515101e-03],\n",
      "       [-4.45347979e-07],\n",
      "       [-1.25080410e-02],\n",
      "       [-1.61215116e-02],\n",
      "       [-1.68987097e-06],\n",
      "       [-7.58042304e-07],\n",
      "       [ 3.63644688e-02],\n",
      "       [-6.38448234e-02],\n",
      "       [ 2.59564958e-02],\n",
      "       [-7.07344816e-03],\n",
      "       [ 3.51932871e-02],\n",
      "       [-3.63082644e-02],\n",
      "       [ 3.74962241e-02],\n",
      "       [-1.13297306e-02],\n",
      "       [ 3.10458922e-02],\n",
      "       [-1.00072627e-06],\n",
      "       [-6.84378936e-02],\n",
      "       [-7.07317125e-03],\n",
      "       [ 3.07921975e-02],\n",
      "       [ 4.54425701e-02],\n",
      "       [-5.73377574e-02]])]\n",
      "\n",
      "Biases:\n",
      " [array([-3.12563055e+00, -1.49232727e-01,  4.88613443e-01, -2.63232283e-02,\n",
      "       -2.83275550e-01,  4.09614772e+00, -1.31830928e+00, -1.71270559e+00,\n",
      "        8.48230674e-02,  1.97429625e+00,  3.10152747e+00,  3.92354806e+00,\n",
      "        3.97877353e+00,  6.33571533e-02, -4.74848121e-01, -6.29922934e-02,\n",
      "        1.49131390e+00,  5.84162354e+00,  1.63667935e+01, -1.66082530e+00,\n",
      "        8.08394552e+00,  1.56825319e+01, -1.16427310e+00, -2.80679099e-01,\n",
      "        3.04130198e+00, -1.36085195e+00, -4.22138191e-03, -4.57146214e-01,\n",
      "        1.14816168e+01,  4.28389420e+00, -6.50051963e-02,  2.70449780e+00,\n",
      "       -6.73074574e+00, -5.43860458e+00, -1.06110232e-01, -6.46361609e-02,\n",
      "        1.56093376e+00, -8.99602132e-02,  9.46443376e-01,  1.23779452e+00,\n",
      "       -3.66577655e-01,  4.05628736e-02, -9.90195060e-01, -1.73623249e+00,\n",
      "        6.11103176e-02,  2.84688512e+00,  3.20020799e+00,  2.70474512e-01,\n",
      "       -1.98917246e+00, -1.43328710e-01, -6.15278821e+00, -7.54543937e-01,\n",
      "       -2.11058191e+00,  1.90793014e+00, -1.06793663e+00,  8.63288740e-01,\n",
      "        1.91236955e+00,  1.19271966e+00,  9.21314573e+00, -1.12350800e+00,\n",
      "        3.26167024e+00, -1.46473747e+00,  3.11959469e-01,  1.00594727e-02,\n",
      "        3.79647413e-02, -1.99828607e-01,  3.81069027e-01, -1.22956901e+00,\n",
      "        3.18374859e-01,  2.84881311e+00]), array([-7.86919683e-02, -1.69862855e-01,  3.01491639e-01,  1.99025625e+00,\n",
      "        7.09533453e+00, -1.24267613e-01,  2.54446785e+00,  1.14647677e+00,\n",
      "        1.71862729e+00,  1.70172985e+00,  3.54414471e+00,  1.66371980e+00,\n",
      "       -1.35995581e-01,  2.51899653e+00,  2.72011815e+00, -6.46695303e-03,\n",
      "       -2.17922268e-01,  1.88907658e+00,  4.60286813e+00, -1.54726586e-01,\n",
      "        1.60251517e+01,  1.42546021e+00, -1.97909510e-01,  1.98653429e+00,\n",
      "        3.90076511e-01,  4.64709008e+00, -2.27853599e-02,  1.43841191e+01,\n",
      "        2.05836777e+00, -9.27828051e-02,  1.04935332e+00,  2.39060894e+00,\n",
      "       -1.75058138e-02,  6.29128901e+00,  1.16973511e+00,  3.85696944e+00,\n",
      "        9.86761948e-01, -1.86097063e-01,  1.43375773e+01,  9.68778135e-01,\n",
      "       -1.72162050e-01, -1.21705580e-01,  1.94987959e+00,  2.47581207e+00,\n",
      "        1.84287684e-01, -8.91019506e-03,  3.74154235e-01,  2.77768597e+00,\n",
      "        2.56041057e+00, -1.01736601e-01, -1.78841286e-01,  5.85660909e-01,\n",
      "        6.99151354e-01, -4.62296687e-02, -9.52776310e-02,  2.24727594e+00,\n",
      "        6.97844118e+00,  1.60111650e+00,  4.19674473e-01,  2.16466969e+00,\n",
      "        2.69812380e+00,  2.32148061e+00,  3.28781702e-01,  1.90415406e+00,\n",
      "       -2.98620039e-02,  1.92528463e+00,  3.62303777e-01,  1.88720402e+00,\n",
      "        2.80736019e+00,  4.16809153e+00]), array([31.38326526])]\n"
     ]
    }
   ],
   "source": [
    "# NOTE HIGHLY SHRINKED WEIGHTS DUE TO HIGH REGULARIZATION\n",
    "print(\"Activation function at Output layer: \", nnreg.out_activation_)\n",
    "print(\"Number of Layers: \", nnreg.n_layers_)\n",
    "print(\"Number of Outputs: \", nnreg.n_outputs_)\n",
    "print(\"Number of iterations for convergence: \", nnreg.n_iter_)\n",
    "print(\"\\nWeights matrix:\\n\", nnreg.coefs_)\n",
    "print(\"\\nBiases:\\n\", nnreg.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of Normalizing input value\n",
    "from sklearn.preprocessing import StandardScaler # for conversion to normal distribution\n",
    "# First fit it on training data and then, transform both train and test using that\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_sc = X_scaler.transform(X_train)\n",
    "X_test_sc = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.82316132 -0.62584351  0.20011909 -0.70870565  1.07038511  1.\n",
      "  -0.84515425 -0.9701425  -1.02105494]\n",
      " [ 0.53669245  0.58452568 -1.00537917  0.82095857 -0.00782282 -1.\n",
      "  -0.84515425 -0.9701425   0.14586499]\n",
      " [ 1.62143129  0.51161188 -0.98624427  0.89656935 -0.51742358 -1.\n",
      "  -0.84515425 -0.9701425  -0.43759497]\n",
      " [ 0.09301505 -0.50918141 -1.59856085  0.44872089  1.1830337   1.\n",
      "  -0.84515425 -0.9701425  -1.02105494]\n",
      " [-1.18474093 -1.07790911  0.92724502 -1.01696498  0.78071731  1.\n",
      "   1.18321596  0.48507125 -1.02105494]\n",
      " [-0.64237151 -0.65500903  0.62108673  0.08811564  2.62064427  1.\n",
      "  -0.84515425  0.48507125 -0.43759497]\n",
      " [ 0.75678439  2.84485368 -0.1060392   0.57667759 -1.83165713 -1.\n",
      "   1.18321596  1.940285    3.06316482]\n",
      " [-1.18212079 -1.07790911  0.92724502 -1.32522431  0.47495685  1.\n",
      "   1.18321596  0.48507125 -1.02105494]\n",
      " [ 1.18474093  1.53240517  0.25752377  0.89075314 -1.39715542 -1.\n",
      "  -0.84515425 -0.9701425   0.72932496]\n",
      " [-0.47468242 -0.43626761  0.58281695 -0.23177612 -0.53351624 -1.\n",
      "   1.18321596  0.48507125  0.72932496]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sc[:10]) # NOTE: normalized values most of which will be between +3 and -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5242"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnreg = MLPRegressor(solver=\"sgd\",\n",
    "                     activation=\"relu\",\n",
    "                     hidden_layer_sizes=(70, 70),\n",
    "                     learning_rate=\"constant\",\n",
    "                     learning_rate_init=0.00001,\n",
    "                     max_iter=6000,\n",
    "                     random_state=0\n",
    "                    )\n",
    "nnreg.fit(X_train_sc, y_train)\n",
    "nnreg.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTCars Data Set\n",
      "R2 of NN Regressor on training set: 0.928\n",
      "R2 of NN Regressor on test set: 0.754\n",
      "MSE: 5.171\n",
      "R-square: 0.754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5242"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MTCars Data Set\")\n",
    "print(\"R2 of NN Regressor on training set: {:.3f}\".format(nnreg.score(X_train_sc, y_train)))\n",
    "print(\"R2 of NN Regressor on test set: {:.3f}\".format(nnreg.score(X_test_sc, y_test)))\n",
    "print(\"MSE: {:.3f}\".format(mean_squared_error(y_test, nnreg.predict(X_test_sc))))\n",
    "print(\"R-square: {:.3f}\".format(r2_score(y_test, nnreg.predict(X_test_sc))))\n",
    "nnreg.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Total number of models in Grid = 3* 3 * 5 * 3 = 135 models\n",
    "# Each of these 135 models will be trained and tested k times in k-folds\n",
    "# So, total iterations will be 135 * k\n",
    "\n",
    "solv = [\"lbfgs\", \"adam\", \"sgd\"]\n",
    "act = [\"logistic\", \"relu\", \"tanh\"]#, \"identity\"]\n",
    "lr_init = [0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "hidden_layer_sz = [(7), (7, 7), (7, 7, 7)]\n",
    "\n",
    "# We are preparing grid for solver, activation, learning_rate_init and hidden_layer_sizes only\n",
    "# Rest all things we need to specify while defining the estimator in GridSearchCV\n",
    "param_grid = {\"solver\":solv,\n",
    "              \"activation\":act,\n",
    "              \"learning_rate_init\": lr_init,\n",
    "              \"hidden_layer_sizes\": hidden_layer_sz\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have prepared the grid for solver, activation, learning_rate_init and hidden_layer_sizes only\n",
    "# Rest all things we are specifying while defining the estimator(MLPRegressor) in GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    MLPRegressor(learning_rate=\"constant\",\n",
    "                 max_iter=8000,\n",
    "                 random_state=0\n",
    "                ),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    scoring=[\"neg_mean_squared_error\", \"r2\"], # metric for evaluating while validation in each cv iteration on cv_test sets\n",
    "    refit=\"r2\"  # Fit the model on whole training dataset with params of cv iteration where best r-square score was there\n",
    "#    Scoring and refit we could have used for classification problem: \n",
    "#     scoring=[\"precision\", \"recall\", \"f1\", \"auc\"],\n",
    "#     refit=\"f1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_models = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       " 'r2': make_scorer(r2_score)}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring parameters\n",
    "grid_models.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'hidden_layer_sizes': 7,\n",
       " 'learning_rate_init': 0.1,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "grid_models.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=7, learning_rate='constant',\n",
       "             learning_rate_init=0.1, max_fun=15000, max_iter=8000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=0, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best estimator\n",
    "grid_models.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872762187459511"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean cross-validated score of the best_estimator\n",
    "# For multi-metric evaluation, this is present only if refit is specified.\n",
    "# This attribute is not available if refit is a function.\n",
    "# Here it is: mean test r2(mean of r2s of all folds)\n",
    "grid_models.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406414936836227"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring on training data\n",
    "# Returns the score on the given data, if the estimator has been refit.\n",
    "grid_models.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2716990824404726"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring on test data\n",
    "grid_models.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 31)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for all the models imported into dataframe\n",
    "cv_results = pd.DataFrame(grid_models.cv_results_)\n",
    "cv_results.shape # (135, 31)--135: one row for each model; 31: internally evaluated values, metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_train_r2</th>\n",
       "      <th>split1_train_r2</th>\n",
       "      <th>split2_train_r2</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>logistic</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-32.059644</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759096e-02</td>\n",
       "      <td>-0.077878</td>\n",
       "      <td>-0.036539</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>80</td>\n",
       "      <td>-1.300429e-07</td>\n",
       "      <td>-1.950328e-08</td>\n",
       "      <td>-7.915540e-09</td>\n",
       "      <td>-5.248725e-08</td>\n",
       "      <td>5.504381e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086436</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>logistic</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>-31.660795</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.940798e-07</td>\n",
       "      <td>-0.183036</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>97</td>\n",
       "      <td>-2.023084e-02</td>\n",
       "      <td>-2.524962e-02</td>\n",
       "      <td>-1.801163e-02</td>\n",
       "      <td>-2.116403e-02</td>\n",
       "      <td>3.027680e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.023555      0.006312         0.006240        0.001991   \n",
       "1       0.086436      0.029817         0.003503        0.001850   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0         logistic                        7                      0.1   \n",
       "1         logistic                        7                      0.1   \n",
       "\n",
       "  param_solver                                             params  \\\n",
       "0        lbfgs  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "1         adam  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "\n",
       "   split0_test_neg_mean_squared_error  ...  split1_test_r2  split2_test_r2  \\\n",
       "0                          -32.059644  ...   -1.759096e-02       -0.077878   \n",
       "1                          -31.660795  ...   -6.940798e-07       -0.183036   \n",
       "\n",
       "   mean_test_r2  std_test_r2  rank_test_r2  split0_train_r2  split1_train_r2  \\\n",
       "0     -0.036539     0.029264            80    -1.300429e-07    -1.950328e-08   \n",
       "1     -0.061523     0.085925            97    -2.023084e-02    -2.524962e-02   \n",
       "\n",
       "   split2_train_r2  mean_train_r2  std_train_r2  \n",
       "0    -7.915540e-09  -5.248725e-08  5.504381e-08  \n",
       "1    -1.801163e-02  -2.116403e-02  3.027680e-03  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_activation', 'param_hidden_layer_sizes',\n",
       "       'param_learning_rate_init', 'param_solver', 'params',\n",
       "       'split0_test_neg_mean_squared_error',\n",
       "       'split1_test_neg_mean_squared_error',\n",
       "       'split2_test_neg_mean_squared_error',\n",
       "       'mean_test_neg_mean_squared_error', 'std_test_neg_mean_squared_error',\n",
       "       'rank_test_neg_mean_squared_error',\n",
       "       'split0_train_neg_mean_squared_error',\n",
       "       'split1_train_neg_mean_squared_error',\n",
       "       'split2_train_neg_mean_squared_error',\n",
       "       'mean_train_neg_mean_squared_error', 'std_train_neg_mean_squared_error',\n",
       "       'split0_test_r2', 'split1_test_r2', 'split2_test_r2', 'mean_test_r2',\n",
       "       'std_test_r2', 'rank_test_r2', 'split0_train_r2', 'split1_train_r2',\n",
       "       'split2_train_r2', 'mean_train_r2', 'std_train_r2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.columns\n",
    "# contains important columns like: \n",
    "# mean_test_neg_mean_squared_error\n",
    "# mean_train_neg_mean_squared_error\n",
    "# mean_test_r2 -- our refit metric we specified\n",
    "# mean_train_r2 -- our refit metric we specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_models.best_index_\n",
    "# Tells us which row is the set of hyperparameters we are looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                                                   0.258959\n",
       "std_fit_time                                                                    0.129264\n",
       "mean_score_time                                                                0.0027109\n",
       "std_score_time                                                                 0.0019169\n",
       "param_activation                                                                    relu\n",
       "param_hidden_layer_sizes                                                               7\n",
       "param_learning_rate_init                                                             0.1\n",
       "param_solver                                                                       lbfgs\n",
       "params                                 {'activation': 'relu', 'hidden_layer_sizes': 7...\n",
       "split0_test_neg_mean_squared_error                                              -9.98572\n",
       "split1_test_neg_mean_squared_error                                              -7.60114\n",
       "split2_test_neg_mean_squared_error                                              -4.85687\n",
       "mean_test_neg_mean_squared_error                                                -7.48125\n",
       "std_test_neg_mean_squared_error                                                  2.09556\n",
       "rank_test_neg_mean_squared_error                                                       1\n",
       "split0_train_neg_mean_squared_error                                            -0.295724\n",
       "split1_train_neg_mean_squared_error                                              -1.8123\n",
       "split2_train_neg_mean_squared_error                                             -2.31303\n",
       "mean_train_neg_mean_squared_error                                               -1.47368\n",
       "std_train_neg_mean_squared_error                                                0.857662\n",
       "split0_test_r2                                                                  0.684119\n",
       "split1_test_r2                                                                  0.832633\n",
       "split2_test_r2                                                                  0.845076\n",
       "mean_test_r2                                                                    0.787276\n",
       "std_test_r2                                                                    0.0731195\n",
       "rank_test_r2                                                                           1\n",
       "split0_train_r2                                                                 0.992428\n",
       "split1_train_r2                                                                 0.943426\n",
       "split2_train_r2                                                                 0.939952\n",
       "mean_train_r2                                                                   0.958602\n",
       "std_train_r2                                                                   0.0239603\n",
       "Name: 45, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.loc[grid_models.best_index_,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the best model in data frame 45\n",
      "\n",
      "Best result of scoring parameters\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean_train_neg_mean_squared_error   -1.47368\n",
       "mean_test_neg_mean_squared_error    -7.48125\n",
       "Name: 45, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mean_train_r2    0.958602\n",
       "mean_test_r2     0.787276\n",
       "Name: 45, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: Test result is on cross validation test rows\n"
     ]
    }
   ],
   "source": [
    "# Best results of scoring parameters\n",
    "print(\"Index of the best model in data frame\", grid_models.best_index_)\n",
    "print(\"\\nBest result of scoring parameters\\n\")\n",
    "# Note: The mean squared error we are printing here is in negatives\n",
    "#       bcoz it is mean of \"neg_mean_squared_error\" for all splits in one model\n",
    "display(cv_results.loc[grid_models.best_index_, [\"mean_train_neg_mean_squared_error\", \"mean_test_neg_mean_squared_error\"]])\n",
    "display(cv_results.loc[grid_models.best_index_, [\"mean_train_r2\", \"mean_test_r2\"]])\n",
    "print(\"\\nNote: Test result is on cross validation test rows\") # We have not used test-data till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.34946705, 20.84060623, 26.96461804, 20.73011831, 18.47717302,\n",
       "       19.03385681, 14.38421352, 22.34521078, 23.94715686, 18.53838783,\n",
       "       18.87333782, 13.4535887 , 14.66054645, 14.72277177, 12.72599627,\n",
       "       11.80027882, 11.63238393, 29.77176693, 32.12241798, 31.78337639,\n",
       "       21.81134188, 16.74005556, 17.74725734, 14.12927304, 17.95338961,\n",
       "       30.17800082, 28.48378045, 29.89764245, 24.02655125, 19.1610249 ,\n",
       "       14.9857022 , 24.32073741])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_models.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/291552/why-do-we-sample-from-log-space-when-optimizing-learning-rate-regularization-p\n",
    "\n",
    "Hyperparameters such as learning rate and regularization term tend to be very small positive numbers. When we sample them, we would like to sample values from all the orders of magnitude in a given interval.\n",
    "\n",
    "Take the learning rate as an example. Let's say we decide to sample uniformly from 0 to 1, then only about 10% of the values would come from 0 to 0.1, and 90% of the values would come from 0.1 to 1. This does not seem to be appropriate because we would definitely like to sample values in the order of 102, 103, 104, 105,etc and all of these values fall under the first group that has only 10% chance of being selected.\n",
    "\n",
    "Instead, if we used a logarithmic scale to sample the values such as from -5 to 0, then values from 104, 103, 102, 101, 100 all have equal chance of being selected.\n",
    "\n",
    "If what I've said does not make much sense, I would recommend watching https://www.youtube.com/watch?v=cSoK_6Rkbfg&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=25 .\n",
    "\n",
    "\n",
    "I think the contention here is that it is not outright wrong to search our hyperparameters in linear scale but it is inefficient to do so as compared to using the log scale, especially in the initial phase of our search when we want to sample from a wider range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate `n` random learning rates between `low` and `high` but, not on linear scale, instead on logarithmic-10 scale\n",
    "def learning_rate_fn(n, low, high):                 # Example: learning_rate_fn(25, 0.001, 0.1)\n",
    "#     print(np.log10(low))\n",
    "#     print(np.log10(high))\n",
    "#     print(np.log10(high) - np.log10(low))\n",
    "#     print((np.log10(high) - np.log10(low))*np.random.sample(n))\n",
    "#     print(np.log10(low)+(np.log10(high) - np.log10(low))*np.random.sample(n))\n",
    "    low_log10 = np.log10(low)                       # -3\n",
    "    high_log10 = np.log10(high)                     # -1\n",
    "    range_log10 = high_log10-low_log10              # 2\n",
    "    rands = np.random.sample(n)                     # array of 25 floats between half-open interval [0 to 1)\n",
    "    rands_log10 = rands*range_log10                 # array of 25 floats between half-open interval [0 to 2)\n",
    "    rands_log10 = rands_log10 + low_log10           # array of 25 floats between half-open interval [-3 to -1)\n",
    "    return 10**rands_log10                          # array of 25 floats between half-open interval [0.001 to 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_instance: number of hidden_layer instances in param_dist\n",
    "# n_layers: number of layers in all the hidden_layer instances in param-grid\n",
    "# low: the minimum number of neurons in any layer\n",
    "# high: the maximum number of neurons in any layer\n",
    "def hidden_layer_fn(n_instance, n_layers, low, high):\n",
    "    hid_layer_list = []                             # this is not list of hidden_layers, it is list of HL specifications for param-grid\n",
    "    for i in range(n_instance):\n",
    "        hid_layer = []                              # this is the list of hidden_layers\n",
    "        for j in range(n_layers):\n",
    "            hid_layer.append(np.random.randint(low, high))\n",
    "        hid_layer_list.append(hid_layer)\n",
    "    return hid_layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "solv = [\"lbfgs\", \"adam\", \"sgd\"]\n",
    "act = [\"logistic\", \"tanh\", \"relu\"]\n",
    "lr_init = learning_rate_fn(25, 0.0001, 0.1)\n",
    "lr_init = learning_rate_fn(15, 0.0001, 0.001) # Going coarse to finer\n",
    "\n",
    "# Total 12 hidden-layer-sizes in list for param-grid\n",
    "hidden_layer_sz = hidden_layer_fn(5, 1, 3, 10) + hidden_layer_fn(4, 2, 3, 10) + hidden_layer_fn(3, 3, 3, 10)\n",
    "hidden_layer_sz = hidden_layer_fn(5, 1, 3, 10) + hidden_layer_fn(5, 2, 3, 10) # Going Coarse to finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"solver\":solv,\n",
    "              \"activation\": act,\n",
    "              \"learning_rate_init\": lr_init,\n",
    "              \"hidden_layer_sizes\": hidden_layer_sz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00025734, 0.00025577, 0.00017343, 0.00016651, 0.00038383,\n",
       "       0.00019344, 0.00068535, 0.00075448, 0.00032931, 0.00077288,\n",
       "       0.00040148, 0.00084021, 0.00011297, 0.00052402, 0.00011753])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9], [3], [6], [3], [3], [6, 9], [5, 9], [9, 8], [6, 6], [5, 9]]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter: The number of parameter settings that are tried. Number of parameter settings that are sampled.\n",
    "random_search = RandomizedSearchCV(\n",
    "    MLPRegressor(learning_rate=\"constant\",\n",
    "                 max_iter=8000,\n",
    "                 alpha=0.01, # Regularization-parameter\n",
    "                 random_state=0),\n",
    "    param_distributions=param_dist,\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    scoring=[\"neg_mean_squared_error\", \"r2\"],\n",
    "    n_iter=30,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "random_models = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 31)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for all the models, imported into Dataframe\n",
    "cv_results = pd.DataFrame(random_models.cv_results_)\n",
    "cv_results.shape  # (30, 31) -- 30 random models created as we specified n_iter=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_train_r2</th>\n",
       "      <th>split1_train_r2</th>\n",
       "      <th>split2_train_r2</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000772877</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0007...</td>\n",
       "      <td>-515.061074</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.831260</td>\n",
       "      <td>-12.162398</td>\n",
       "      <td>-12.762232</td>\n",
       "      <td>1.870243</td>\n",
       "      <td>29</td>\n",
       "      <td>-11.637597</td>\n",
       "      <td>-14.143172</td>\n",
       "      <td>-1.154609e+01</td>\n",
       "      <td>-12.442285</td>\n",
       "      <td>1.203289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.046871</td>\n",
       "      <td>1.992581</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00025577</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-32.468003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.116522</td>\n",
       "      <td>0.297023</td>\n",
       "      <td>0.361584</td>\n",
       "      <td>9</td>\n",
       "      <td>0.992567</td>\n",
       "      <td>0.996456</td>\n",
       "      <td>6.742117e-01</td>\n",
       "      <td>0.887745</td>\n",
       "      <td>0.150999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.892289</td>\n",
       "      <td>1.608697</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000257344</td>\n",
       "      <td>[3]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-23.954062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700485</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.330649</td>\n",
       "      <td>0.273132</td>\n",
       "      <td>7</td>\n",
       "      <td>0.823941</td>\n",
       "      <td>0.949030</td>\n",
       "      <td>9.998946e-01</td>\n",
       "      <td>0.924289</td>\n",
       "      <td>0.073933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045345</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00084021</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0008...</td>\n",
       "      <td>-32.212407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006491</td>\n",
       "      <td>-0.300964</td>\n",
       "      <td>-0.108812</td>\n",
       "      <td>0.135967</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.053347</td>\n",
       "      <td>-0.064435</td>\n",
       "      <td>-5.912860e-02</td>\n",
       "      <td>-0.058970</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.625414</td>\n",
       "      <td>1.015832</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000257344</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-11.954588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871850</td>\n",
       "      <td>0.838867</td>\n",
       "      <td>0.777519</td>\n",
       "      <td>0.110903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951081</td>\n",
       "      <td>0.926497</td>\n",
       "      <td>9.222546e-01</td>\n",
       "      <td>0.933278</td>\n",
       "      <td>0.012707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.438567</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000117531</td>\n",
       "      <td>[9]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0001...</td>\n",
       "      <td>-32.213930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022094</td>\n",
       "      <td>-0.067675</td>\n",
       "      <td>-0.036266</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-3.094993e-04</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.010959</td>\n",
       "      <td>0.189581</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000173432</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-80.906797</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135121</td>\n",
       "      <td>-0.947175</td>\n",
       "      <td>-1.213879</td>\n",
       "      <td>0.256046</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.033229</td>\n",
       "      <td>-1.233590</td>\n",
       "      <td>-1.276333e+00</td>\n",
       "      <td>-1.181051</td>\n",
       "      <td>0.105972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.661617</td>\n",
       "      <td>1.284983</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000383831</td>\n",
       "      <td>[9, 8]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-43.707759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259062</td>\n",
       "      <td>0.409418</td>\n",
       "      <td>0.095288</td>\n",
       "      <td>0.343459</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.998533</td>\n",
       "      <td>9.997736e-01</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000112967</td>\n",
       "      <td>[9, 8]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0001...</td>\n",
       "      <td>-65.761146</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.304454</td>\n",
       "      <td>-0.090147</td>\n",
       "      <td>-3.158279</td>\n",
       "      <td>3.661275</td>\n",
       "      <td>23</td>\n",
       "      <td>-1.086000</td>\n",
       "      <td>-10.714769</td>\n",
       "      <td>-2.731305e-01</td>\n",
       "      <td>-4.024633</td>\n",
       "      <td>4.742266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.574791</td>\n",
       "      <td>1.218941</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000772877</td>\n",
       "      <td>[9, 8]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-43.707759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259062</td>\n",
       "      <td>0.409418</td>\n",
       "      <td>0.095288</td>\n",
       "      <td>0.343459</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.998533</td>\n",
       "      <td>9.997736e-01</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.137507</td>\n",
       "      <td>0.660213</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000112967</td>\n",
       "      <td>[6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-9.081424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668863</td>\n",
       "      <td>0.265392</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.201335</td>\n",
       "      <td>4</td>\n",
       "      <td>0.860783</td>\n",
       "      <td>0.950238</td>\n",
       "      <td>9.990085e-01</td>\n",
       "      <td>0.936677</td>\n",
       "      <td>0.057239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.347542</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000112967</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0001...</td>\n",
       "      <td>-32.169071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020758</td>\n",
       "      <td>-0.070334</td>\n",
       "      <td>-0.036234</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-1.562563e-04</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015925</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000685352</td>\n",
       "      <td>[9, 8]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0006...</td>\n",
       "      <td>-1378.337374</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.979612</td>\n",
       "      <td>-312.539184</td>\n",
       "      <td>-130.706678</td>\n",
       "      <td>128.595479</td>\n",
       "      <td>30</td>\n",
       "      <td>-33.238823</td>\n",
       "      <td>-50.165366</td>\n",
       "      <td>-2.624589e+02</td>\n",
       "      <td>-115.287682</td>\n",
       "      <td>104.294911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.213954</td>\n",
       "      <td>1.126209</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000754484</td>\n",
       "      <td>[6]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-13.240060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>-0.661880</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.538954</td>\n",
       "      <td>12</td>\n",
       "      <td>0.991825</td>\n",
       "      <td>0.994616</td>\n",
       "      <td>9.953034e-01</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.303102</td>\n",
       "      <td>0.040352</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000383831</td>\n",
       "      <td>[6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-39.772608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142061</td>\n",
       "      <td>-0.014857</td>\n",
       "      <td>-0.138351</td>\n",
       "      <td>0.099353</td>\n",
       "      <td>21</td>\n",
       "      <td>0.096182</td>\n",
       "      <td>-0.084592</td>\n",
       "      <td>-1.308332e-01</td>\n",
       "      <td>-0.039748</td>\n",
       "      <td>0.097953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.201844</td>\n",
       "      <td>0.067403</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000112967</td>\n",
       "      <td>[3]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-398.847921</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.213173</td>\n",
       "      <td>-9.965355</td>\n",
       "      <td>-9.931790</td>\n",
       "      <td>1.389744</td>\n",
       "      <td>28</td>\n",
       "      <td>-8.758564</td>\n",
       "      <td>-10.591303</td>\n",
       "      <td>-9.607799e+00</td>\n",
       "      <td>-9.652555</td>\n",
       "      <td>0.748882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.188770</td>\n",
       "      <td>0.146691</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000401484</td>\n",
       "      <td>[3]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-249.542907</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.897208</td>\n",
       "      <td>-5.613200</td>\n",
       "      <td>-5.801417</td>\n",
       "      <td>0.825917</td>\n",
       "      <td>24</td>\n",
       "      <td>-5.086189</td>\n",
       "      <td>-6.135691</td>\n",
       "      <td>-5.707968e+00</td>\n",
       "      <td>-5.643283</td>\n",
       "      <td>0.430892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000754484</td>\n",
       "      <td>[3]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0007...</td>\n",
       "      <td>-297.267148</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.302730</td>\n",
       "      <td>-9.192118</td>\n",
       "      <td>-7.966121</td>\n",
       "      <td>1.219460</td>\n",
       "      <td>26</td>\n",
       "      <td>-6.255595</td>\n",
       "      <td>-8.016456</td>\n",
       "      <td>-8.921719e+00</td>\n",
       "      <td>-7.731256</td>\n",
       "      <td>1.106966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.117807</td>\n",
       "      <td>0.672713</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000685352</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-12.561251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188824</td>\n",
       "      <td>-0.374425</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.423680</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.983672</td>\n",
       "      <td>9.966290e-01</td>\n",
       "      <td>0.993421</td>\n",
       "      <td>0.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.022453</td>\n",
       "      <td>0.636801</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00084021</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-11.802957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853626</td>\n",
       "      <td>0.789465</td>\n",
       "      <td>0.756575</td>\n",
       "      <td>0.095543</td>\n",
       "      <td>2</td>\n",
       "      <td>0.960391</td>\n",
       "      <td>0.925449</td>\n",
       "      <td>9.300108e-01</td>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.015509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.292287</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000257344</td>\n",
       "      <td>[3]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>-32.179286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021083</td>\n",
       "      <td>-0.069701</td>\n",
       "      <td>-0.036240</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-1.923632e-04</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.899040</td>\n",
       "      <td>1.196604</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000772877</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-11.091664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811854</td>\n",
       "      <td>0.342392</td>\n",
       "      <td>0.601127</td>\n",
       "      <td>0.194640</td>\n",
       "      <td>3</td>\n",
       "      <td>0.990271</td>\n",
       "      <td>0.889923</td>\n",
       "      <td>9.764421e-01</td>\n",
       "      <td>0.952212</td>\n",
       "      <td>0.044405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.270129</td>\n",
       "      <td>0.136958</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000401484</td>\n",
       "      <td>[3]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-249.542907</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.897208</td>\n",
       "      <td>-5.613200</td>\n",
       "      <td>-5.801417</td>\n",
       "      <td>0.825917</td>\n",
       "      <td>24</td>\n",
       "      <td>-5.086189</td>\n",
       "      <td>-6.135691</td>\n",
       "      <td>-5.707968e+00</td>\n",
       "      <td>-5.643283</td>\n",
       "      <td>0.430892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000117531</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0001...</td>\n",
       "      <td>-393.095617</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.318127</td>\n",
       "      <td>-8.031082</td>\n",
       "      <td>-9.261362</td>\n",
       "      <td>1.541368</td>\n",
       "      <td>27</td>\n",
       "      <td>-8.616433</td>\n",
       "      <td>-10.733262</td>\n",
       "      <td>-7.886882e+00</td>\n",
       "      <td>-9.078859</td>\n",
       "      <td>1.207158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.200244</td>\n",
       "      <td>0.661136</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000401484</td>\n",
       "      <td>[6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-9.081424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668863</td>\n",
       "      <td>0.265392</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.201335</td>\n",
       "      <td>4</td>\n",
       "      <td>0.860783</td>\n",
       "      <td>0.950238</td>\n",
       "      <td>9.990085e-01</td>\n",
       "      <td>0.936677</td>\n",
       "      <td>0.057239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.093934</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000401484</td>\n",
       "      <td>[9, 8]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0004...</td>\n",
       "      <td>-32.026765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.077422</td>\n",
       "      <td>-0.035726</td>\n",
       "      <td>0.029518</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-5.407730e-07</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.695707</td>\n",
       "      <td>0.235055</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000166506</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-25.177949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543266</td>\n",
       "      <td>-0.673609</td>\n",
       "      <td>0.024399</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>9.966022e-01</td>\n",
       "      <td>0.998636</td>\n",
       "      <td>0.001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.531426</td>\n",
       "      <td>0.076818</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000685352</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>-32.376014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026565</td>\n",
       "      <td>-0.058737</td>\n",
       "      <td>-0.036487</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>-1.096819e-03</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.747314</td>\n",
       "      <td>1.516382</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000166506</td>\n",
       "      <td>[3]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-23.954062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700485</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.330649</td>\n",
       "      <td>0.273132</td>\n",
       "      <td>7</td>\n",
       "      <td>0.823941</td>\n",
       "      <td>0.949030</td>\n",
       "      <td>9.998946e-01</td>\n",
       "      <td>0.924289</td>\n",
       "      <td>0.073933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.955725</td>\n",
       "      <td>2.093065</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000401484</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>-25.816631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.121244</td>\n",
       "      <td>0.362685</td>\n",
       "      <td>0.298620</td>\n",
       "      <td>6</td>\n",
       "      <td>0.487238</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>9.982253e-01</td>\n",
       "      <td>0.828483</td>\n",
       "      <td>0.241297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_solver  \\\n",
       "0        0.011081      0.001990         0.004040        0.000802          sgd   \n",
       "1        3.046871      1.992581         0.003018        0.001427        lbfgs   \n",
       "2        1.892289      1.608697         0.005499        0.001105        lbfgs   \n",
       "3        0.045345      0.000690         0.003787        0.000404          sgd   \n",
       "4        7.625414      1.015832         0.003426        0.002712         adam   \n",
       "5        0.438567      0.020867         0.005320        0.000993          sgd   \n",
       "6        7.010959      0.189581         0.002064        0.002253         adam   \n",
       "7        4.661617      1.284983         0.004317        0.000332        lbfgs   \n",
       "8        0.015285      0.002108         0.001676        0.001714          sgd   \n",
       "9        4.574791      1.218941         0.003990        0.000016        lbfgs   \n",
       "10       1.137507      0.660213         0.003353        0.000961        lbfgs   \n",
       "11       0.347542      0.005629         0.004002        0.000340          sgd   \n",
       "12       0.015925      0.001342         0.002433        0.001752          sgd   \n",
       "13       3.213954      1.126209         0.003318        0.000875        lbfgs   \n",
       "14       5.303102      0.040352         0.001335        0.001888         adam   \n",
       "15       5.201844      0.067403         0.005083        0.001491         adam   \n",
       "16       5.188770      0.146691         0.005879        0.002569         adam   \n",
       "17       0.013692      0.002944         0.002175        0.001653          sgd   \n",
       "18       5.117807      0.672713         0.004654        0.001348        lbfgs   \n",
       "19       4.022453      0.636801         0.003057        0.002204         adam   \n",
       "20       0.292287      0.029203         0.002177        0.001842          sgd   \n",
       "21       3.899040      1.196604         0.004194        0.000272         adam   \n",
       "22       5.270129      0.136958         0.003466        0.001805         adam   \n",
       "23       0.016308      0.002994         0.002997        0.000833          sgd   \n",
       "24       1.200244      0.661136         0.002706        0.001914        lbfgs   \n",
       "25       0.093934      0.004155         0.003350        0.000962          sgd   \n",
       "26       5.695707      0.235055         0.001763        0.002493        lbfgs   \n",
       "27       4.531426      0.076818         0.004699        0.000977         adam   \n",
       "28       1.747314      1.516382         0.001663        0.001697        lbfgs   \n",
       "29       2.955725      2.093065         0.001690        0.001734        lbfgs   \n",
       "\n",
       "   param_learning_rate_init param_hidden_layer_sizes param_activation  \\\n",
       "0               0.000772877                   [6, 6]             relu   \n",
       "1                0.00025577                   [5, 9]             tanh   \n",
       "2               0.000257344                      [3]             tanh   \n",
       "3                0.00084021                   [5, 9]             tanh   \n",
       "4               0.000257344                   [6, 6]             relu   \n",
       "5               0.000117531                      [9]         logistic   \n",
       "6               0.000173432                   [5, 9]             tanh   \n",
       "7               0.000383831                   [9, 8]             tanh   \n",
       "8               0.000112967                   [9, 8]             relu   \n",
       "9               0.000772877                   [9, 8]             tanh   \n",
       "10              0.000112967                      [6]             tanh   \n",
       "11              0.000112967                   [6, 9]             tanh   \n",
       "12              0.000685352                   [9, 8]             relu   \n",
       "13              0.000754484                      [6]         logistic   \n",
       "14              0.000383831                      [6]             tanh   \n",
       "15              0.000112967                      [3]         logistic   \n",
       "16              0.000401484                      [3]         logistic   \n",
       "17              0.000754484                      [3]             relu   \n",
       "18              0.000685352                   [6, 9]         logistic   \n",
       "19               0.00084021                   [6, 6]             relu   \n",
       "20              0.000257344                      [3]         logistic   \n",
       "21              0.000772877                   [6, 9]             relu   \n",
       "22              0.000401484                      [3]         logistic   \n",
       "23              0.000117531                   [6, 9]             relu   \n",
       "24              0.000401484                      [6]             tanh   \n",
       "25              0.000401484                   [9, 8]             tanh   \n",
       "26              0.000166506                   [5, 9]         logistic   \n",
       "27              0.000685352                   [6, 9]         logistic   \n",
       "28              0.000166506                      [3]             tanh   \n",
       "29              0.000401484                   [6, 6]             tanh   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'solver': 'sgd', 'learning_rate_init': 0.0007...   \n",
       "1   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "2   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "3   {'solver': 'sgd', 'learning_rate_init': 0.0008...   \n",
       "4   {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "5   {'solver': 'sgd', 'learning_rate_init': 0.0001...   \n",
       "6   {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "7   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "8   {'solver': 'sgd', 'learning_rate_init': 0.0001...   \n",
       "9   {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "10  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "11  {'solver': 'sgd', 'learning_rate_init': 0.0001...   \n",
       "12  {'solver': 'sgd', 'learning_rate_init': 0.0006...   \n",
       "13  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "14  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "15  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "16  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "17  {'solver': 'sgd', 'learning_rate_init': 0.0007...   \n",
       "18  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "19  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "20  {'solver': 'sgd', 'learning_rate_init': 0.0002...   \n",
       "21  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "22  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "23  {'solver': 'sgd', 'learning_rate_init': 0.0001...   \n",
       "24  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "25  {'solver': 'sgd', 'learning_rate_init': 0.0004...   \n",
       "26  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "27  {'solver': 'adam', 'learning_rate_init': 0.000...   \n",
       "28  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "29  {'solver': 'lbfgs', 'learning_rate_init': 0.00...   \n",
       "\n",
       "    split0_test_neg_mean_squared_error  ...  split1_test_r2  split2_test_r2  \\\n",
       "0                          -515.061074  ...      -10.831260      -12.162398   \n",
       "1                           -32.468003  ...        0.801615        0.116522   \n",
       "2                           -23.954062  ...        0.700485        0.049205   \n",
       "3                           -32.212407  ...       -0.006491       -0.300964   \n",
       "4                           -11.954588  ...        0.871850        0.838867   \n",
       "5                           -32.213930  ...       -0.022094       -0.067675   \n",
       "6                           -80.906797  ...       -1.135121       -0.947175   \n",
       "7                           -43.707759  ...        0.259062        0.409418   \n",
       "8                           -65.761146  ...       -8.304454       -0.090147   \n",
       "9                           -43.707759  ...        0.259062        0.409418   \n",
       "10                           -9.081424  ...        0.668863        0.265392   \n",
       "11                          -32.169071  ...       -0.020758       -0.070334   \n",
       "12                        -1378.337374  ...      -36.979612     -312.539184   \n",
       "13                          -13.240060  ...        0.344654       -0.661880   \n",
       "14                          -39.772608  ...       -0.142061       -0.014857   \n",
       "15                         -398.847921  ...       -8.213173       -9.965355   \n",
       "16                         -249.542907  ...       -4.897208       -5.613200   \n",
       "17                         -297.267148  ...       -6.302730       -9.192118   \n",
       "18                          -12.561251  ...       -0.188824       -0.374425   \n",
       "19                          -11.802957  ...        0.853626        0.789465   \n",
       "20                          -32.179286  ...       -0.021083       -0.069701   \n",
       "21                          -11.091664  ...        0.811854        0.342392   \n",
       "22                         -249.542907  ...       -4.897208       -5.613200   \n",
       "23                         -393.095617  ...       -8.318127       -8.031082   \n",
       "24                           -9.081424  ...        0.668863        0.265392   \n",
       "25                          -32.026765  ...       -0.016647       -0.077422   \n",
       "26                          -25.177949  ...        0.543266       -0.673609   \n",
       "27                          -32.376014  ...       -0.026565       -0.058737   \n",
       "28                          -23.954062  ...        0.700485        0.049205   \n",
       "29                          -25.816631  ...        0.783473        0.121244   \n",
       "\n",
       "    mean_test_r2  std_test_r2  rank_test_r2  split0_train_r2  split1_train_r2  \\\n",
       "0     -12.762232     1.870243            29       -11.637597       -14.143172   \n",
       "1       0.297023     0.361584             9         0.992567         0.996456   \n",
       "2       0.330649     0.273132             7         0.823941         0.949030   \n",
       "3      -0.108812     0.135967            20        -0.053347        -0.064435   \n",
       "4       0.777519     0.110903             1         0.951081         0.926497   \n",
       "5      -0.036266     0.022245            18        -0.000304        -0.000368   \n",
       "6      -1.213879     0.256046            22        -1.033229        -1.233590   \n",
       "7       0.095288     0.343459            10         0.999186         0.998533   \n",
       "8      -3.158279     3.661275            23        -1.086000       -10.714769   \n",
       "9       0.095288     0.343459            10         0.999186         0.998533   \n",
       "10      0.548993     0.201335             4         0.860783         0.950238   \n",
       "11     -0.036234     0.024147            16        -0.000153        -0.000186   \n",
       "12   -130.706678   128.595479            30       -33.238823       -50.165366   \n",
       "13      0.087983     0.538954            12         0.991825         0.994616   \n",
       "14     -0.138351     0.099353            21         0.096182        -0.084592   \n",
       "15     -9.931790     1.389744            28        -8.758564       -10.591303   \n",
       "16     -5.801417     0.825917            24        -5.086189        -6.135691   \n",
       "17     -7.966121     1.219460            26        -6.255595        -8.016456   \n",
       "18      0.013133     0.423680            14         0.999963         0.983672   \n",
       "19      0.756575     0.095543             2         0.960391         0.925449   \n",
       "20     -0.036240     0.023696            17        -0.000189        -0.000226   \n",
       "21      0.601127     0.194640             3         0.990271         0.889923   \n",
       "22     -5.801417     0.825917            24        -5.086189        -6.135691   \n",
       "23     -9.261362     1.541368            27        -8.616433       -10.733262   \n",
       "24      0.548993     0.201335             4         0.860783         0.950238   \n",
       "25     -0.035726     0.029518            15        -0.000016        -0.000018   \n",
       "26      0.024399     0.512683            13         0.999744         0.999561   \n",
       "27     -0.036487     0.015764            19        -0.001078        -0.001307   \n",
       "28      0.330649     0.273132             7         0.823941         0.949030   \n",
       "29      0.362685     0.298620             6         0.487238         0.999985   \n",
       "\n",
       "    split2_train_r2  mean_train_r2  std_train_r2  \n",
       "0     -1.154609e+01     -12.442285      1.203289  \n",
       "1      6.742117e-01       0.887745      0.150999  \n",
       "2      9.998946e-01       0.924289      0.073933  \n",
       "3     -5.912860e-02      -0.058970      0.004528  \n",
       "4      9.222546e-01       0.933278      0.012707  \n",
       "5     -3.094993e-04      -0.000327      0.000029  \n",
       "6     -1.276333e+00      -1.181051      0.105972  \n",
       "7      9.997736e-01       0.999164      0.000506  \n",
       "8     -2.731305e-01      -4.024633      4.742266  \n",
       "9      9.997736e-01       0.999164      0.000506  \n",
       "10     9.990085e-01       0.936677      0.057239  \n",
       "11    -1.562563e-04      -0.000165      0.000015  \n",
       "12    -2.624589e+02    -115.287682    104.294911  \n",
       "13     9.953034e-01       0.993915      0.001504  \n",
       "14    -1.308332e-01      -0.039748      0.097953  \n",
       "15    -9.607799e+00      -9.652555      0.748882  \n",
       "16    -5.707968e+00      -5.643283      0.430892  \n",
       "17    -8.921719e+00      -7.731256      1.106966  \n",
       "18     9.966290e-01       0.993421      0.007027  \n",
       "19     9.300108e-01       0.938617      0.015509  \n",
       "20    -1.923632e-04      -0.000203      0.000017  \n",
       "21     9.764421e-01       0.952212      0.044405  \n",
       "22    -5.707968e+00      -5.643283      0.430892  \n",
       "23    -7.886882e+00      -9.078859      1.207158  \n",
       "24     9.990085e-01       0.936677      0.057239  \n",
       "25    -5.407730e-07      -0.000012      0.000008  \n",
       "26     9.966022e-01       0.998636      0.001440  \n",
       "27    -1.096819e-03      -0.001161      0.000104  \n",
       "28     9.998946e-01       0.924289      0.073933  \n",
       "29     9.982253e-01       0.828483      0.241297  \n",
       "\n",
       "[30 rows x 31 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results  # Note: solver, activation, learning rate, hidden_layers are all taken randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       " 'r2': make_scorer(r2_score)}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_models.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_solver', 'param_learning_rate_init', 'param_hidden_layer_sizes',\n",
       "       'param_activation', 'params', 'split0_test_neg_mean_squared_error',\n",
       "       'split1_test_neg_mean_squared_error',\n",
       "       'split2_test_neg_mean_squared_error',\n",
       "       'mean_test_neg_mean_squared_error', 'std_test_neg_mean_squared_error',\n",
       "       'rank_test_neg_mean_squared_error',\n",
       "       'split0_train_neg_mean_squared_error',\n",
       "       'split1_train_neg_mean_squared_error',\n",
       "       'split2_train_neg_mean_squared_error',\n",
       "       'mean_train_neg_mean_squared_error', 'std_train_neg_mean_squared_error',\n",
       "       'split0_test_r2', 'split1_test_r2', 'split2_test_r2', 'mean_test_r2',\n",
       "       'std_test_r2', 'rank_test_r2', 'split0_train_r2', 'split1_train_r2',\n",
       "       'split2_train_r2', 'mean_train_r2', 'std_train_r2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contains important columns like: \n",
    "# mean_test_neg_mean_squared_error\n",
    "# mean_train_neg_mean_squared_error\n",
    "# mean_test_r2 -- our refit metric we specified\n",
    "# mean_train_r2 -- our refit metric we specified\n",
    "cv_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of best model in data frame:  4\n",
      "\n",
      "Best result of scoring parameters\n",
      "\n",
      "mean_train_neg_mean_squared_error   -2.41994\n",
      "mean_test_neg_mean_squared_error    -7.60872\n",
      "Name: 4, dtype: object\n",
      "mean_train_r2    0.933278\n",
      "mean_test_r2     0.777519\n",
      "Name: 4, dtype: object\n",
      "\n",
      "Note: Test result is pn cross validation test rows\n"
     ]
    }
   ],
   "source": [
    "# Best result of scoring parameters\n",
    "print(\"Index of best model in data frame: \", random_models.best_index_)\n",
    "print(\"\\nBest result of scoring parameters\\n\")\n",
    "# Note: The mean squared error we are printing here is in negatives\n",
    "#       bcoz it is mean of \"neg_mean_squared_error\" for all splits in one model\n",
    "print(cv_results.loc[random_models.best_index_, [\"mean_train_neg_mean_squared_error\", \"mean_test_neg_mean_squared_error\"]])\n",
    "print(cv_results.loc[random_models.best_index_, [\"mean_train_r2\", \"mean_test_r2\"]])\n",
    "print(\"\\nNote: Test result is pn cross validation test rows\") # We have not used test-data till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'adam',\n",
       " 'learning_rate_init': 0.00025734448471926923,\n",
       " 'hidden_layer_sizes': [6, 6],\n",
       " 'activation': 'relu'}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_models.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=[6, 6], learning_rate='constant',\n",
       "             learning_rate_init=0.00025734448471926923, max_fun=15000,\n",
       "             max_iter=8000, momentum=0.9, n_iter_no_change=10,\n",
       "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_models.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7775185091819837"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9149192886365252\n",
      "0.9149192886365252\n"
     ]
    }
   ],
   "source": [
    "print(random_models.score(X_train, y_train))\n",
    "print(random_search.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19553085539969295"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will see Keras.. Here, we don't have Dropout layers, Batch-Normalizations, etc. So, we will see Keras in next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOME-WORK -- try to plot alpha vs learning_rate_init taken in cross-validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00160854 0.00126837 0.00012013 0.00076769 0.05002515 0.01145947\n",
      " 0.02901714 0.09790474 0.00027246 0.00037008 0.00012785 0.010354\n",
      " 0.0001637  0.0948443  0.00422924 0.00925159 0.0004398  0.0004947\n",
      " 0.00061136 0.00257339 0.02863698 0.008649   0.00080754 0.0123753\n",
      " 0.00213746]\n",
      "[[8], [6], [9], [6], [5], [5, 3], [6, 5], [7, 9], [4, 4], [4, 7, 4], [5, 4, 8], [3, 6, 5]]\n",
      "[4.13060923e-02 1.38068191e-04 3.73858468e+00 3.64520492e-01\n",
      " 1.22056361e-04 2.48012558e-03 1.28511657e-03 1.53387198e-01\n",
      " 1.96136544e-03 5.29575044e-01 2.55381130e-01 2.79069957e-01\n",
      " 6.29175430e-03 2.72246126e-03 1.46428470e+00 4.98806935e-01\n",
      " 2.58114647e-03 7.26335996e+00 1.42827228e-04 8.26012374e+00\n",
      " 2.97498847e+00 9.95689976e-02 4.84361743e+00 4.13700789e-01\n",
      " 6.79034555e+00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "solv = [\"lbfgs\", \"adam\", \"sgd\"]\n",
    "act = [\"logistic\", \"tanh\", \"relu\"]\n",
    "lr_init = learning_rate_fn(25, 0.0001, 0.1)\n",
    "alpha = learning_rate_fn(25, 0.0001, 10)\n",
    "\n",
    "# Total 12 hidden-layer-sizes in list for param-grid\n",
    "hidden_layer_sz = hidden_layer_fn(5, 1, 3, 10) + hidden_layer_fn(4, 2, 3, 10) + hidden_layer_fn(3, 3, 3, 10)\n",
    "\n",
    "param_dist = {\"solver\":solv,\n",
    "              \"activation\": act,\n",
    "              \"learning_rate_init\": lr_init,\n",
    "              \"hidden_layer_sizes\": hidden_layer_sz,\n",
    "              \"alpha\": alpha}\n",
    "\n",
    "print(lr_init)\n",
    "print(hidden_layer_sz)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# n_iter: The number of parameter settings that are tried. Number of parameter settings that are sampled.\n",
    "random_search = RandomizedSearchCV(\n",
    "    MLPRegressor(learning_rate=\"constant\",\n",
    "                 max_iter=18000,\n",
    "#                  alpha=0.01, # Regularization-parameter\n",
    "                 random_state=0),\n",
    "    param_distributions=param_dist,\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    scoring=[\"neg_mean_squared_error\", \"r2\"],\n",
    "    n_iter=30,\n",
    "    refit=\"r2\"\n",
    ")\n",
    "random_models = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_train_r2</th>\n",
       "      <th>split1_train_r2</th>\n",
       "      <th>split2_train_r2</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00126837</td>\n",
       "      <td>[6, 5]</td>\n",
       "      <td>0.00629175</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0012...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.241367e+04</td>\n",
       "      <td>-2.539848e+04</td>\n",
       "      <td>-1.999478e+04</td>\n",
       "      <td>5.520095e+03</td>\n",
       "      <td>29</td>\n",
       "      <td>-1.797629e+04</td>\n",
       "      <td>-1.764117e+04</td>\n",
       "      <td>-2.059863e+04</td>\n",
       "      <td>-1.873870e+04</td>\n",
       "      <td>1.322270e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.151062</td>\n",
       "      <td>1.072571</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00925159</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.0413061</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.468816e-01</td>\n",
       "      <td>3.294070e-01</td>\n",
       "      <td>1.742156e-01</td>\n",
       "      <td>1.171595e-01</td>\n",
       "      <td>11</td>\n",
       "      <td>9.860633e-01</td>\n",
       "      <td>3.096961e-01</td>\n",
       "      <td>9.488778e-01</td>\n",
       "      <td>7.482124e-01</td>\n",
       "      <td>3.104492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025728</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0290171</td>\n",
       "      <td>[5, 3]</td>\n",
       "      <td>0.00258115</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0290...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.115095e-01</td>\n",
       "      <td>-1.041095e+00</td>\n",
       "      <td>-5.350771e-01</td>\n",
       "      <td>3.624173e-01</td>\n",
       "      <td>27</td>\n",
       "      <td>-4.112360e-01</td>\n",
       "      <td>-4.977411e-01</td>\n",
       "      <td>-4.472145e-01</td>\n",
       "      <td>-4.520638e-01</td>\n",
       "      <td>3.548164e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>0.413701</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0103...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.131189e+47</td>\n",
       "      <td>-4.559459e+47</td>\n",
       "      <td>-3.695794e+47</td>\n",
       "      <td>1.845383e+47</td>\n",
       "      <td>30</td>\n",
       "      <td>-4.368465e+47</td>\n",
       "      <td>-1.603722e+47</td>\n",
       "      <td>-3.710790e+47</td>\n",
       "      <td>-3.227659e+47</td>\n",
       "      <td>1.179269e+47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.877246</td>\n",
       "      <td>0.490855</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00126837</td>\n",
       "      <td>[6]</td>\n",
       "      <td>7.26336</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.237576e-01</td>\n",
       "      <td>4.206384e-01</td>\n",
       "      <td>6.357232e-01</td>\n",
       "      <td>1.529198e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>7.847430e-01</td>\n",
       "      <td>7.479468e-01</td>\n",
       "      <td>8.131164e-01</td>\n",
       "      <td>7.819354e-01</td>\n",
       "      <td>2.667935e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.134094</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000272459</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>0.099569</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.914896e-02</td>\n",
       "      <td>-7.398893e-02</td>\n",
       "      <td>-3.632439e-02</td>\n",
       "      <td>2.666719e-02</td>\n",
       "      <td>18</td>\n",
       "      <td>-3.851033e-05</td>\n",
       "      <td>-4.702776e-05</td>\n",
       "      <td>-4.050660e-05</td>\n",
       "      <td>-4.201490e-05</td>\n",
       "      <td>3.637112e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014056</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0114595</td>\n",
       "      <td>[6]</td>\n",
       "      <td>8.26012</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0114...</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.400783e-02</td>\n",
       "      <td>-3.942254e-02</td>\n",
       "      <td>-3.508172e-02</td>\n",
       "      <td>3.197337e-03</td>\n",
       "      <td>15</td>\n",
       "      <td>-2.897470e-03</td>\n",
       "      <td>-3.771380e-03</td>\n",
       "      <td>-5.324097e-03</td>\n",
       "      <td>-3.997649e-03</td>\n",
       "      <td>1.003503e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.584997</td>\n",
       "      <td>0.156318</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000272459</td>\n",
       "      <td>[5, 4, 8]</td>\n",
       "      <td>4.84362</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.532351e-02</td>\n",
       "      <td>-6.107922e-02</td>\n",
       "      <td>-3.637216e-02</td>\n",
       "      <td>1.750299e-02</td>\n",
       "      <td>20</td>\n",
       "      <td>-8.198678e-04</td>\n",
       "      <td>-9.990824e-04</td>\n",
       "      <td>-8.324072e-04</td>\n",
       "      <td>-8.837858e-04</td>\n",
       "      <td>8.168759e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000370082</td>\n",
       "      <td>[3, 6, 5]</td>\n",
       "      <td>0.000122056</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.758929e-02</td>\n",
       "      <td>-7.787301e-02</td>\n",
       "      <td>-3.653688e-02</td>\n",
       "      <td>2.926279e-02</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.824541e-11</td>\n",
       "      <td>-2.233724e-11</td>\n",
       "      <td>-2.006417e-11</td>\n",
       "      <td>-2.021561e-11</td>\n",
       "      <td>1.673914e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.435830</td>\n",
       "      <td>0.042216</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>[8]</td>\n",
       "      <td>6.79035</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.028...</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.264675e-03</td>\n",
       "      <td>-1.306605e-01</td>\n",
       "      <td>6.964129e-02</td>\n",
       "      <td>2.023854e-01</td>\n",
       "      <td>13</td>\n",
       "      <td>3.008620e-01</td>\n",
       "      <td>6.905349e-02</td>\n",
       "      <td>-5.601508e-03</td>\n",
       "      <td>1.214380e-01</td>\n",
       "      <td>1.304813e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.623217</td>\n",
       "      <td>1.193644</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00925159</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>0.498807</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.009...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.140690e-01</td>\n",
       "      <td>1.449369e-01</td>\n",
       "      <td>6.043362e-01</td>\n",
       "      <td>3.313519e-01</td>\n",
       "      <td>7</td>\n",
       "      <td>9.821308e-01</td>\n",
       "      <td>9.308626e-01</td>\n",
       "      <td>9.907878e-01</td>\n",
       "      <td>9.679271e-01</td>\n",
       "      <td>2.644574e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.504245</td>\n",
       "      <td>0.035798</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000272459</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>0.529575</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0002...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.360998e-02</td>\n",
       "      <td>-6.416981e-02</td>\n",
       "      <td>-3.618908e-02</td>\n",
       "      <td>1.981888e-02</td>\n",
       "      <td>16</td>\n",
       "      <td>-5.201652e-04</td>\n",
       "      <td>-6.296699e-04</td>\n",
       "      <td>-5.438462e-04</td>\n",
       "      <td>-5.645604e-04</td>\n",
       "      <td>4.704344e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.258004</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000163696</td>\n",
       "      <td>[8]</td>\n",
       "      <td>0.000138068</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0001...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.073311e-02</td>\n",
       "      <td>-7.052455e-02</td>\n",
       "      <td>-3.625501e-02</td>\n",
       "      <td>2.426798e-02</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.582226e-04</td>\n",
       "      <td>-1.904974e-04</td>\n",
       "      <td>-1.637315e-04</td>\n",
       "      <td>-1.708172e-04</td>\n",
       "      <td>1.409661e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.195180</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00257339</td>\n",
       "      <td>[9]</td>\n",
       "      <td>6.79035</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.815788e-01</td>\n",
       "      <td>9.154610e-01</td>\n",
       "      <td>7.543321e-01</td>\n",
       "      <td>2.043809e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.450694e-01</td>\n",
       "      <td>9.221424e-01</td>\n",
       "      <td>9.229945e-01</td>\n",
       "      <td>9.300688e-01</td>\n",
       "      <td>1.061274e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.770831</td>\n",
       "      <td>1.759487</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00213746</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.413701</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.137427e-01</td>\n",
       "      <td>3.014432e-01</td>\n",
       "      <td>6.194553e-01</td>\n",
       "      <td>2.505325e-01</td>\n",
       "      <td>6</td>\n",
       "      <td>9.985768e-01</td>\n",
       "      <td>9.920890e-01</td>\n",
       "      <td>9.980113e-01</td>\n",
       "      <td>9.962257e-01</td>\n",
       "      <td>2.934200e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00160854</td>\n",
       "      <td>[5, 3]</td>\n",
       "      <td>0.000138068</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.758980e-02</td>\n",
       "      <td>-7.787125e-02</td>\n",
       "      <td>-3.653666e-02</td>\n",
       "      <td>2.926171e-02</td>\n",
       "      <td>23</td>\n",
       "      <td>-4.175238e-11</td>\n",
       "      <td>-4.930922e-11</td>\n",
       "      <td>-5.398793e-11</td>\n",
       "      <td>-4.834984e-11</td>\n",
       "      <td>5.040996e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.067848</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000494701</td>\n",
       "      <td>[8]</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0004...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743834e-02</td>\n",
       "      <td>-7.837749e-02</td>\n",
       "      <td>-3.658983e-02</td>\n",
       "      <td>2.958256e-02</td>\n",
       "      <td>25</td>\n",
       "      <td>-1.535916e-05</td>\n",
       "      <td>-1.293731e-05</td>\n",
       "      <td>-1.664899e-05</td>\n",
       "      <td>-1.498182e-05</td>\n",
       "      <td>1.538603e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.391042</td>\n",
       "      <td>0.068486</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0979047</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>7.26336</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.097...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.904045e-02</td>\n",
       "      <td>-7.426944e-02</td>\n",
       "      <td>-3.634245e-02</td>\n",
       "      <td>2.685272e-02</td>\n",
       "      <td>19</td>\n",
       "      <td>-3.343892e-05</td>\n",
       "      <td>-4.082933e-05</td>\n",
       "      <td>-3.479069e-05</td>\n",
       "      <td>-3.635298e-05</td>\n",
       "      <td>3.213004e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.992254</td>\n",
       "      <td>3.127461</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000439805</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>4.84362</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0004...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.328440e-02</td>\n",
       "      <td>-1.000878e-03</td>\n",
       "      <td>-1.490024e-02</td>\n",
       "      <td>9.897878e-03</td>\n",
       "      <td>14</td>\n",
       "      <td>-4.632385e-04</td>\n",
       "      <td>-5.651208e-04</td>\n",
       "      <td>-4.982446e-02</td>\n",
       "      <td>-1.695094e-02</td>\n",
       "      <td>2.324513e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00422924</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>6.79035</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.758719e-02</td>\n",
       "      <td>-7.787518e-02</td>\n",
       "      <td>-3.653629e-02</td>\n",
       "      <td>2.926474e-02</td>\n",
       "      <td>22</td>\n",
       "      <td>-4.067191e-12</td>\n",
       "      <td>-1.864908e-11</td>\n",
       "      <td>1.529887e-12</td>\n",
       "      <td>-7.062129e-12</td>\n",
       "      <td>8.505878e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.267788</td>\n",
       "      <td>0.463744</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000439805</td>\n",
       "      <td>[9]</td>\n",
       "      <td>8.26012</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.575994e-01</td>\n",
       "      <td>3.962398e-01</td>\n",
       "      <td>6.468050e-01</td>\n",
       "      <td>1.775708e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>8.274524e-01</td>\n",
       "      <td>7.811677e-01</td>\n",
       "      <td>8.626737e-01</td>\n",
       "      <td>8.237646e-01</td>\n",
       "      <td>3.337672e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.675017</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000370082</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.498807</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.739426e-01</td>\n",
       "      <td>4.370561e-01</td>\n",
       "      <td>6.572199e-01</td>\n",
       "      <td>1.783748e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>9.563292e-01</td>\n",
       "      <td>9.354905e-01</td>\n",
       "      <td>9.441759e-01</td>\n",
       "      <td>9.453319e-01</td>\n",
       "      <td>8.546509e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.117328</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0979047</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>0.27907</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.09...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.021227e-01</td>\n",
       "      <td>1.331829e-01</td>\n",
       "      <td>5.145703e-01</td>\n",
       "      <td>2.810384e-01</td>\n",
       "      <td>9</td>\n",
       "      <td>9.179762e-01</td>\n",
       "      <td>6.933296e-01</td>\n",
       "      <td>9.157132e-01</td>\n",
       "      <td>8.423397e-01</td>\n",
       "      <td>1.053701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.000370082</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>0.00629175</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.758788e-02</td>\n",
       "      <td>-7.787064e-02</td>\n",
       "      <td>-3.653511e-02</td>\n",
       "      <td>2.926237e-02</td>\n",
       "      <td>21</td>\n",
       "      <td>-2.269074e-12</td>\n",
       "      <td>-2.514433e-12</td>\n",
       "      <td>2.965871e-10</td>\n",
       "      <td>9.726786e-11</td>\n",
       "      <td>1.409400e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.881326</td>\n",
       "      <td>0.082570</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00257339</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.0413061</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.002...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.818451e-01</td>\n",
       "      <td>4.294766e-01</td>\n",
       "      <td>6.461129e-01</td>\n",
       "      <td>1.851716e-01</td>\n",
       "      <td>4</td>\n",
       "      <td>9.591902e-01</td>\n",
       "      <td>9.361063e-01</td>\n",
       "      <td>9.448793e-01</td>\n",
       "      <td>9.467253e-01</td>\n",
       "      <td>9.513909e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.262723</td>\n",
       "      <td>1.781706</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000494701</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>0.00258115</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'adam', 'learning_rate_init': 0.000...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.871968e-02</td>\n",
       "      <td>-5.509234e-02</td>\n",
       "      <td>1.139997e-01</td>\n",
       "      <td>2.207467e-01</td>\n",
       "      <td>12</td>\n",
       "      <td>9.623187e-01</td>\n",
       "      <td>-1.924978e-03</td>\n",
       "      <td>-1.600436e-03</td>\n",
       "      <td>3.195978e-01</td>\n",
       "      <td>4.544723e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00257339</td>\n",
       "      <td>[5]</td>\n",
       "      <td>6.79035</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0025...</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.347646e-02</td>\n",
       "      <td>-5.400293e-01</td>\n",
       "      <td>-2.317180e-01</td>\n",
       "      <td>2.188942e-01</td>\n",
       "      <td>26</td>\n",
       "      <td>-1.551246e-01</td>\n",
       "      <td>-1.877101e-01</td>\n",
       "      <td>-1.690870e-01</td>\n",
       "      <td>-1.706405e-01</td>\n",
       "      <td>1.334826e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.027147</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.000163696</td>\n",
       "      <td>[4, 7, 4]</td>\n",
       "      <td>0.36452</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'sgd', 'learning_rate_init': 0.0001...</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.690021e+00</td>\n",
       "      <td>-1.136391e+01</td>\n",
       "      <td>-8.790335e+00</td>\n",
       "      <td>2.930688e+00</td>\n",
       "      <td>28</td>\n",
       "      <td>-7.729293e+00</td>\n",
       "      <td>-5.309453e+00</td>\n",
       "      <td>-1.087056e+01</td>\n",
       "      <td>-7.969770e+00</td>\n",
       "      <td>2.276673e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.151345</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0114595</td>\n",
       "      <td>[8]</td>\n",
       "      <td>6.79035</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.01...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.392860e-01</td>\n",
       "      <td>5.191681e-01</td>\n",
       "      <td>5.933712e-01</td>\n",
       "      <td>1.031824e-01</td>\n",
       "      <td>8</td>\n",
       "      <td>9.432099e-01</td>\n",
       "      <td>8.981893e-01</td>\n",
       "      <td>9.716979e-01</td>\n",
       "      <td>9.376990e-01</td>\n",
       "      <td>3.026171e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.980685</td>\n",
       "      <td>2.491054</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00257339</td>\n",
       "      <td>[6, 5]</td>\n",
       "      <td>0.0413061</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'solver': 'lbfgs', 'learning_rate_init': 0.00...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.426210e-01</td>\n",
       "      <td>4.698914e-01</td>\n",
       "      <td>2.212037e-01</td>\n",
       "      <td>3.326009e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>9.998529e-01</td>\n",
       "      <td>9.970974e-01</td>\n",
       "      <td>9.996045e-01</td>\n",
       "      <td>9.988516e-01</td>\n",
       "      <td>1.244529e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_solver  \\\n",
       "0        0.012578      0.004465         0.002675        0.001892          sgd   \n",
       "1        1.151062      1.072571         0.001346        0.001904        lbfgs   \n",
       "2        0.025728      0.003799         0.004566        0.000767          sgd   \n",
       "3        0.016841      0.000591         0.002035        0.001634          sgd   \n",
       "4        0.877246      0.490855         0.004367        0.000517        lbfgs   \n",
       "5        0.134094      0.002488         0.003571        0.000687          sgd   \n",
       "6        0.014056      0.000022         0.004607        0.000421          sgd   \n",
       "7       11.584997      0.156318         0.004225        0.000304          sgd   \n",
       "8        0.010461      0.000970         0.004866        0.001140        lbfgs   \n",
       "9        0.435830      0.042216         0.003593        0.000648         adam   \n",
       "10       1.623217      1.193644         0.006152        0.005319         adam   \n",
       "11       0.504245      0.035798         0.002402        0.002724          sgd   \n",
       "12       0.258004      0.006275         0.002672        0.001889          sgd   \n",
       "13       0.195180      0.024278         0.002015        0.001444        lbfgs   \n",
       "14       5.770831      1.759487         0.004010        0.000006        lbfgs   \n",
       "15       0.007608      0.001207         0.002667        0.001886        lbfgs   \n",
       "16       0.067848      0.000226         0.002352        0.001234          sgd   \n",
       "17       1.391042      0.068486         0.004366        0.000410         adam   \n",
       "18       4.992254      3.127461         0.002525        0.001911          sgd   \n",
       "19       0.019043      0.007301         0.000632        0.000894        lbfgs   \n",
       "20       1.267788      0.463744         0.002213        0.001135        lbfgs   \n",
       "21      12.675017      0.351014         0.005095        0.001183         adam   \n",
       "22       0.117328      0.006769         0.004069        0.000095        lbfgs   \n",
       "23       0.013649      0.002598         0.004391        0.000519        lbfgs   \n",
       "24       6.881326      0.082570         0.004077        0.000096         adam   \n",
       "25      12.262723      1.781706         0.003008        0.002127         adam   \n",
       "26       0.022220      0.001164         0.003075        0.001469          sgd   \n",
       "27       0.027147      0.006667         0.002386        0.001732          sgd   \n",
       "28       0.151345      0.037387         0.003615        0.002557        lbfgs   \n",
       "29       6.980685      2.491054         0.002063        0.002252        lbfgs   \n",
       "\n",
       "   param_learning_rate_init param_hidden_layer_sizes  param_alpha  \\\n",
       "0                0.00126837                   [6, 5]   0.00629175   \n",
       "1                0.00925159                      [6]    0.0413061   \n",
       "2                 0.0290171                   [5, 3]   0.00258115   \n",
       "3                  0.010354                   [7, 9]     0.413701   \n",
       "4                0.00126837                      [6]      7.26336   \n",
       "5               0.000272459                   [7, 9]     0.099569   \n",
       "6                 0.0114595                      [6]      8.26012   \n",
       "7               0.000272459                [5, 4, 8]      4.84362   \n",
       "8               0.000370082                [3, 6, 5]  0.000122056   \n",
       "9                  0.028637                      [8]      6.79035   \n",
       "10               0.00925159                [4, 7, 4]     0.498807   \n",
       "11              0.000272459                [4, 7, 4]     0.529575   \n",
       "12              0.000163696                      [8]  0.000138068   \n",
       "13               0.00257339                      [9]      6.79035   \n",
       "14               0.00213746                      [6]     0.413701   \n",
       "15               0.00160854                   [5, 3]  0.000138068   \n",
       "16              0.000494701                      [8]     0.153387   \n",
       "17                0.0979047                [4, 7, 4]      7.26336   \n",
       "18              0.000439805                [4, 7, 4]      4.84362   \n",
       "19               0.00422924                   [4, 4]      6.79035   \n",
       "20              0.000439805                      [9]      8.26012   \n",
       "21              0.000370082                      [6]     0.498807   \n",
       "22                0.0979047                [4, 7, 4]      0.27907   \n",
       "23              0.000370082                   [4, 4]   0.00629175   \n",
       "24               0.00257339                      [6]    0.0413061   \n",
       "25              0.000494701                [4, 7, 4]   0.00258115   \n",
       "26               0.00257339                      [5]      6.79035   \n",
       "27              0.000163696                [4, 7, 4]      0.36452   \n",
       "28                0.0114595                      [8]      6.79035   \n",
       "29               0.00257339                   [6, 5]    0.0413061   \n",
       "\n",
       "   param_activation                                             params  ...  \\\n",
       "0              relu  {'solver': 'sgd', 'learning_rate_init': 0.0012...  ...   \n",
       "1              relu  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "2              relu  {'solver': 'sgd', 'learning_rate_init': 0.0290...  ...   \n",
       "3              relu  {'solver': 'sgd', 'learning_rate_init': 0.0103...  ...   \n",
       "4          logistic  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "5              tanh  {'solver': 'sgd', 'learning_rate_init': 0.0002...  ...   \n",
       "6          logistic  {'solver': 'sgd', 'learning_rate_init': 0.0114...  ...   \n",
       "7              tanh  {'solver': 'sgd', 'learning_rate_init': 0.0002...  ...   \n",
       "8              tanh  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "9          logistic  {'solver': 'adam', 'learning_rate_init': 0.028...  ...   \n",
       "10             relu  {'solver': 'adam', 'learning_rate_init': 0.009...  ...   \n",
       "11         logistic  {'solver': 'sgd', 'learning_rate_init': 0.0002...  ...   \n",
       "12         logistic  {'solver': 'sgd', 'learning_rate_init': 0.0001...  ...   \n",
       "13             relu  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "14             tanh  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "15             tanh  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "16         logistic  {'solver': 'sgd', 'learning_rate_init': 0.0004...  ...   \n",
       "17         logistic  {'solver': 'adam', 'learning_rate_init': 0.097...  ...   \n",
       "18             tanh  {'solver': 'sgd', 'learning_rate_init': 0.0004...  ...   \n",
       "19         logistic  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "20         logistic  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "21             relu  {'solver': 'adam', 'learning_rate_init': 0.000...  ...   \n",
       "22             relu  {'solver': 'lbfgs', 'learning_rate_init': 0.09...  ...   \n",
       "23             relu  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "24             relu  {'solver': 'adam', 'learning_rate_init': 0.002...  ...   \n",
       "25             tanh  {'solver': 'adam', 'learning_rate_init': 0.000...  ...   \n",
       "26             tanh  {'solver': 'sgd', 'learning_rate_init': 0.0025...  ...   \n",
       "27             relu  {'solver': 'sgd', 'learning_rate_init': 0.0001...  ...   \n",
       "28             relu  {'solver': 'lbfgs', 'learning_rate_init': 0.01...  ...   \n",
       "29         logistic  {'solver': 'lbfgs', 'learning_rate_init': 0.00...  ...   \n",
       "\n",
       "    split1_test_r2  split2_test_r2  mean_test_r2   std_test_r2  rank_test_r2  \\\n",
       "0    -1.241367e+04   -2.539848e+04 -1.999478e+04  5.520095e+03            29   \n",
       "1     1.468816e-01    3.294070e-01  1.742156e-01  1.171595e-01            11   \n",
       "2    -2.115095e-01   -1.041095e+00 -5.350771e-01  3.624173e-01            27   \n",
       "3    -1.131189e+47   -4.559459e+47 -3.695794e+47  1.845383e+47            30   \n",
       "4     7.237576e-01    4.206384e-01  6.357232e-01  1.529198e-01             5   \n",
       "5    -1.914896e-02   -7.398893e-02 -3.632439e-02  2.666719e-02            18   \n",
       "6    -3.400783e-02   -3.942254e-02 -3.508172e-02  3.197337e-03            15   \n",
       "7    -2.532351e-02   -6.107922e-02 -3.637216e-02  1.750299e-02            20   \n",
       "8    -1.758929e-02   -7.787301e-02 -3.653688e-02  2.926279e-02            24   \n",
       "9    -7.264675e-03   -1.306605e-01  6.964129e-02  2.023854e-01            13   \n",
       "10    9.140690e-01    1.449369e-01  6.043362e-01  3.313519e-01             7   \n",
       "11   -2.360998e-02   -6.416981e-02 -3.618908e-02  1.981888e-02            16   \n",
       "12   -2.073311e-02   -7.052455e-02 -3.625501e-02  2.426798e-02            17   \n",
       "13    8.815788e-01    9.154610e-01  7.543321e-01  2.043809e-01             1   \n",
       "14    9.137427e-01    3.014432e-01  6.194553e-01  2.505325e-01             6   \n",
       "15   -1.758980e-02   -7.787125e-02 -3.653666e-02  2.926171e-02            23   \n",
       "16   -1.743834e-02   -7.837749e-02 -3.658983e-02  2.958256e-02            25   \n",
       "17   -1.904045e-02   -7.426944e-02 -3.634245e-02  2.685272e-02            19   \n",
       "18   -2.328440e-02   -1.000878e-03 -1.490024e-02  9.897878e-03            14   \n",
       "19   -1.758719e-02   -7.787518e-02 -3.653629e-02  2.926474e-02            22   \n",
       "20    7.575994e-01    3.962398e-01  6.468050e-01  1.775708e-01             3   \n",
       "21    8.739426e-01    4.370561e-01  6.572199e-01  1.783748e-01             2   \n",
       "22    8.021227e-01    1.331829e-01  5.145703e-01  2.810384e-01             9   \n",
       "23   -1.758788e-02   -7.787064e-02 -3.653511e-02  2.926237e-02            21   \n",
       "24    8.818451e-01    4.294766e-01  6.461129e-01  1.851716e-01             4   \n",
       "25   -2.871968e-02   -5.509234e-02  1.139997e-01  2.207467e-01            12   \n",
       "26   -5.347646e-02   -5.400293e-01 -2.317180e-01  2.188942e-01            26   \n",
       "27   -4.690021e+00   -1.136391e+01 -8.790335e+00  2.930688e+00            28   \n",
       "28    7.392860e-01    5.191681e-01  5.933712e-01  1.031824e-01             8   \n",
       "29    4.426210e-01    4.698914e-01  2.212037e-01  3.326009e-01            10   \n",
       "\n",
       "    split0_train_r2  split1_train_r2  split2_train_r2  mean_train_r2  \\\n",
       "0     -1.797629e+04    -1.764117e+04    -2.059863e+04  -1.873870e+04   \n",
       "1      9.860633e-01     3.096961e-01     9.488778e-01   7.482124e-01   \n",
       "2     -4.112360e-01    -4.977411e-01    -4.472145e-01  -4.520638e-01   \n",
       "3     -4.368465e+47    -1.603722e+47    -3.710790e+47  -3.227659e+47   \n",
       "4      7.847430e-01     7.479468e-01     8.131164e-01   7.819354e-01   \n",
       "5     -3.851033e-05    -4.702776e-05    -4.050660e-05  -4.201490e-05   \n",
       "6     -2.897470e-03    -3.771380e-03    -5.324097e-03  -3.997649e-03   \n",
       "7     -8.198678e-04    -9.990824e-04    -8.324072e-04  -8.837858e-04   \n",
       "8     -1.824541e-11    -2.233724e-11    -2.006417e-11  -2.021561e-11   \n",
       "9      3.008620e-01     6.905349e-02    -5.601508e-03   1.214380e-01   \n",
       "10     9.821308e-01     9.308626e-01     9.907878e-01   9.679271e-01   \n",
       "11    -5.201652e-04    -6.296699e-04    -5.438462e-04  -5.645604e-04   \n",
       "12    -1.582226e-04    -1.904974e-04    -1.637315e-04  -1.708172e-04   \n",
       "13     9.450694e-01     9.221424e-01     9.229945e-01   9.300688e-01   \n",
       "14     9.985768e-01     9.920890e-01     9.980113e-01   9.962257e-01   \n",
       "15    -4.175238e-11    -4.930922e-11    -5.398793e-11  -4.834984e-11   \n",
       "16    -1.535916e-05    -1.293731e-05    -1.664899e-05  -1.498182e-05   \n",
       "17    -3.343892e-05    -4.082933e-05    -3.479069e-05  -3.635298e-05   \n",
       "18    -4.632385e-04    -5.651208e-04    -4.982446e-02  -1.695094e-02   \n",
       "19    -4.067191e-12    -1.864908e-11     1.529887e-12  -7.062129e-12   \n",
       "20     8.274524e-01     7.811677e-01     8.626737e-01   8.237646e-01   \n",
       "21     9.563292e-01     9.354905e-01     9.441759e-01   9.453319e-01   \n",
       "22     9.179762e-01     6.933296e-01     9.157132e-01   8.423397e-01   \n",
       "23    -2.269074e-12    -2.514433e-12     2.965871e-10   9.726786e-11   \n",
       "24     9.591902e-01     9.361063e-01     9.448793e-01   9.467253e-01   \n",
       "25     9.623187e-01    -1.924978e-03    -1.600436e-03   3.195978e-01   \n",
       "26    -1.551246e-01    -1.877101e-01    -1.690870e-01  -1.706405e-01   \n",
       "27    -7.729293e+00    -5.309453e+00    -1.087056e+01  -7.969770e+00   \n",
       "28     9.432099e-01     8.981893e-01     9.716979e-01   9.376990e-01   \n",
       "29     9.998529e-01     9.970974e-01     9.996045e-01   9.988516e-01   \n",
       "\n",
       "    std_train_r2  \n",
       "0   1.322270e+03  \n",
       "1   3.104492e-01  \n",
       "2   3.548164e-02  \n",
       "3   1.179269e+47  \n",
       "4   2.667935e-02  \n",
       "5   3.637112e-06  \n",
       "6   1.003503e-03  \n",
       "7   8.168759e-05  \n",
       "8   1.673914e-12  \n",
       "9   1.304813e-01  \n",
       "10  2.644574e-02  \n",
       "11  4.704344e-05  \n",
       "12  1.409661e-05  \n",
       "13  1.061274e-02  \n",
       "14  2.934200e-03  \n",
       "15  5.040996e-12  \n",
       "16  1.538603e-06  \n",
       "17  3.213004e-06  \n",
       "18  2.324513e-02  \n",
       "19  8.505878e-12  \n",
       "20  3.337672e-02  \n",
       "21  8.546509e-03  \n",
       "22  1.053701e-01  \n",
       "23  1.409400e-10  \n",
       "24  9.513909e-03  \n",
       "25  4.544723e-01  \n",
       "26  1.334826e-02  \n",
       "27  2.276673e+00  \n",
       "28  3.026171e-02  \n",
       "29  1.244529e-03  \n",
       "\n",
       "[30 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(random_models.cv_results_)\n",
    "cv_results.columns\n",
    "random_models.param_distributions\n",
    "display(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "# plt.plot(cv_results.param_learning_rate_init, cv_results.mean_train_r2)\n",
    "# plt.plot(cv_results.param_learning_rate_init, cv_results.mean_test_r2)\n",
    "# plt.show()\n",
    "plt.scatter(cv_results.loc[0:5, :].param_alpha, cv_results.loc[0:5, :].mean_train_r2, c=cv_results.loc[0:5, :].mean_test_r2)\n",
    "plt.plot(cv_results.loc[0:5, :].param_alpha, cv_results.loc[0:5, :].mean_train_r2)\n",
    "# plt.scatter(cv_results.param_alpha, cv_results.param_learning_rate_init)#, color=cv_results.mean_test_r2)\n",
    "# sb.lineplot(cv_results[0:3].param_alpha, cv_results[0:3].param_learning_rate_init)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032146286432036"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_train, y_train)\n",
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 32 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   mean_fit_time                        30 non-null     float64\n",
      " 1   std_fit_time                         30 non-null     float64\n",
      " 2   mean_score_time                      30 non-null     float64\n",
      " 3   std_score_time                       30 non-null     float64\n",
      " 4   param_solver                         30 non-null     object \n",
      " 5   param_learning_rate_init             30 non-null     object \n",
      " 6   param_hidden_layer_sizes             30 non-null     object \n",
      " 7   param_alpha                          30 non-null     object \n",
      " 8   param_activation                     30 non-null     object \n",
      " 9   params                               30 non-null     object \n",
      " 10  split0_test_neg_mean_squared_error   30 non-null     float64\n",
      " 11  split1_test_neg_mean_squared_error   30 non-null     float64\n",
      " 12  split2_test_neg_mean_squared_error   30 non-null     float64\n",
      " 13  mean_test_neg_mean_squared_error     30 non-null     float64\n",
      " 14  std_test_neg_mean_squared_error      30 non-null     float64\n",
      " 15  rank_test_neg_mean_squared_error     30 non-null     int32  \n",
      " 16  split0_train_neg_mean_squared_error  30 non-null     float64\n",
      " 17  split1_train_neg_mean_squared_error  30 non-null     float64\n",
      " 18  split2_train_neg_mean_squared_error  30 non-null     float64\n",
      " 19  mean_train_neg_mean_squared_error    30 non-null     float64\n",
      " 20  std_train_neg_mean_squared_error     30 non-null     float64\n",
      " 21  split0_test_r2                       30 non-null     float64\n",
      " 22  split1_test_r2                       30 non-null     float64\n",
      " 23  split2_test_r2                       30 non-null     float64\n",
      " 24  mean_test_r2                         30 non-null     float64\n",
      " 25  std_test_r2                          30 non-null     float64\n",
      " 26  rank_test_r2                         30 non-null     int32  \n",
      " 27  split0_train_r2                      30 non-null     float64\n",
      " 28  split1_train_r2                      30 non-null     float64\n",
      " 29  split2_train_r2                      30 non-null     float64\n",
      " 30  mean_train_r2                        30 non-null     float64\n",
      " 31  std_train_r2                         30 non-null     float64\n",
      "dtypes: float64(24), int32(2), object(6)\n",
      "memory usage: 7.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cv_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
